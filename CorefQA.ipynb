{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\r\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\r\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 3.8MB/s \r\n",
      "\u001b[?25hRequirement already satisfied: boto3 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.9.134)\r\n",
      "Requirement already satisfied: torch>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.0.1.post2)\r\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2019.4.14)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (1.16.3)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (4.31.1)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pytorch_pretrained_bert) (2.21.0)\r\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\r\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.134 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (1.12.134)\r\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\r\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2.6)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\r\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (1.22)\r\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pytorch_pretrained_bert) (3.0.4)\r\n",
      "Requirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.134->boto3->pytorch_pretrained_bert) (0.14)\r\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /opt/conda/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.134->boto3->pytorch_pretrained_bert) (2.6.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.134->boto3->pytorch_pretrained_bert) (1.12.0)\r\n",
      "Installing collected packages: pytorch-pretrained-bert\r\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\r\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 19.1 is available.\r\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test_stage_2.tsv', 'test_stage_1.tsv', 'sample_submission_stage_1.csv', 'sample_submission_stage_2.csv']\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from bson import ObjectId\n",
    "\n",
    "import pdb\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "from io import open\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
    "                              TensorDataset, Dataset)\n",
    "\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "from pytorch_pretrained_bert.file_utils import PYTORCH_PRETRAINED_BERT_CACHE\n",
    "from pytorch_pretrained_bert.modeling import BertForQuestionAnswering, BertForMultipleChoice, BertForPreTraining, BertConfig, BertModel, WEIGHTS_NAME, CONFIG_NAME\n",
    "from pytorch_pretrained_bert.optimization import BertAdam\n",
    "from pytorch_pretrained_bert.tokenization import (BasicTokenizer,\n",
    "                                                  BertTokenizer,\n",
    "                                                  whitespace_tokenize)\n",
    "\n",
    "if sys.version_info[0] == 2:\n",
    "    import cPickle as pickle\n",
    "else:\n",
    "    import pickle\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\"\n",
    "dev_path = \"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\"\n",
    "val_path = \"https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\"\n",
    "\n",
    "dev_df = pd.read_csv(test_path, delimiter=\"\\t\")#pd.read_csv(dev_path, delimiter=\"\\t\")\n",
    "test_df = pd.read_csv(dev_path, delimiter=\"\\t\")#pd.read_csv(test_path, delimiter=\"\\t\")\n",
    "val_df = pd.read_csv(val_path, delimiter=\"\\t\")\n",
    "\n",
    "test_df_prod = test_df.copy()\n",
    "#test_df_prod = test_df_prod[['ID', 'Text', 'Pronoun', 'Pronoun-offset', 'A', 'A-offset', 'B', 'B-offset', 'URL']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev_df = pd.concat([dev_df, test_df])\n",
    "# test_df_prod = pd.read_csv('../input/test_stage_2.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 454 2000\n"
     ]
    }
   ],
   "source": [
    "print(len(dev_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_label(a_coref, b_coref):\n",
    "    if a_coref:\n",
    "        return 0\n",
    "    elif b_coref:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "def get_gender(pronoun):\n",
    "    gender_mapping = {'he': 0, 'his': 0, 'him': 0, \n",
    "                      'she': 1, 'her': 1, 'hers': 1}\n",
    "    return gender_mapping.get(pronoun.lower(), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadExample(object):\n",
    "    \"\"\"\n",
    "    A single training/test example for the Squad dataset.\n",
    "    For examples without an answer, the start and end position are -1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 qas_id,\n",
    "                 question_text,\n",
    "                 doc_tokens,\n",
    "                 orig_answer_text=None,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 is_impossible=None):\n",
    "        self.qas_id = qas_id\n",
    "        self.question_text = question_text\n",
    "        self.doc_tokens = doc_tokens\n",
    "        self.orig_answer_text = orig_answer_text\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.__repr__()\n",
    "\n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        s += \"qas_id: %s\" % (self.qas_id)\n",
    "        s += \", question_text: %s\" % (\n",
    "            self.question_text)\n",
    "        s += \", doc_tokens: [%s]\" % (\" \".join(self.doc_tokens))\n",
    "        if self.start_position:\n",
    "            s += \", start_position: %d\" % (self.start_position)\n",
    "        if self.start_position:\n",
    "            s += \", end_position: %d\" % (self.end_position)\n",
    "        if self.start_position:\n",
    "            s += \", is_impossible: %r\" % (self.is_impossible)\n",
    "        return s\n",
    "\n",
    "\n",
    "class SquadInputFeatures(object):\n",
    "    \"\"\"A single set of features of data.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 unique_id,\n",
    "                 example_index,\n",
    "                 doc_span_index,\n",
    "                 tokens,\n",
    "                 token_to_orig_map,\n",
    "                 token_is_max_context,\n",
    "                 input_ids,\n",
    "                 input_mask,\n",
    "                 segment_ids,\n",
    "                 start_position=None,\n",
    "                 end_position=None,\n",
    "                 is_impossible=None):\n",
    "        self.unique_id = unique_id\n",
    "        self.example_index = example_index\n",
    "        self.doc_span_index = doc_span_index\n",
    "        self.tokens = tokens\n",
    "        self.token_to_orig_map = token_to_orig_map\n",
    "        self.token_is_max_context = token_is_max_context\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.start_position = start_position\n",
    "        self.end_position = end_position\n",
    "        self.is_impossible = is_impossible\n",
    "        \n",
    "SquadRawResult = collections.namedtuple(\"SquadRawResult\",\n",
    "                                       [\"unique_id\", \"start_logits\", \"end_logits\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SquadRunner:\n",
    "    def __init__(self, dev_df, val_df, test_df, bert_model = 'bert-large-uncased', do_lower_case = True, learning_rate = 1e-5,\n",
    "                num_train_epochs = 2, max_seq_length = 300, doc_stride = 128, train_batch_size = 12, predict_batch_size = 8, warmup_proportion = 0.1,\n",
    "                n_best_size = 20, max_query_length = 50, max_answer_length = 50, output_dir = 'squad'):\n",
    "        self.dev_df = self.extract_target(dev_df)\n",
    "        self.val_df = self.extract_target(val_df)\n",
    "        self.test_df = test_df\n",
    "        #self.test_df = self.extract_target(test_df)\n",
    "\n",
    "        # Custom parameters\n",
    "        self.do_lower_case = do_lower_case\n",
    "        if do_lower_case: \n",
    "            self.bert_model = 'bert-large-uncased'\n",
    "        else:\n",
    "            self.bert_model = 'bert-large-cased'\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_train_epochs = num_train_epochs\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.doc_stride = doc_stride\n",
    "        self.output_dir = output_dir\n",
    "        self.train_batch_size = train_batch_size\n",
    "\n",
    "        # Default parameters\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "        \n",
    "        self.seed = 42\n",
    "        self.warmup_proportion = warmup_proportion\n",
    "        self.n_best_size = n_best_size\n",
    "        self.max_query_length = max_query_length\n",
    "        self.max_answer_length = max_answer_length\n",
    "        self.local_rank = -1\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.loss_scale = 0\n",
    "        self.version_2_with_negative = False\n",
    "        self.fp16 = False\n",
    "        self.no_cuda = False\n",
    "        self.verbose_logging = False\n",
    "        \n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() and not self.no_cuda else \"cpu\")\n",
    "\n",
    "        logger.info(\"device: {} distributed training: {}, 16-bits training: {}\".format(\n",
    "            self.device, bool(self.local_rank != -1), self.fp16))\n",
    "\n",
    "        self.train_batch_size = self.train_batch_size // self.gradient_accumulation_steps\n",
    "\n",
    "        random.seed(self.seed)\n",
    "        np.random.seed(self.seed)\n",
    "        torch.manual_seed(self.seed)\n",
    "\n",
    "        self.tokenizer = BertTokenizer.from_pretrained(self.bert_model, do_lower_case=self.do_lower_case)\n",
    "        \n",
    "    def extract_target(self, df):\n",
    "        df[\"Neither\"] = 0\n",
    "        df.loc[~(df['A-coref'] | df['B-coref']), \"Neither\"] = 1\n",
    "        df[\"target\"] = 0\n",
    "        df.loc[df['B-coref'] == 1, \"target\"] = 1\n",
    "        df.loc[df[\"Neither\"] == 1, \"target\"] = 2\n",
    "        df['gender'] = df['Pronoun'].transform(get_gender)\n",
    "        #print(df.target.value_counts())\n",
    "        return df\n",
    "\n",
    "    def read_squad_examples_from_data(self, input_data, is_training, version_2_with_negative):\n",
    "\n",
    "        def is_whitespace(c):\n",
    "            if c == \" \" or c == \"\\t\" or c == \"\\r\" or c == \"\\n\" or ord(c) == 0x202F:\n",
    "                return True\n",
    "            return False\n",
    "\n",
    "        examples = []\n",
    "        for entry in input_data:\n",
    "            for paragraph in entry[\"paragraphs\"]:\n",
    "                paragraph_text = paragraph[\"context\"]\n",
    "                doc_tokens = []\n",
    "                char_to_word_offset = []\n",
    "                prev_is_whitespace = True\n",
    "                for c in paragraph_text:\n",
    "                    if is_whitespace(c):\n",
    "                        prev_is_whitespace = True\n",
    "                    else:\n",
    "                        if prev_is_whitespace:\n",
    "                            doc_tokens.append(c)\n",
    "                        else:\n",
    "                            doc_tokens[-1] += c\n",
    "                        prev_is_whitespace = False\n",
    "                    char_to_word_offset.append(len(doc_tokens) - 1)\n",
    "\n",
    "                for qa in paragraph[\"qas\"]:\n",
    "                    qas_id = qa[\"id\"]\n",
    "                    question_text = qa[\"question\"]\n",
    "                    start_position = None\n",
    "                    end_position = None\n",
    "                    orig_answer_text = None\n",
    "                    is_impossible = False\n",
    "                    if is_training:\n",
    "                        if version_2_with_negative:\n",
    "                            is_impossible = qa[\"is_impossible\"]\n",
    "                        if (len(qa[\"answers\"]) != 1) and (not is_impossible):\n",
    "                            raise ValueError(\n",
    "                                \"For training, each question should have exactly 1 answer.\")\n",
    "                        if not is_impossible:\n",
    "                            answer = qa[\"answers\"][0]\n",
    "                            orig_answer_text = answer[\"text\"]\n",
    "                            answer_offset = answer[\"answer_start\"]\n",
    "                            answer_length = len(orig_answer_text)\n",
    "                            start_position = char_to_word_offset[answer_offset]\n",
    "                            end_position = char_to_word_offset[answer_offset + answer_length - 1]\n",
    "                            # Only add answers where the text can be exactly recovered from the\n",
    "                            # document. If this CAN'T happen it's likely due to weird Unicode\n",
    "                            # stuff so we will just skip the example.\n",
    "                            #\n",
    "                            # Note that this means for training mode, every example is NOT\n",
    "                            # guaranteed to be preserved.\n",
    "                            actual_text = \" \".join(doc_tokens[start_position:(end_position + 1)])\n",
    "                            cleaned_answer_text = \" \".join(\n",
    "                                whitespace_tokenize(orig_answer_text))\n",
    "                            if actual_text.find(cleaned_answer_text) == -1:\n",
    "                                logger.warning(\"Could not find answer: '%s' vs. '%s'\",\n",
    "                                               actual_text, cleaned_answer_text)\n",
    "                                continue\n",
    "                        else:\n",
    "                            start_position = -1\n",
    "                            end_position = -1\n",
    "                            orig_answer_text = \"\"\n",
    "\n",
    "                    example = SquadExample(\n",
    "                        qas_id=qas_id,\n",
    "                        question_text=question_text,\n",
    "                        doc_tokens=doc_tokens,\n",
    "                        orig_answer_text=orig_answer_text,\n",
    "                        start_position=start_position,\n",
    "                        end_position=end_position,\n",
    "                        is_impossible=is_impossible)\n",
    "                    examples.append(example)\n",
    "        return examples\n",
    "\n",
    "    def row_to_squad_example(self, row, is_training):\n",
    "        json_dict = {}\n",
    "\n",
    "        question_text = \"\"\n",
    "        pronoun_offset = row['Pronoun-offset']\n",
    "        n_chars_processed = 0\n",
    "        words = row['Text'].split(\" \")\n",
    "        for i, w in enumerate(words):\n",
    "            n_chars_processed += len(w) + 1\n",
    "            if n_chars_processed >= pronoun_offset:\n",
    "                question_text = \" \".join(words[i:i+5])\n",
    "                #question_text = \" \".join(words[i-3:i+4])\n",
    "    #             question_text_replaced = []\n",
    "    #             for w in question_text:\n",
    "    #                 if w != row['Pronoun']:\n",
    "    #                     question_text_replaced.append(w)\n",
    "    #                 else:\n",
    "    #                     question_text_replaced.append(\"<QUESTION>\")\n",
    "    #             question_text = \" \".join(question_text)\n",
    "                break \n",
    "\n",
    "    #     question_text = \"\"\n",
    "    #     pronoun_offset = row['Pronoun-offset']\n",
    "    #     n_chars_processed = 0\n",
    "    #     for sent in row['Text'].split(\".\"):\n",
    "    #         n_chars_processed += len(sent) + 1\n",
    "    #         if n_chars_processed >= pronoun_offset:\n",
    "    #             question_text = sent.strip()\n",
    "    #             question_text_replaced = []\n",
    "    #             for w in question_text.split(\" \"):\n",
    "    #                 if w != row['Pronoun']:\n",
    "    #                     question_text_replaced.append(w)\n",
    "    #                 else:\n",
    "    #                     question_text_replaced.append(\"question\")\n",
    "    #             question_text = \" \".join(question_text_replaced)\n",
    "    #             break \n",
    "\n",
    "        #question_text = \" \".join(row['Text'][row['Pronoun-offset']:].split(\" \")[:10])\n",
    "        \n",
    "        qas = None\n",
    "        if is_training:\n",
    "            answer_offset = row['A-offset'] if row['A-coref'] else row['B-offset']\n",
    "            answer_text = row['A'] if row['A-coref'] else row['B']\n",
    "            qas = [{'answers': [{'answer_start': answer_offset, 'text': answer_text}], \n",
    "                                 'question': question_text, 'id': str(ObjectId())}]\n",
    "        else:\n",
    "            qas = [{'question': question_text, 'id': str(ObjectId())}]\n",
    "            \n",
    "        json_dict['paragraphs'] = [{'context': row['Text'], 'qas': qas}]\n",
    "        \n",
    "#         context = row['Text']\n",
    "#         url_text = \" \".join(urllib.request.unquote(row['URL'].split(\"/wiki/\")[1]).split(\"_\"))\n",
    "#         if url_text:\n",
    "#             context += \" \" + url_text\n",
    "\n",
    "#         json_dict['paragraphs'] = [{'context': context, 'qas': qas}]\n",
    "\n",
    "        return json_dict \n",
    "        \n",
    "    def convert_examples_to_features(self, examples, tokenizer, max_seq_length,\n",
    "                                 doc_stride, max_query_length, is_training):\n",
    "        \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "\n",
    "        unique_id = 1000000000\n",
    "\n",
    "        features = []\n",
    "        for (example_index, example) in enumerate(examples):\n",
    "            query_tokens = tokenizer.tokenize(example.question_text)\n",
    "\n",
    "            if len(query_tokens) > max_query_length:\n",
    "                query_tokens = query_tokens[0:max_query_length]\n",
    "\n",
    "            tok_to_orig_index = []\n",
    "            orig_to_tok_index = []\n",
    "            all_doc_tokens = []\n",
    "            for (i, token) in enumerate(example.doc_tokens):\n",
    "                orig_to_tok_index.append(len(all_doc_tokens))\n",
    "                sub_tokens = tokenizer.tokenize(token)\n",
    "                for sub_token in sub_tokens:\n",
    "                    tok_to_orig_index.append(i)\n",
    "                    all_doc_tokens.append(sub_token)\n",
    "\n",
    "            tok_start_position = None\n",
    "            tok_end_position = None\n",
    "            if is_training and example.is_impossible:\n",
    "                tok_start_position = -1\n",
    "                tok_end_position = -1\n",
    "            if is_training and not example.is_impossible:\n",
    "                tok_start_position = orig_to_tok_index[example.start_position]\n",
    "                if example.end_position < len(example.doc_tokens) - 1:\n",
    "                    tok_end_position = orig_to_tok_index[example.end_position + 1] - 1\n",
    "                else:\n",
    "                    tok_end_position = len(all_doc_tokens) - 1\n",
    "                (tok_start_position, tok_end_position) = self._improve_answer_span(\n",
    "                    all_doc_tokens, tok_start_position, tok_end_position, tokenizer,\n",
    "                    example.orig_answer_text)\n",
    "\n",
    "            # The -3 accounts for [CLS], [SEP] and [SEP]\n",
    "            max_tokens_for_doc = max_seq_length - len(query_tokens) - 3\n",
    "\n",
    "            # We can have documents that are longer than the maximum sequence length.\n",
    "            # To deal with this we do a sliding window approach, where we take chunks\n",
    "            # of the up to our max length with a stride of `doc_stride`.\n",
    "            _DocSpan = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "                \"DocSpan\", [\"start\", \"length\"])\n",
    "            doc_spans = []\n",
    "            start_offset = 0\n",
    "            while start_offset < len(all_doc_tokens):\n",
    "                length = len(all_doc_tokens) - start_offset\n",
    "                if length > max_tokens_for_doc:\n",
    "                    length = max_tokens_for_doc\n",
    "                doc_spans.append(_DocSpan(start=start_offset, length=length))\n",
    "                if start_offset + length == len(all_doc_tokens):\n",
    "                    break\n",
    "                start_offset += min(length, doc_stride)\n",
    "\n",
    "            for (doc_span_index, doc_span) in enumerate(doc_spans):\n",
    "                tokens = []\n",
    "                token_to_orig_map = {}\n",
    "                token_is_max_context = {}\n",
    "                segment_ids = []\n",
    "                tokens.append(\"[CLS]\")\n",
    "                segment_ids.append(0)\n",
    "                for token in query_tokens:\n",
    "                    tokens.append(token)\n",
    "                    segment_ids.append(0)\n",
    "                tokens.append(\"[SEP]\")\n",
    "                segment_ids.append(0)\n",
    "\n",
    "                for i in range(doc_span.length):\n",
    "                    split_token_index = doc_span.start + i\n",
    "                    token_to_orig_map[len(tokens)] = tok_to_orig_index[split_token_index]\n",
    "\n",
    "                    is_max_context = self._check_is_max_context(doc_spans, doc_span_index,\n",
    "                                                           split_token_index)\n",
    "                    token_is_max_context[len(tokens)] = is_max_context\n",
    "                    tokens.append(all_doc_tokens[split_token_index])\n",
    "                    segment_ids.append(1)\n",
    "                tokens.append(\"[SEP]\")\n",
    "                segment_ids.append(1)\n",
    "\n",
    "                input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "\n",
    "                # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "                # tokens are attended to.\n",
    "                input_mask = [1] * len(input_ids)\n",
    "\n",
    "                # Zero-pad up to the sequence length.\n",
    "                while len(input_ids) < max_seq_length:\n",
    "                    input_ids.append(0)\n",
    "                    input_mask.append(0)\n",
    "                    segment_ids.append(0)\n",
    "\n",
    "                assert len(input_ids) == max_seq_length\n",
    "                assert len(input_mask) == max_seq_length\n",
    "                assert len(segment_ids) == max_seq_length\n",
    "\n",
    "                start_position = None\n",
    "                end_position = None\n",
    "                if is_training and not example.is_impossible:\n",
    "                    # For training, if our document chunk does not contain an annotation\n",
    "                    # we throw it out, since there is nothing to predict.\n",
    "                    doc_start = doc_span.start\n",
    "                    doc_end = doc_span.start + doc_span.length - 1\n",
    "                    out_of_span = False\n",
    "                    if not (tok_start_position >= doc_start and\n",
    "                            tok_end_position <= doc_end):\n",
    "                        out_of_span = True\n",
    "                    if out_of_span:\n",
    "                        start_position = 0\n",
    "                        end_position = 0\n",
    "                    else:\n",
    "                        doc_offset = len(query_tokens) + 2\n",
    "                        start_position = tok_start_position - doc_start + doc_offset\n",
    "                        end_position = tok_end_position - doc_start + doc_offset\n",
    "                if is_training and example.is_impossible:\n",
    "                    start_position = 0\n",
    "                    end_position = 0\n",
    "\n",
    "    #             pronoun_offset += 1\n",
    "    #             pronoun_ids = np.array([3] * (len(segment_ids)))\n",
    "    #             if a_offset < len(pronoun_ids):\n",
    "    #                 n_a_tokens = len(tokenizer.tokenize(example.endings[0]))\n",
    "    #                 pronoun_ids[a_offset: a_offset + n_a_tokens] = 0\n",
    "    #             if b_offset < len(pronoun_ids):\n",
    "    #                 n_b_tokens = len(tokenizer.tokenize(example.endings[1]))\n",
    "    #                 pronoun_ids[b_offset: b_offset + n_b_tokens] = 1\n",
    "\n",
    "    #             #print(f\"ei: {example_index}, po: {pronoun_offset}, pil: {len(pronoun_ids)}\")\n",
    "    #             #print(\"*\" * 50)\n",
    "    #             if pronoun_offset < len(pronoun_ids):\n",
    "    #                 pronoun_ids[pronoun_offset] = 2\n",
    "    #             pronoun_ids = list(pronoun_ids)\n",
    "\n",
    "                if example_index < 20:\n",
    "                    logger.info(\"*** Example ***\")\n",
    "                    logger.info(\"unique_id: %s\" % (unique_id))\n",
    "                    logger.info(\"example_index: %s\" % (example_index))\n",
    "                    logger.info(\"doc_span_index: %s\" % (doc_span_index))\n",
    "                    logger.info(\"tokens: %s\" % \" \".join(tokens))\n",
    "                    logger.info(\"token_to_orig_map: %s\" % \" \".join([\n",
    "                        \"%d:%d\" % (x, y) for (x, y) in token_to_orig_map.items()]))\n",
    "                    logger.info(\"token_is_max_context: %s\" % \" \".join([\n",
    "                        \"%d:%s\" % (x, y) for (x, y) in token_is_max_context.items()\n",
    "                    ]))\n",
    "                    logger.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
    "                    logger.info(\n",
    "                        \"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
    "                    logger.info(\n",
    "                        \"segment_ids: %s\" % \" \".join([str(x) for x in segment_ids]))\n",
    "                    if is_training and example.is_impossible:\n",
    "                        logger.info(\"impossible example\")\n",
    "                    if is_training and not example.is_impossible:\n",
    "                        answer_text = \" \".join(tokens[start_position:(end_position + 1)])\n",
    "                        logger.info(\"start_position: %d\" % (start_position))\n",
    "                        logger.info(\"end_position: %d\" % (end_position))\n",
    "                        logger.info(\n",
    "                            \"answer: %s\" % (answer_text))\n",
    "\n",
    "                features.append(\n",
    "                    SquadInputFeatures(\n",
    "                        unique_id=unique_id,\n",
    "                        example_index=example_index,\n",
    "                        doc_span_index=doc_span_index,\n",
    "                        tokens=tokens,\n",
    "                        token_to_orig_map=token_to_orig_map,\n",
    "                        token_is_max_context=token_is_max_context,\n",
    "                        input_ids=input_ids,\n",
    "                        input_mask=input_mask,\n",
    "                        segment_ids=segment_ids,\n",
    "                        start_position=start_position,\n",
    "                        end_position=end_position,\n",
    "                        is_impossible=example.is_impossible))\n",
    "                unique_id += 1\n",
    "\n",
    "        return features\n",
    "\n",
    "\n",
    "    def _improve_answer_span(self, doc_tokens, input_start, input_end, tokenizer,\n",
    "                             orig_answer_text):\n",
    "        \"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"\n",
    "\n",
    "        # The SQuAD annotations are character based. We first project them to\n",
    "        # whitespace-tokenized words. But then after WordPiece tokenization, we can\n",
    "        # often find a \"better match\". For example:\n",
    "        #\n",
    "        #   Question: What year was John Smith born?\n",
    "        #   Context: The leader was John Smith (1895-1943).\n",
    "        #   Answer: 1895\n",
    "        #\n",
    "        # The original whitespace-tokenized answer will be \"(1895-1943).\". However\n",
    "        # after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match\n",
    "        # the exact answer, 1895.\n",
    "        #\n",
    "        # However, this is not always possible. Consider the following:\n",
    "        #\n",
    "        #   Question: What country is the top exporter of electornics?\n",
    "        #   Context: The Japanese electronics industry is the lagest in the world.\n",
    "        #   Answer: Japan\n",
    "        #\n",
    "        # In this case, the annotator chose \"Japan\" as a character sub-span of\n",
    "        # the word \"Japanese\". Since our WordPiece tokenizer does not split\n",
    "        # \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare\n",
    "        # in SQuAD, but does happen.\n",
    "        tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n",
    "\n",
    "        for new_start in range(input_start, input_end + 1):\n",
    "            for new_end in range(input_end, new_start - 1, -1):\n",
    "                text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n",
    "                if text_span == tok_answer_text:\n",
    "                    return (new_start, new_end)\n",
    "\n",
    "        return (input_start, input_end)\n",
    "\n",
    "\n",
    "    def _check_is_max_context(self, doc_spans, cur_span_index, position):\n",
    "        \"\"\"Check if this is the 'max context' doc span for the token.\"\"\"\n",
    "\n",
    "        # Because of the sliding window approach taken to scoring documents, a single\n",
    "        # token can appear in multiple documents. E.g.\n",
    "        #  Doc: the man went to the store and bought a gallon of milk\n",
    "        #  Span A: the man went to the\n",
    "        #  Span B: to the store and bought\n",
    "        #  Span C: and bought a gallon of\n",
    "        #  ...\n",
    "        #\n",
    "        # Now the word 'bought' will have two scores from spans B and C. We only\n",
    "        # want to consider the score with \"maximum context\", which we define as\n",
    "        # the *minimum* of its left and right context (the *sum* of left and\n",
    "        # right context will always be the same, of course).\n",
    "        #\n",
    "        # In the example the maximum context for 'bought' would be span C since\n",
    "        # it has 1 left context and 3 right context, while span B has 4 left context\n",
    "        # and 0 right context.\n",
    "        best_score = None\n",
    "        best_span_index = None\n",
    "        for (span_index, doc_span) in enumerate(doc_spans):\n",
    "            end = doc_span.start + doc_span.length - 1\n",
    "            if position < doc_span.start:\n",
    "                continue\n",
    "            if position > end:\n",
    "                continue\n",
    "            num_left_context = position - doc_span.start\n",
    "            num_right_context = end - position\n",
    "            score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n",
    "            if best_score is None or score > best_score:\n",
    "                best_score = score\n",
    "                best_span_index = span_index\n",
    "\n",
    "        return cur_span_index == best_span_index\n",
    "\n",
    "\n",
    "    def write_predictions(self, all_examples, all_features, all_results, n_best_size,\n",
    "                          max_answer_length, do_lower_case):\n",
    "        example_index_to_features = collections.defaultdict(list)\n",
    "        for feature in all_features:\n",
    "            example_index_to_features[feature.example_index].append(feature)\n",
    "\n",
    "        unique_id_to_result = {}\n",
    "        for result in all_results:\n",
    "            unique_id_to_result[result.unique_id] = result\n",
    "\n",
    "        _PrelimPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "            \"PrelimPrediction\",\n",
    "            [\"feature_index\", \"start_index\", \"end_index\", \"start_logit\", \"end_logit\"])\n",
    "\n",
    "        all_predictions = collections.OrderedDict()\n",
    "        all_nbest_json = collections.OrderedDict()\n",
    "        scores_diff_json = collections.OrderedDict()\n",
    "\n",
    "        for (example_index, example) in enumerate(all_examples):\n",
    "            features = example_index_to_features[example_index]\n",
    "\n",
    "            prelim_predictions = []\n",
    "            # keep track of the minimum score of null start+end of position 0\n",
    "            score_null = 1000000  # large and positive\n",
    "            min_null_feature_index = 0  # the paragraph slice with min mull score\n",
    "            null_start_logit = 0  # the start logit at the slice with min null score\n",
    "            null_end_logit = 0  # the end logit at the slice with min null score\n",
    "            for (feature_index, feature) in enumerate(features):\n",
    "                result = unique_id_to_result[feature.unique_id]\n",
    "                start_indexes = self._get_best_indexes(result.start_logits, n_best_size)\n",
    "                end_indexes = self._get_best_indexes(result.end_logits, n_best_size)\n",
    "\n",
    "                for start_index in start_indexes:\n",
    "                    for end_index in end_indexes:\n",
    "                        # We could hypothetically create invalid predictions, e.g., predict\n",
    "                        # that the start of the span is in the question. We throw out all\n",
    "                        # invalid predictions.\n",
    "                        if start_index >= len(feature.tokens):\n",
    "                            continue\n",
    "                        if end_index >= len(feature.tokens):\n",
    "                            continue\n",
    "                        if start_index not in feature.token_to_orig_map:\n",
    "                            continue\n",
    "                        if end_index not in feature.token_to_orig_map:\n",
    "                            continue\n",
    "                        if not feature.token_is_max_context.get(start_index, False):\n",
    "                            continue\n",
    "                        if end_index < start_index:\n",
    "                            continue\n",
    "                        length = end_index - start_index + 1\n",
    "                        if length > max_answer_length:\n",
    "                            continue\n",
    "                        prelim_predictions.append(\n",
    "                            _PrelimPrediction(\n",
    "                                feature_index=feature_index,\n",
    "                                start_index=start_index,\n",
    "                                end_index=end_index,\n",
    "                                start_logit=result.start_logits[start_index],\n",
    "                                end_logit=result.end_logits[end_index]))\n",
    "            prelim_predictions = sorted(\n",
    "                prelim_predictions,\n",
    "                key=lambda x: (x.start_logit + x.end_logit),\n",
    "                reverse=True)\n",
    "\n",
    "            _NbestPrediction = collections.namedtuple(  # pylint: disable=invalid-name\n",
    "                \"NbestPrediction\", [\"text\", \"start_logit\", \"end_logit\"])\n",
    "\n",
    "            seen_predictions = {}\n",
    "            nbest = []\n",
    "            for pred in prelim_predictions:\n",
    "                if len(nbest) >= n_best_size:\n",
    "                    break\n",
    "                feature = features[pred.feature_index]\n",
    "                if pred.start_index > 0:  # this is a non-null prediction\n",
    "                    tok_tokens = feature.tokens[pred.start_index:(pred.end_index + 1)]\n",
    "                    orig_doc_start = feature.token_to_orig_map[pred.start_index]\n",
    "                    orig_doc_end = feature.token_to_orig_map[pred.end_index]\n",
    "                    orig_tokens = example.doc_tokens[orig_doc_start:(orig_doc_end + 1)]\n",
    "                    tok_text = \" \".join(tok_tokens)\n",
    "\n",
    "                    # De-tokenize WordPieces that have been split off.\n",
    "                    tok_text = tok_text.replace(\" ##\", \"\")\n",
    "                    tok_text = tok_text.replace(\"##\", \"\")\n",
    "\n",
    "                    # Clean whitespace\n",
    "                    tok_text = tok_text.strip()\n",
    "                    tok_text = \" \".join(tok_text.split())\n",
    "                    orig_text = \" \".join(orig_tokens)\n",
    "\n",
    "                    final_text = self.get_final_text(tok_text, orig_text, do_lower_case, verbose_logging=False)\n",
    "                    if final_text in seen_predictions:\n",
    "                        continue\n",
    "\n",
    "                    seen_predictions[final_text] = True\n",
    "                else:\n",
    "                    final_text = \"\"\n",
    "                    seen_predictions[final_text] = True\n",
    "\n",
    "                nbest.append(\n",
    "                    _NbestPrediction(\n",
    "                        text=final_text,\n",
    "                        start_logit=pred.start_logit,\n",
    "                        end_logit=pred.end_logit))\n",
    "\n",
    "            # In very rare edge cases we could have no valid predictions. So we\n",
    "            # just create a nonce prediction in this case to avoid failure.\n",
    "            if not nbest:\n",
    "                nbest.append(\n",
    "                    _NbestPrediction(text=\"empty\", start_logit=0.0, end_logit=0.0))\n",
    "\n",
    "            assert len(nbest) >= 1\n",
    "\n",
    "            total_scores = []\n",
    "            best_non_null_entry = None\n",
    "            for entry in nbest:\n",
    "                total_scores.append(entry.start_logit + entry.end_logit)\n",
    "                if not best_non_null_entry:\n",
    "                    if entry.text:\n",
    "                        best_non_null_entry = entry\n",
    "\n",
    "            probs = self._compute_softmax(total_scores)\n",
    "\n",
    "            nbest_json = []\n",
    "            for (i, entry) in enumerate(nbest):\n",
    "                output = collections.OrderedDict()\n",
    "                output[\"text\"] = entry.text\n",
    "                output[\"probability\"] = probs[i]\n",
    "                output[\"start_logit\"] = entry.start_logit\n",
    "                output[\"end_logit\"] = entry.end_logit\n",
    "                nbest_json.append(output)\n",
    "\n",
    "            assert len(nbest_json) >= 1\n",
    "\n",
    "            all_predictions[example.qas_id] = nbest_json[0][\"text\"]\n",
    "\n",
    "\n",
    "        return all_predictions, all_nbest_json\n",
    "\n",
    "\n",
    "    def get_final_text(self, pred_text, orig_text, do_lower_case, verbose_logging=False):\n",
    "        \"\"\"Project the tokenized prediction back to the original text.\"\"\"\n",
    "\n",
    "        # When we created the data, we kept track of the alignment between original\n",
    "        # (whitespace tokenized) tokens and our WordPiece tokenized tokens. So\n",
    "        # now `orig_text` contains the span of our original text corresponding to the\n",
    "        # span that we predicted.\n",
    "        #\n",
    "        # However, `orig_text` may contain extra characters that we don't want in\n",
    "        # our prediction.\n",
    "        #\n",
    "        # For example, let's say:\n",
    "        #   pred_text = steve smith\n",
    "        #   orig_text = Steve Smith's\n",
    "        #\n",
    "        # We don't want to return `orig_text` because it contains the extra \"'s\".\n",
    "        #\n",
    "        # We don't want to return `pred_text` because it's already been normalized\n",
    "        # (the SQuAD eval script also does punctuation stripping/lower casing but\n",
    "        # our tokenizer does additional normalization like stripping accent\n",
    "        # characters).\n",
    "        #\n",
    "        # What we really want to return is \"Steve Smith\".\n",
    "        #\n",
    "        # Therefore, we have to apply a semi-complicated alignment heruistic between\n",
    "        # `pred_text` and `orig_text` to get a character-to-charcter alignment. This\n",
    "        # can fail in certain cases in which case we just return `orig_text`.\n",
    "\n",
    "        def _strip_spaces(text):\n",
    "            ns_chars = []\n",
    "            ns_to_s_map = collections.OrderedDict()\n",
    "            for (i, c) in enumerate(text):\n",
    "                if c == \" \":\n",
    "                    continue\n",
    "                ns_to_s_map[len(ns_chars)] = i\n",
    "                ns_chars.append(c)\n",
    "            ns_text = \"\".join(ns_chars)\n",
    "            return (ns_text, ns_to_s_map)\n",
    "\n",
    "        # We first tokenize `orig_text`, strip whitespace from the result\n",
    "        # and `pred_text`, and check if they are the same length. If they are\n",
    "        # NOT the same length, the heuristic has failed. If they are the same\n",
    "        # length, we assume the characters are one-to-one aligned.\n",
    "        tokenizer = BasicTokenizer(do_lower_case=do_lower_case)\n",
    "\n",
    "        tok_text = \" \".join(tokenizer.tokenize(orig_text))\n",
    "\n",
    "        start_position = tok_text.find(pred_text)\n",
    "        if start_position == -1:\n",
    "            if verbose_logging:\n",
    "                logger.info(\n",
    "                    \"Unable to find text: '%s' in '%s'\" % (pred_text, orig_text))\n",
    "            return orig_text\n",
    "        end_position = start_position + len(pred_text) - 1\n",
    "\n",
    "        (orig_ns_text, orig_ns_to_s_map) = _strip_spaces(orig_text)\n",
    "        (tok_ns_text, tok_ns_to_s_map) = _strip_spaces(tok_text)\n",
    "\n",
    "        if len(orig_ns_text) != len(tok_ns_text):\n",
    "            if verbose_logging:\n",
    "                logger.info(\"Length not equal after stripping spaces: '%s' vs '%s'\",\n",
    "                            orig_ns_text, tok_ns_text)\n",
    "            return orig_text\n",
    "\n",
    "        # We then project the characters in `pred_text` back to `orig_text` using\n",
    "        # the character-to-character alignment.\n",
    "        tok_s_to_ns_map = {}\n",
    "        for (i, tok_index) in tok_ns_to_s_map.items():\n",
    "            tok_s_to_ns_map[tok_index] = i\n",
    "\n",
    "        orig_start_position = None\n",
    "        if start_position in tok_s_to_ns_map:\n",
    "            ns_start_position = tok_s_to_ns_map[start_position]\n",
    "            if ns_start_position in orig_ns_to_s_map:\n",
    "                orig_start_position = orig_ns_to_s_map[ns_start_position]\n",
    "\n",
    "        if orig_start_position is None:\n",
    "            if verbose_logging:\n",
    "                logger.info(\"Couldn't map start position\")\n",
    "            return orig_text\n",
    "\n",
    "        orig_end_position = None\n",
    "        if end_position in tok_s_to_ns_map:\n",
    "            ns_end_position = tok_s_to_ns_map[end_position]\n",
    "            if ns_end_position in orig_ns_to_s_map:\n",
    "                orig_end_position = orig_ns_to_s_map[ns_end_position]\n",
    "\n",
    "        if orig_end_position is None:\n",
    "            if verbose_logging:\n",
    "                logger.info(\"Couldn't map end position\")\n",
    "            return orig_text\n",
    "\n",
    "        output_text = orig_text[orig_start_position:(orig_end_position + 1)]\n",
    "        return output_text\n",
    "\n",
    "\n",
    "    def _get_best_indexes(self, logits, n_best_size):\n",
    "        \"\"\"Get the n-best logits from a list.\"\"\"\n",
    "        index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        best_indexes = []\n",
    "        for i in range(len(index_and_score)):\n",
    "            if i >= n_best_size:\n",
    "                break\n",
    "            best_indexes.append(index_and_score[i][0])\n",
    "        return best_indexes\n",
    "\n",
    "\n",
    "    def _compute_softmax(self, scores):\n",
    "        \"\"\"Compute softmax probability over raw logits.\"\"\"\n",
    "        if not scores:\n",
    "            return []\n",
    "\n",
    "        max_score = None\n",
    "        for score in scores:\n",
    "            if max_score is None or score > max_score:\n",
    "                max_score = score\n",
    "\n",
    "        exp_scores = []\n",
    "        total_sum = 0.0\n",
    "        for score in scores:\n",
    "            x = math.exp(score - max_score)\n",
    "            exp_scores.append(x)\n",
    "            total_sum += x\n",
    "\n",
    "        probs = []\n",
    "        for score in exp_scores:\n",
    "            probs.append(score / total_sum)\n",
    "        return probs\n",
    "    \n",
    "    def evaluate(self, model, eval_examples, eval_features):\n",
    "        logger.info(\"***** Running predictions *****\")\n",
    "        #logger.info(\"  Num orig examples = %d\", len(eval_examples))\n",
    "        logger.info(\"  Num split examples = %d\", len(eval_features))\n",
    "        logger.info(\"  Batch size = %d\", self.predict_batch_size)\n",
    "\n",
    "        all_input_ids = torch.tensor([f.input_ids for f in eval_features], dtype=torch.long)\n",
    "        all_input_mask = torch.tensor([f.input_mask for f in eval_features], dtype=torch.long)\n",
    "        all_segment_ids = torch.tensor([f.segment_ids for f in eval_features], dtype=torch.long)\n",
    "        all_example_index = torch.arange(all_input_ids.size(0), dtype=torch.long)\n",
    "        eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_example_index)\n",
    "        # Run prediction for full data\n",
    "        eval_sampler = SequentialSampler(eval_data)\n",
    "        eval_dataloader = DataLoader(eval_data, sampler=eval_sampler, batch_size=self.predict_batch_size)\n",
    "\n",
    "        model.eval()\n",
    "        all_results = []\n",
    "        logger.info(\"Start evaluating\")\n",
    "        for input_ids, input_mask, segment_ids, example_indices in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "            if len(all_results) % 1000 == 0:\n",
    "                logger.info(\"Processing example: %d\" % (len(all_results)))\n",
    "            input_ids = input_ids.to(self.device)\n",
    "            input_mask = input_mask.to(self.device)\n",
    "            segment_ids = segment_ids.to(self.device)\n",
    "            with torch.no_grad():\n",
    "                batch_start_logits, batch_end_logits = model(input_ids, segment_ids, input_mask)\n",
    "            for i, example_index in enumerate(example_indices):\n",
    "                start_logits = batch_start_logits[i].detach().cpu().tolist()\n",
    "                end_logits = batch_end_logits[i].detach().cpu().tolist()\n",
    "                eval_feature = eval_features[example_index.item()]\n",
    "                unique_id = int(eval_feature.unique_id)\n",
    "                all_results.append(SquadRawResult(unique_id=unique_id,\n",
    "                                             start_logits=start_logits,\n",
    "                                             end_logits=end_logits))\n",
    "\n",
    "        all_predictions, all_nbest_json = self.write_predictions(eval_examples, eval_features, all_results,\n",
    "                          self.n_best_size, self.max_answer_length,\n",
    "                          self.do_lower_case)\n",
    "\n",
    "        return all_predictions, all_results\n",
    "    \n",
    "    def get_class_label(self, a_coref, b_coref):\n",
    "        if a_coref:\n",
    "            return 0\n",
    "        elif b_coref:\n",
    "            return 1\n",
    "        return 2\n",
    "    \n",
    "    def get_start_end_logit(self, example, feature, result, text, offset):\n",
    "        of = 0\n",
    "        orig_tok_idx_start = 0\n",
    "        for t in example.doc_tokens:\n",
    "            of += len(t) + 1\n",
    "            if of > offset:\n",
    "                break\n",
    "            orig_tok_idx_start += 1\n",
    "\n",
    "        orig_tok_idx_end = orig_tok_idx_start + len(whitespace_tokenize(text)) - 1\n",
    "\n",
    "        #print(f\"offset, orig_tok_idx_start, orig_tok_idx_end: {offset} {orig_tok_idx_start}, {orig_tok_idx_end}\")\n",
    "\n",
    "        start_logit = -100 #result.start_logits[0]\n",
    "        end_logit = -100 #result.end_logits[0]\n",
    "\n",
    "        for feat_idx, orig_idx in feature.token_to_orig_map.items():\n",
    "            if orig_idx >= orig_tok_idx_start and orig_idx <= orig_tok_idx_end:\n",
    "                start_logit = max(start_logit, result.start_logits[feat_idx])\n",
    "                end_logit = max(end_logit, result.end_logits[feat_idx])\n",
    "        return start_logit, end_logit\n",
    "\n",
    "    def build_a_b_logits(self, examples, features, results, predictions, a_texts, b_texts, a_offsets, b_offsets):\n",
    "        logits = {}\n",
    "        for feature, result in zip(features, results):\n",
    "            a_b_logit = []\n",
    "            \n",
    "            example = examples[feature.example_index]\n",
    "            a_text = a_texts[feature.example_index]\n",
    "            a_offset = a_offsets[feature.example_index]\n",
    "            b_text =b_texts[feature.example_index]\n",
    "            b_offset = b_offsets[feature.example_index]\n",
    "\n",
    "\n",
    "            a_start_logit, a_end_logit = self.get_start_end_logit(example, feature, result, a_text, a_offset)\n",
    "            b_start_logit, b_end_logit = self.get_start_end_logit(example, feature, result, b_text, b_offset)\n",
    "            max_start_logit = max(result.start_logits)\n",
    "            max_end_logit = max(result.end_logits)\n",
    "\n",
    "            if feature.example_index in logits:\n",
    "                a_start_logit = max(a_start_logit, logits[feature.example_index][0])\n",
    "                a_end_logit = max(a_end_logit, logits[feature.example_index][1])\n",
    "                b_start_logit = max(b_start_logit, logits[feature.example_index][2])\n",
    "                b_end_logit = max(b_end_logit, logits[feature.example_index][3])\n",
    "                max_start_logit = max(max_start_logit, logits[feature.example_index][4])\n",
    "                max_end_logit = max(max_end_logit, logits[feature.example_index][5])\n",
    "\n",
    "            a_b_logit.append(a_start_logit)\n",
    "            a_b_logit.append(a_end_logit)\n",
    "            a_b_logit.append(b_start_logit)\n",
    "            a_b_logit.append(b_end_logit)\n",
    "            a_b_logit.append(max_start_logit)\n",
    "            a_b_logit.append(max_end_logit)\n",
    "\n",
    "            prediction = predictions[example.qas_id]\n",
    "\n",
    "            if prediction.lower() in a_text.lower() or a_text.lower() in prediction.lower():\n",
    "                a_b_logit.append(0.)\n",
    "            elif prediction.lower() in b_text.lower() or b_text.lower() in prediction.lower():\n",
    "                a_b_logit.append(1.)\n",
    "            else:\n",
    "                a_b_logit.append(2.)\n",
    "\n",
    "            logits[feature.example_index] = a_b_logit\n",
    "\n",
    "        #return [[k[0] / k[4], k[1] / k[5], k[2] / k[4], k[3] / k[5]] for k in list(logits.values())]\n",
    "\n",
    "        #return [k[0:4] + [k[6]] for k in list(logits.values())]\n",
    "        #return list(logits.values()), [[k[-1]] for k in list(logits.values())]\n",
    "        return list(logits.values())\n",
    "    \n",
    "    def run_k_fold(self):\n",
    "        kfold_data = pd.concat([self.dev_df, self.val_df])\n",
    "        kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        test_squad_format = self.test_df.apply(lambda x: self.row_to_squad_example(x, False), axis=1).tolist()\n",
    "        test_examples = self.read_squad_examples_from_data(test_squad_format, False, False)\n",
    "        test_features = self.convert_examples_to_features(\n",
    "                    examples=test_examples,\n",
    "                    tokenizer=self.tokenizer,\n",
    "                    max_seq_length=self.max_seq_length,\n",
    "                    doc_stride=self.doc_stride,\n",
    "                    max_query_length=self.max_query_length,\n",
    "                    is_training=False)\n",
    "        val_preds, test_preds, val_losses = [], [], []\n",
    "        for train_index, valid_index in kf.split(kfold_data, kfold_data[\"gender\"]):\n",
    "            print(\"=\" * 20)\n",
    "            print(f\"Fold {len(val_preds) + 1}\")\n",
    "            print(\"=\" * 20)\n",
    "            kf_train_unfiltered = kfold_data.iloc[train_index]\n",
    "            kf_val_unfiltered = kfold_data.iloc[valid_index]\n",
    "            kf_train = kf_train_unfiltered[kf_train_unfiltered['A-coref'] | kf_train_unfiltered['B-coref']]\n",
    "            kf_val = kf_val_unfiltered[kf_val_unfiltered['A-coref'] | kf_val_unfiltered['B-coref']]\n",
    "\n",
    "            train_squad = kf_train.apply(lambda x: self.row_to_squad_example(x, True), axis=1).tolist()\n",
    "            val_squad = kf_val.apply(lambda x: self.row_to_squad_example(x, True), axis=1).tolist()\n",
    "            train_examples = self.read_squad_examples_from_data(train_squad, True, False)\n",
    "            val_examples = self.read_squad_examples_from_data(val_squad, False, False)\n",
    "\n",
    "            num_train_optimization_steps = int(\n",
    "                len(train_examples) / self.train_batch_size / self.gradient_accumulation_steps) * self.num_train_epochs\n",
    "\n",
    "            # Prepare model\n",
    "            model = BertForQuestionAnswering.from_pretrained(self.bert_model,\n",
    "                        cache_dir=os.path.join(PYTORCH_PRETRAINED_BERT_CACHE, 'distributed_{}'.format(self.local_rank)))\n",
    "\n",
    "            # Freeze some weights\n",
    "            model_children = list(model.children())\n",
    "            bert_layers = list(model_children[0].children())\n",
    "            bert_embeddings, bert_encoder, bert_pooler = bert_layers\n",
    "\n",
    "            for param in bert_embeddings.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            for child in list(bert_encoder.children())[0][:-12]:\n",
    "                for param in child.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            # for param in bert_pooler.parameters():\n",
    "            #     param.requires_grad = False\n",
    "\n",
    "            total_params = sum(p.numel() for p in model.parameters())\n",
    "\n",
    "            total_trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "            print(f\"Total parameters: {total_params}, trainable parameters: {total_trainable_params}\")\n",
    "\n",
    "            model.to(self.device)\n",
    "            model = torch.nn.DataParallel(model)\n",
    "\n",
    "            # Prepare optimizer\n",
    "            param_optimizer = list(model.named_parameters())\n",
    "\n",
    "            # hack to remove pooler, which is not used\n",
    "            # thus it produce None grad that break apex\n",
    "            param_optimizer = [n for n in param_optimizer if 'pooler' not in n[0]]\n",
    "\n",
    "            no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "            optimizer_grouped_parameters = [\n",
    "                {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "                {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "                ]\n",
    "\n",
    "            optimizer = BertAdam(optimizer_grouped_parameters,\n",
    "                                 lr=self.learning_rate,\n",
    "                                 warmup=self.warmup_proportion,\n",
    "                                 t_total=num_train_optimization_steps)\n",
    "\n",
    "            global_step = 0\n",
    "\n",
    "            train_features = self.convert_examples_to_features(\n",
    "                examples=train_examples,\n",
    "                tokenizer=self.tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                doc_stride=self.doc_stride,\n",
    "                max_query_length=self.max_query_length,\n",
    "                is_training=True)\n",
    "\n",
    "            logger.info(\"***** Running training *****\")\n",
    "            logger.info(\"  Num orig examples = %d\", len(train_examples))\n",
    "            logger.info(\"  Num split examples = %d\", len(train_features))\n",
    "            logger.info(\"  Batch size = %d\", self.train_batch_size)\n",
    "            logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
    "            all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
    "            all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
    "            all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
    "            all_start_positions = torch.tensor([f.start_position for f in train_features], dtype=torch.long)\n",
    "            all_end_positions = torch.tensor([f.end_position for f in train_features], dtype=torch.long)\n",
    "            train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids,\n",
    "                                       all_start_positions, all_end_positions)\n",
    "            train_sampler = RandomSampler(train_data)\n",
    "            train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=self.train_batch_size)\n",
    "\n",
    "            model.train()\n",
    "            for _ in trange(int(self.num_train_epochs), desc=\"Epoch\"):\n",
    "                for step, batch in enumerate(tqdm(train_dataloader, desc=\"Iteration\")):\n",
    "                    batch = tuple(t.to(self.device) for t in batch) # multi-gpu does scattering it-self\n",
    "                    input_ids, input_mask, segment_ids, start_positions, end_positions = batch\n",
    "                    loss = model(input_ids, segment_ids, input_mask, start_positions, end_positions)\n",
    "\n",
    "                    if self.gradient_accumulation_steps > 1:\n",
    "                        loss = loss / gradient_accumulation_steps\n",
    "                    print(f\"loss: {loss}\")\n",
    "                    loss.backward()\n",
    "                    if (step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                        optimizer.step()\n",
    "                        optimizer.zero_grad()\n",
    "                        global_step += 1\n",
    "                        \n",
    "            model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
    "            # If we save using the predefined names, we can load using `from_pretrained`\n",
    "            output_model_file = os.path.join('.', WEIGHTS_NAME)\n",
    "            output_config_file = os.path.join('.', CONFIG_NAME)\n",
    "\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "            model_to_save.config.to_json_file(output_config_file)\n",
    "            self.tokenizer.save_vocabulary('.')\n",
    "\n",
    "            train_squad_unfiltered = kf_train_unfiltered.apply(lambda x: self.row_to_squad_example(x, True), axis=1).tolist()\n",
    "            val_squad_unfiltered = kf_val_unfiltered.apply(lambda x: self.row_to_squad_example(x, True), axis=1).tolist()\n",
    "            train_examples_unfiltered = self.read_squad_examples_from_data(train_squad_unfiltered, True, False)\n",
    "            val_examples_unfiltered = self.read_squad_examples_from_data(val_squad_unfiltered, False, False)\n",
    "\n",
    "            train_features_unfiltered = self.convert_examples_to_features(\n",
    "                examples=train_examples_unfiltered,\n",
    "                tokenizer=self.tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                doc_stride=self.doc_stride,\n",
    "                max_query_length=self.max_query_length,\n",
    "                is_training=False)\n",
    "            val_features_unfiltered = self.convert_examples_to_features(\n",
    "                examples=val_examples_unfiltered,\n",
    "                tokenizer=self.tokenizer,\n",
    "                max_seq_length=self.max_seq_length,\n",
    "                doc_stride=self.doc_stride,\n",
    "                max_query_length=self.max_query_length,\n",
    "                is_training=False)\n",
    "\n",
    "            # Train logits\n",
    "            train_predictions, train_results = self.evaluate(model, train_examples_unfiltered, train_features_unfiltered)\n",
    "\n",
    "            # Val logits\n",
    "            val_predictions, val_results = self.evaluate(model, val_examples_unfiltered, val_features_unfiltered)\n",
    "\n",
    "            # Test logits\n",
    "            test_predictions, test_results = self.evaluate(model, test_examples, test_features)\n",
    "\n",
    "            train_a_b_logits = self.build_a_b_logits(train_examples_unfiltered, train_features_unfiltered, train_results, train_predictions, kf_train_unfiltered['A'].tolist(),\n",
    "                    kf_train_unfiltered['B'].tolist(), kf_train_unfiltered['A-offset'].tolist(), kf_train_unfiltered['B-offset'].tolist())\n",
    "            val_a_b_logits = self.build_a_b_logits(val_examples_unfiltered, val_features_unfiltered, val_results, val_predictions, kf_val_unfiltered['A'].tolist(),\n",
    "                            kf_val_unfiltered['B'].tolist(), kf_val_unfiltered['A-offset'].tolist(), kf_val_unfiltered['B-offset'].tolist())\n",
    "            test_a_b_logits = self.build_a_b_logits(test_examples, test_features, test_results, test_predictions, self.test_df['A'].tolist(),\n",
    "                            self.test_df['B'].tolist(), self.test_df['A-offset'].tolist(), self.test_df['B-offset'].tolist())\n",
    "\n",
    "            scaler = StandardScaler().fit(train_a_b_logits)\n",
    "\n",
    "            train_a_b_logits_scaled = scaler.transform(train_a_b_logits)\n",
    "            val_a_b_logits_scaled = scaler.transform(val_a_b_logits)\n",
    "            test_a_b_logits_scaled = scaler.transform(test_a_b_logits)\n",
    "\n",
    "            train_class_labels = [self.get_class_label(aco, bco) for aco, bco in zip(kf_train_unfiltered['A-coref'], kf_train_unfiltered['B-coref'])]\n",
    "            val_class_labels = [self.get_class_label(aco, bco) for aco, bco in zip(kf_val_unfiltered['A-coref'], kf_val_unfiltered['B-coref'])]\n",
    "\n",
    "            logreg = LogisticRegression(C=0.1)#xgb.XGBClassifier()\n",
    "            logreg.fit(np.array(train_a_b_logits_scaled), train_class_labels)\n",
    "\n",
    "            val_logreg_probas = logreg.predict_proba(val_a_b_logits_scaled)\n",
    "            test_logreg_probas = logreg.predict_proba(test_a_b_logits_scaled)\n",
    "\n",
    "            val_preds.append(val_logreg_probas)\n",
    "            val_losses.append(log_loss(val_class_labels, val_logreg_probas))\n",
    "            logger.info(\"Confirm val loss: %.4f\", val_losses[-1])\n",
    "            test_preds.append(test_logreg_probas)\n",
    "\n",
    "            del model\n",
    "            \n",
    "            break\n",
    "            \n",
    "        return val_preds, test_preds, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2019 16:43:43 - INFO - __main__ -   device: cuda distributed training: False, 16-bits training: False\n",
      "05/02/2019 16:43:43 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt not found in cache, downloading to /tmp/tmp6l9cr8cp\n",
      "100%|██████████| 231508/231508 [00:00<00:00, 2114450.62B/s]\n",
      "05/02/2019 16:43:43 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp6l9cr8cp to cache at /tmp/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/02/2019 16:43:43 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /tmp/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "05/02/2019 16:43:43 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp6l9cr8cp\n",
      "05/02/2019 16:43:43 - INFO - pytorch_pretrained_bert.tokenization -   loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt from cache at /tmp/.pytorch_pretrained_bert/9b3c03a36e83b13d5ba95ac965c9f9074a99e14340c523ab405703179e79fc46.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "squad_runner = SquadRunner(dev_df, val_df, test_df_prod, train_batch_size=12, num_train_epochs=2, do_lower_case=True)\n",
    "#squad_runner = SquadRunner(dev_df.iloc[:50], val_df, test_df_prod.iloc[:50], train_batch_size=12, num_train_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000000\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] dumped her boyfriend following simon ' s [SEP] zoe tel ##ford - - played the police officer girlfriend of simon , maggie . dumped by simon in the final episode of series 1 , after he slept with jenny , and is not seen again . phoebe thomas played cheryl cassidy , pauline ' s friend and also a year 11 pupil in simon ' s class . dumped her boyfriend following simon ' s advice after he wouldn ' t have sex with her but later realised this was due to him catching crabs off her friend pauline . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:1 12:2 13:2 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:9 22:10 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:20 35:21 36:22 37:23 38:24 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:32 49:33 50:34 51:35 52:35 53:36 54:36 55:36 56:37 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:45 66:45 67:46 68:46 69:47 70:48 71:49 72:50 73:51 74:51 75:51 76:52 77:53 78:54 79:55 80:55 81:55 82:56 83:57 84:58 85:59 86:60 87:61 88:62 89:63 90:64 91:65 92:66 93:67 94:68 95:69 96:70 97:71 98:72 99:73 100:73\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 14019 2014 6898 2206 4079 1005 1055 102 11199 10093 3877 1011 1011 2209 1996 2610 2961 6513 1997 4079 1010 8538 1012 14019 2011 4079 1999 1996 2345 2792 1997 2186 1015 1010 2044 2002 7771 2007 8437 1010 1998 2003 2025 2464 2153 1012 18188 2726 2209 19431 13737 1010 15595 1005 1055 2767 1998 2036 1037 2095 2340 11136 1999 4079 1005 1055 2465 1012 14019 2014 6898 2206 4079 1005 1055 6040 2044 2002 2876 1005 1056 2031 3348 2007 2014 2021 2101 11323 2023 2001 2349 2000 2032 9105 26076 2125 2014 2767 15595 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000001\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 1\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] 1952 . his simple , wheel - thrown functional [SEP] he grew up in evans ##ton , illinois the second oldest of five children including his brothers , fred and gordon and sisters , marge ( pep ##py ) and marilyn . his high school days were spent at new trier high school in win ##net ##ka , illinois . mackenzie studied with bernard leach from 1949 to 1952 . his simple , wheel - thrown functional pottery is heavily influenced by the oriental aesthetic of sho ##ji ham ##ada and kan ##ji ##ro ka ##wai . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:4 17:4 18:5 19:6 20:7 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:14 29:15 30:16 31:17 32:18 33:19 34:19 35:20 36:21 37:21 38:21 39:21 40:22 41:23 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:36 57:36 58:36 59:37 60:37 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:46 71:47 72:48 73:48 74:49 75:49 76:49 77:50 78:51 79:52 80:53 81:54 82:55 83:56 84:57 85:58 86:59 87:60 88:60 89:61 90:61 91:62 92:63 93:63 94:63 95:64 96:64 97:64\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 3999 1012 2010 3722 1010 5217 1011 6908 8360 102 2002 3473 2039 1999 6473 2669 1010 4307 1996 2117 4587 1997 2274 2336 2164 2010 3428 1010 5965 1998 5146 1998 5208 1010 25532 1006 27233 7685 1007 1998 14749 1012 2010 2152 2082 2420 2020 2985 2012 2047 25487 2152 2082 1999 2663 7159 2912 1010 4307 1012 11407 3273 2007 6795 24520 2013 4085 2000 3999 1012 2010 3722 1010 5217 1011 6908 8360 11378 2003 4600 5105 2011 1996 11481 12465 1997 26822 4478 10654 8447 1998 22827 4478 3217 10556 21547 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000002\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 2\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] of his support within the [SEP] he had been reelected to congress , but resigned in 1990 to accept a post as ambassador to brazil . de la so ##ta again ran for governor of c * rd ##ob ##a in 1991 . defeated by governor angelo ##z by over 15 % , this latter set ##back was significant because it cost de la so ##ta much of his support within the just ##icia ##list party ( which was flush with victory in the 1991 mid - terms ) , leading to president carlos men ##em ' s endorsement of a separate party list in c * rd ##ob ##a for the 1993 mid - term elections , and to de la so ##ta ' s failure to regain a seat in congress . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:17 26:17 27:18 28:19 29:20 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:26 38:26 39:26 40:26 41:27 42:28 43:28 44:29 45:30 46:31 47:32 48:32 49:33 50:34 51:35 52:35 53:35 54:36 55:37 56:38 57:38 58:39 59:40 60:41 61:42 62:43 63:44 64:45 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:53 76:54 77:55 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:63 87:63 88:63 89:63 90:63 91:64 92:65 93:66 94:67 95:68 96:68 97:69 98:69 99:70 100:71 101:72 102:73 103:74 104:75 105:76 106:77 107:77 108:77 109:77 110:77 111:78 112:79 113:80 114:81 115:81 116:81 117:82 118:82 119:83 120:84 121:85 122:86 123:87 124:87 125:87 126:87 127:88 128:89 129:90 130:91 131:92 132:93 133:94 134:94\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 1997 2010 2490 2306 1996 102 2002 2018 2042 20847 2000 3519 1010 2021 5295 1999 2901 2000 5138 1037 2695 2004 6059 2000 4380 1012 2139 2474 2061 2696 2153 2743 2005 3099 1997 1039 1008 16428 16429 2050 1999 2889 1012 3249 2011 3099 12262 2480 2011 2058 2321 1003 1010 2023 3732 2275 5963 2001 3278 2138 2009 3465 2139 2474 2061 2696 2172 1997 2010 2490 2306 1996 2074 24108 9863 2283 1006 2029 2001 13862 2007 3377 1999 1996 2889 3054 1011 3408 1007 1010 2877 2000 2343 5828 2273 6633 1005 1055 20380 1997 1037 3584 2283 2862 1999 1039 1008 16428 16429 2050 2005 1996 2857 3054 1011 2744 3864 1010 1998 2000 2139 2474 2061 2696 1005 1055 4945 2000 12452 1037 2835 1999 3519 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000003\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 3\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] ( under his real name , henry [SEP] the current members of crime have also performed in san francisco under the band name ' ' remote viewers ` ` . strike has published two works of fiction in recent years : ports of hell , which is listed in the rock and roll hall of fame library , and a loud humming sound came from above . rank has produced numerous films ( under his real name , henry rosenthal ) including the hit the devil and daniel johnston . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:15 26:15 27:16 28:16 29:16 30:16 31:17 32:18 33:19 34:20 35:21 36:22 37:23 38:24 39:25 40:26 41:26 42:27 43:28 44:29 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:41 59:42 60:43 61:44 62:45 63:46 64:47 65:48 66:49 67:49 68:50 69:51 70:52 71:53 72:54 73:55 74:55 75:56 76:57 77:58 78:58 79:59 80:60 81:60 82:61 83:62 84:63 85:64 86:65 87:66 88:67 89:68 90:68\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 1006 2104 2010 2613 2171 1010 2888 102 1996 2783 2372 1997 4126 2031 2036 2864 1999 2624 3799 2104 1996 2316 2171 1005 1005 6556 7193 1036 1036 1012 4894 2038 2405 2048 2573 1997 4349 1999 3522 2086 1024 8831 1997 3109 1010 2029 2003 3205 1999 1996 2600 1998 4897 2534 1997 4476 3075 1010 1998 1037 5189 20364 2614 2234 2013 2682 1012 4635 2038 2550 3365 3152 1006 2104 2010 2613 2171 1010 2888 29062 1007 2164 1996 2718 1996 6548 1998 3817 10773 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000004\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 4\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] 2007 . she has since sung [SEP] her santa fe opera debut in 2005 was as nur ##ia in the revised edition of go ##li ##jo ##v ' s ain ##ada ##mar . she sang on the subsequent deutsche gram ##mo ##phon recording of the opera . for his opera doctor atomic , adams re ##wr ##ote the role of kitty op ##pen ##heimer , originally a me ##zzo - soprano role , for soprano voice , and rivera sang the re ##written part of kitty op ##pen ##heimer at lyric opera of chicago , de ned ##erland ##se opera , and the metropolitan opera . , all in 2007 . she has since sung several parts and roles in john adams ' works , including the soprano part in el ni * o , and the role of ku ##mu ##dha in a flowering tree in the peter sell ##ars production at the new crowned hope festival in vienna . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:15 26:15 27:15 28:15 29:15 30:16 31:16 32:16 33:16 34:17 35:18 36:19 37:20 38:21 39:22 40:23 41:23 42:23 43:24 44:25 45:26 46:27 47:27 48:28 49:29 50:30 51:31 52:32 53:32 54:33 55:34 56:34 57:34 58:35 59:36 60:37 61:38 62:39 63:39 64:39 65:39 66:40 67:41 68:42 69:42 70:42 71:42 72:43 73:43 74:44 75:45 76:46 77:46 78:47 79:48 80:49 81:50 82:51 83:51 84:52 85:53 86:54 87:55 88:55 89:55 90:56 91:57 92:58 93:59 94:60 95:60 96:61 97:62 98:62 99:62 100:63 101:63 102:64 103:65 104:66 105:67 106:67 107:67 108:68 109:69 110:70 111:70 112:71 113:72 114:73 115:74 116:75 117:76 118:77 119:78 120:79 121:80 122:81 123:81 124:82 125:82 126:83 127:84 128:85 129:86 130:87 131:88 132:89 133:89 134:89 135:89 136:90 137:91 138:92 139:93 140:94 141:94 142:94 143:95 144:96 145:97 146:98 147:99 148:100 149:101 150:102 151:102 152:103 153:104 154:105 155:106 156:107 157:108 158:109 159:110 160:111 161:111\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2289 1012 2016 2038 2144 7042 102 2014 4203 10768 3850 2834 1999 2384 2001 2004 27617 2401 1999 1996 8001 3179 1997 2175 3669 5558 2615 1005 1055 7110 8447 7849 1012 2016 6369 2006 1996 4745 11605 13250 5302 20846 3405 1997 1996 3850 1012 2005 2010 3850 3460 9593 1010 5922 2128 13088 12184 1996 2535 1997 14433 6728 11837 18826 1010 2761 1037 2033 12036 1011 10430 2535 1010 2005 10430 2376 1010 1998 14043 6369 1996 2128 15773 2112 1997 14433 6728 11837 18826 2012 13677 3850 1997 3190 1010 2139 12311 22492 3366 3850 1010 1998 1996 4956 3850 1012 1010 2035 1999 2289 1012 2016 2038 2144 7042 2195 3033 1998 4395 1999 2198 5922 1005 2573 1010 2164 1996 10430 2112 1999 3449 9152 1008 1051 1010 1998 1996 2535 1997 13970 12274 17516 1999 1037 10902 3392 1999 1996 2848 5271 11650 2537 2012 1996 2047 10249 3246 2782 1999 6004 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000005\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 5\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] recordings . she recently has released [SEP] sandra collins is an american dj . she got her start on the west coast of the u . s . in phoenix , arizona and into reside ##ncies in los angeles , and eventually moved towards trance . she used american producers to give herself a unique sound . collins performed for an estimated 80 , 000 people on the first night of woodstock ' 99 , and was the first female dj featured in the trance ##port series of influential recordings . she recently has released two cd mixes under paul oak ##en ##fold ' s perfect ##o label . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:16 27:16 28:16 29:17 30:18 31:18 32:19 33:20 34:21 35:22 36:22 37:23 38:24 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:40 58:41 59:42 60:43 61:44 62:45 63:46 64:46 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:53 73:54 74:54 75:54 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:64 87:65 88:66 89:67 90:68 91:68 92:69 93:70 94:71 95:72 96:73 97:74 98:75 99:76 100:77 101:78 102:78 103:78 104:78 105:78 106:79 107:79 108:80 109:80\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 5633 1012 2016 3728 2038 2207 102 12834 6868 2003 2019 2137 6520 1012 2016 2288 2014 2707 2006 1996 2225 3023 1997 1996 1057 1012 1055 1012 1999 6708 1010 5334 1998 2046 13960 14767 1999 3050 3349 1010 1998 2776 2333 2875 16588 1012 2016 2109 2137 6443 2000 2507 2841 1037 4310 2614 1012 6868 2864 2005 2019 4358 3770 1010 2199 2111 2006 1996 2034 2305 1997 21028 1005 5585 1010 1998 2001 1996 2034 2931 6520 2956 1999 1996 16588 6442 2186 1997 6383 5633 1012 2016 3728 2038 2207 2048 3729 21109 2104 2703 6116 2368 10371 1005 1055 3819 2080 3830 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000006\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 6\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] before his marriage , rabbi ariel ##i [SEP] re ##b cha ##im ya ##ako ##v ' s wife is the sister of rabbi moi ##sh ##e stern ##buch , as is the wife of rabbi mesh ##ula ##m do ##vid solo ##ve ##itch ##ik , making the two rabbis his uncles . re ##b asher ' s brother rabbi sh ##lom ##o ariel ##i is the author of a critical edition of the nova ##lla ##e of rabbi ak ##iva e ##iger . before his marriage , rabbi ariel ##i studied in the po ##ne ##vez ##h yeshiva headed by rabbi sh ##mu ##el ro ##zo ##vsky , and he later studied under his father - in - law in the mir ##rer yeshiva . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:1 12:1 13:2 14:2 15:2 16:2 17:2 18:3 19:4 20:5 21:6 22:7 23:8 24:9 25:9 26:9 27:10 28:10 29:10 30:11 31:12 32:13 33:14 34:15 35:16 36:17 37:17 38:17 39:18 40:18 41:19 42:19 43:19 44:19 45:19 46:20 47:21 48:22 49:23 50:24 51:25 52:25 53:26 54:26 55:27 56:27 57:27 58:28 59:29 60:30 61:30 62:30 63:31 64:31 65:32 66:33 67:34 68:35 69:36 70:37 71:38 72:39 73:40 74:41 75:41 76:41 77:42 78:43 79:44 80:44 81:45 82:45 83:45 84:46 85:47 86:48 87:48 88:49 89:50 90:50 91:51 92:52 93:53 94:54 95:54 96:54 97:54 98:55 99:56 100:57 101:58 102:59 103:59 104:59 105:60 106:60 107:60 108:60 109:61 110:62 111:63 112:64 113:65 114:66 115:67 116:67 117:67 118:67 119:67 120:68 121:69 122:70 123:70 124:71 125:71\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2077 2010 3510 1010 7907 16126 2072 102 2128 2497 15775 5714 8038 20411 2615 1005 1055 2564 2003 1996 2905 1997 7907 25175 4095 2063 8665 25987 1010 2004 2003 1996 2564 1997 7907 20437 7068 2213 2079 17258 3948 3726 20189 5480 1010 2437 1996 2048 25602 2010 27328 1012 2128 2497 17243 1005 1055 2567 7907 14021 21297 2080 16126 2072 2003 1996 3166 1997 1037 4187 3179 1997 1996 6846 4571 2063 1997 7907 17712 11444 1041 17071 1012 2077 2010 3510 1010 7907 16126 2072 3273 1999 1996 13433 2638 26132 2232 22142 3753 2011 7907 14021 12274 2884 20996 6844 15904 1010 1998 2002 2101 3273 2104 2010 2269 1011 1999 1011 2375 1999 1996 14719 14544 22142 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000007\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 7\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] in his list for the [SEP] slant magazine ' s sal ci ##n ##que ##mani viewed the album as formula ##ic and ` ` competent ##ly , often frustrating ##ly more of the same from an artist who still seems capable of much more . ' ' greg ko ##t of the chicago tribune perceived ` ` formula production and hack songwriting ' ' , but complimented pink ' s personality and its ` ` handful ' ' of worthy tracks . in his list for the barnes & noble review , robert christ ##gau named the truth about love the fourth best album of 2012 . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:1 10:1 11:2 12:3 13:3 14:3 15:3 16:4 17:5 18:6 19:7 20:8 21:8 22:9 23:10 24:10 25:10 26:10 27:10 28:11 29:12 30:12 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:23 42:24 43:25 44:26 45:26 46:26 47:26 48:27 49:28 50:28 51:29 52:30 53:31 54:32 55:33 56:34 57:34 58:34 59:35 60:36 61:37 62:38 63:38 64:38 65:38 66:39 67:40 68:41 69:41 70:41 71:42 72:43 73:44 74:45 75:45 76:45 77:45 78:45 79:46 80:47 81:48 82:48 83:49 84:50 85:51 86:52 87:53 88:54 89:55 90:56 91:57 92:57 93:58 94:59 95:59 96:60 97:61 98:62 99:63 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:70\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 1999 2010 2862 2005 1996 102 27474 2932 1005 1055 16183 25022 2078 4226 20799 7021 1996 2201 2004 5675 2594 1998 1036 1036 17824 2135 1010 2411 25198 2135 2062 1997 1996 2168 2013 2019 3063 2040 2145 3849 5214 1997 2172 2062 1012 1005 1005 6754 12849 2102 1997 1996 3190 10969 8690 1036 1036 5675 2537 1998 20578 14029 1005 1005 1010 2021 27175 5061 1005 1055 6180 1998 2049 1036 1036 9210 1005 1005 1997 11007 3162 1012 1999 2010 2862 2005 1996 9957 1004 7015 3319 1010 2728 4828 20420 2315 1996 3606 2055 2293 1996 2959 2190 2201 1997 2262 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000008\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 8\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] with her aunt mary pain ##e , [SEP] her father was an englishman ` ` of rank and culture ' ' and her mother was a free woman of color , described as light - skinned . when mary was six , her mother sent her to alexandria ( then part of the district of columbia ) to attend school . living with her aunt mary pain ##e , kelsey studied for about ten years . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:5 16:5 17:6 18:7 19:8 20:8 21:8 22:9 23:10 24:11 25:12 26:13 27:14 28:15 29:16 30:17 31:17 32:18 33:19 34:20 35:20 36:20 37:20 38:21 39:22 40:23 41:24 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:31 51:32 52:33 53:34 54:35 55:36 56:37 57:37 58:38 59:39 60:40 61:40 62:41 63:42 64:43 65:44 66:45 67:46 68:46 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:52\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2007 2014 5916 2984 3255 2063 1010 102 2014 2269 2001 2019 25244 1036 1036 1997 4635 1998 3226 1005 1005 1998 2014 2388 2001 1037 2489 2450 1997 3609 1010 2649 2004 2422 1011 19937 1012 2043 2984 2001 2416 1010 2014 2388 2741 2014 2000 10297 1006 2059 2112 1997 1996 2212 1997 3996 1007 2000 5463 2082 1012 2542 2007 2014 5916 2984 3255 2063 1010 21004 3273 2005 2055 2702 2086 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000009\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 9\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] and she felt that ` ` a [SEP] shaft ##es ##bury ' s uk partners in the production of the series , british broadcaster uk ##tv and the international distributor itv studios global entertainment , were both interested in additional seasons . christina jennings approached ki ##rst ##ine stewart , executive vice - president of cbc ' s english services , about continuing the series , and she felt that ` ` a home at cbc made absolute sense ' ' . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:0 12:0 13:0 14:1 15:2 16:3 17:4 18:5 19:6 20:7 21:8 22:8 23:9 24:10 25:11 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:19 36:20 37:21 38:22 39:23 40:24 41:25 42:25 43:26 44:27 45:28 46:29 47:29 48:29 49:30 50:30 51:31 52:32 53:32 54:32 55:33 56:34 57:34 58:34 59:35 60:36 61:36 62:37 63:38 64:39 65:40 66:40 67:41 68:42 69:43 70:44 71:45 72:45 73:45 74:46 75:47 76:48 77:49 78:50 79:51 80:51 81:51 82:51\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 1998 2016 2371 2008 1036 1036 1037 102 9093 2229 4917 1005 1055 2866 5826 1999 1996 2537 1997 1996 2186 1010 2329 11995 2866 9189 1998 1996 2248 16632 11858 4835 3795 4024 1010 2020 2119 4699 1999 3176 3692 1012 12657 14103 5411 11382 12096 3170 5954 1010 3237 3580 1011 2343 1997 13581 1005 1055 2394 2578 1010 2055 5719 1996 2186 1010 1998 2016 2371 2008 1036 1036 1037 2188 2012 13581 2081 7619 3168 1005 1005 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000010\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 10\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] as his own forerunner oliver [SEP] william sha ##tner portraying writer mark twain ; a special christmas episode which included appearances by ed as ##ner , brendan co ##yle , kelly rowan and television news anchor peter mans ##bridge ; an episode which featured david on ##ley , the lieutenant governor of ontario at the time of production , appearing as his own forerunner oliver mo ##wat ; and two different episodes in which former dragons ' den investors ar ##lene dickinson and david chi ##lton guest starred . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:1 10:2 11:3 12:4 13:5 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:15 26:15 27:16 28:17 29:17 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:31 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:42 61:43 62:44 63:45 64:46 65:47 66:48 67:48 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:56 78:57 79:58 80:59 81:59 82:60 83:61 84:62 85:63 86:63 87:64 88:65 89:65\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2004 2010 2219 23993 6291 102 2520 21146 18885 17274 3213 2928 24421 1025 1037 2569 4234 2792 2029 2443 3922 2011 3968 2004 3678 1010 15039 2522 12844 1010 5163 14596 1998 2547 2739 8133 2848 16042 6374 1025 2019 2792 2029 2956 2585 2006 3051 1010 1996 3812 3099 1997 4561 2012 1996 2051 1997 2537 1010 6037 2004 2010 2219 23993 6291 9587 24281 1025 1998 2048 2367 4178 1999 2029 2280 8626 1005 7939 9387 12098 11474 17590 1998 2585 9610 13947 4113 5652 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000011\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 11\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] beau ##champ . she was a granddaughter [SEP] his maternal great - grandfather was henry percy , 4th earl of northumberland , whose wife was maud herbert , countess of northumberland . his maternal grandmother was a daughter of sir robert spencer and eleanor beaufort . eleanor was a daughter of edmund beaufort , 2nd duke of somerset and eleanor beau ##champ . she was a granddaughter of richard de beau ##champ , 13th earl of warwick and elizabeth berkeley . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:2 13:2 14:3 15:4 16:5 17:5 18:6 19:7 20:8 21:9 22:9 23:10 24:11 25:12 26:13 27:14 28:14 29:15 30:16 31:17 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:37 55:38 56:39 57:40 58:41 59:42 60:43 61:44 62:44 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:52 73:52 74:53 75:54 76:55 77:56 78:57 79:58 80:59 81:59\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 17935 25450 1012 2016 2001 1037 12787 102 2010 11062 2307 1011 5615 2001 2888 11312 1010 4343 4656 1997 16205 1010 3005 2564 2001 21696 7253 1010 11716 1997 16205 1012 2010 11062 7133 2001 1037 2684 1997 2909 2728 7084 1998 10508 23622 1012 10508 2001 1037 2684 1997 9493 23622 1010 3416 3804 1997 9198 1998 10508 17935 25450 1012 2016 2001 1037 12787 1997 2957 2139 17935 25450 1010 6122 4656 1997 13283 1998 3870 8256 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000012\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 12\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] in her most recent bid [SEP] kill ##ian in 1978 - - 79 , an assistant district attorney for brunswick judicial circuit in 1979 - - 80 , and a practicing attorney in g ##lynn county in 1980 - - 90 . williams was elected a superior court judge in 1990 , taking the bench in 1991 . in november 2010 williams competed against mary helen moses in her most recent bid for re - election . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:0 9:1 10:2 11:2 12:2 13:2 14:2 15:3 16:4 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:12 27:12 28:12 29:13 30:14 31:15 32:16 33:17 34:18 35:18 36:19 37:20 38:21 39:21 40:21 41:21 42:21 43:22 44:23 45:24 46:25 47:26 48:27 49:28 50:29 51:30 52:30 53:31 54:32 55:33 56:34 57:35 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:51 76:51 77:51\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 1999 2014 2087 3522 7226 102 3102 2937 1999 3301 1011 1011 6535 1010 2019 3353 2212 4905 2005 9192 8268 4984 1999 3245 1011 1011 3770 1010 1998 1037 12560 4905 1999 1043 27610 2221 1999 3150 1011 1011 3938 1012 3766 2001 2700 1037 6020 2457 3648 1999 2901 1010 2635 1996 6847 1999 2889 1012 1999 2281 2230 3766 3879 2114 2984 6330 9952 1999 2014 2087 3522 7226 2005 2128 1011 2602 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000013\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 13\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] on his l ##mp ##1 drive in [SEP] art ##a driver vita ##nton ##io liu ##zzi will be replaced by former mug ##en driver tom ##oki no ##ji ##ri after a disappointing season last year . after years of being with real racing , to ##shi ##hiro kane ##ish ##i will not drive for this season , being replaced by former team kun ##imi ##tsu driver hide ##ki mu ##to ##h . ka ##zuki nak ##aj ##ima , like oliver jarvis , will not return to focus on his l ##mp ##1 drive in the 2015 world endurance championship . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:1 12:2 13:2 14:2 15:3 16:3 17:4 18:5 19:6 20:7 21:8 22:9 23:9 24:10 25:11 26:11 27:12 28:12 29:12 30:13 31:14 32:15 33:16 34:17 35:18 36:18 37:19 38:20 39:21 40:22 41:23 42:24 43:25 44:25 45:26 46:26 47:26 48:27 49:27 50:27 51:28 52:29 53:30 54:31 55:32 56:33 57:33 58:34 59:35 60:36 61:37 62:38 63:39 64:39 65:39 66:40 67:41 68:41 69:42 70:42 71:42 72:42 73:43 74:43 75:44 76:44 77:44 78:44 79:45 80:46 81:47 82:47 83:48 84:49 85:50 86:51 87:52 88:53 89:54 90:55 91:55 92:55 93:56 94:57 95:58 96:59 97:60 98:61 99:62 100:62\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2006 2010 1048 8737 2487 3298 1999 102 2396 2050 4062 19300 15104 3695 8607 13793 2097 2022 2999 2011 2280 14757 2368 4062 3419 23212 2053 4478 3089 2044 1037 15640 2161 2197 2095 1012 2044 2086 1997 2108 2007 2613 3868 1010 2000 6182 18334 8472 4509 2072 2097 2025 3298 2005 2023 2161 1010 2108 2999 2011 2280 2136 28919 27605 10422 4062 5342 3211 14163 3406 2232 1012 10556 24015 17823 13006 9581 1010 2066 6291 21072 1010 2097 2025 2709 2000 3579 2006 2010 1048 8737 2487 3298 1999 1996 2325 2088 14280 2528 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000014\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 14\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] wanted her daughter to catch [SEP] twenty years ago , lorenzo ur ##ibe discovered true love with maria herrera and began a romance . lorenzo was rich , married , and had a young son : lau ##taro . maria was poor and unknown to lorenzo , had a daughter called ren ##ata . maria ' s mother , gr ##ac ##ia , wanted her daughter to catch this rich man at all costs and convinced her that pregnancy would assure this . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:14 25:15 26:16 27:17 28:17 29:18 30:18 31:19 32:20 33:21 34:22 35:23 36:23 37:24 38:24 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:31 48:32 49:33 50:34 51:35 52:36 53:36 54:36 55:37 56:37 57:37 58:38 59:38 60:39 61:39 62:39 63:39 64:40 65:41 66:42 67:43 68:44 69:45 70:46 71:47 72:48 73:49 74:50 75:51 76:52 77:53 78:54 79:55 80:56 81:57 82:58 83:58\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2359 2014 2684 2000 4608 102 3174 2086 3283 1010 12484 24471 20755 3603 2995 2293 2007 3814 23527 1998 2211 1037 7472 1012 12484 2001 4138 1010 2496 1010 1998 2018 1037 2402 2365 1024 21360 28160 1012 3814 2001 3532 1998 4242 2000 12484 1010 2018 1037 2684 2170 14916 6790 1012 3814 1005 1055 2388 1010 24665 6305 2401 1010 2359 2014 2684 2000 4608 2023 4138 2158 2012 2035 5366 1998 6427 2014 2008 10032 2052 14306 2023 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000015\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 15\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] college , she was appointed head [SEP] a colleague in the department run by erwin fr ##ink smith , she also collaborated with botanist nellie ada ##les ##a brown . mcc ##ull ##och was born in cincinnati , ohio . she was the daughter of robert s . and alma tag ##gart ( n * e eve ##let ##h ) mcc ##ull ##och . in 1898 , while studying biology at florida agricultural college , she was appointed head of the library , now part of the george a . sm ##ath ##ers libraries . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:8 18:9 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:16 28:16 29:17 30:17 31:18 32:18 33:18 34:19 35:20 36:21 37:22 38:22 39:23 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:30 48:30 49:31 50:32 51:33 52:33 53:34 54:34 55:34 56:34 57:35 58:35 59:35 60:35 61:36 62:36 63:36 64:36 65:37 66:38 67:38 68:39 69:40 70:41 71:42 72:43 73:44 74:45 75:45 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:52 84:53 85:54 86:55 87:56 88:57 89:58 90:58 91:59 92:59 93:59 94:60 95:60\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2267 1010 2016 2001 2805 2132 102 1037 11729 1999 1996 2533 2448 2011 22209 10424 19839 3044 1010 2016 2036 8678 2007 17098 25365 15262 4244 2050 2829 1012 23680 18083 11663 2001 2141 1999 7797 1010 4058 1012 2016 2001 1996 2684 1997 2728 1055 1012 1998 11346 6415 27378 1006 1050 1008 1041 6574 7485 2232 1007 23680 18083 11663 1012 1999 6068 1010 2096 5702 7366 2012 3516 4910 2267 1010 2016 2001 2805 2132 1997 1996 3075 1010 2085 2112 1997 1996 2577 1037 1012 15488 8988 2545 8860 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000016\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 16\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] introduces him as ` ` baron court ##elin ' ' [SEP] maurice custom - tailor ##s clothing for de var * ze on credit , but the vic ##om ##te ' s unpaid tailor ##ing bills become into ##ler ##able , so maurice travels to de sa ##vi ##gna ##c ' s castle to collect the money owed to him . on the way , he has a confrontation with princess ##e jean ##ette . he immediately prof ##esses his love for her , but she ha ##ught ##ily rejects him . when maurice arrives at the castle , gilbert introduces him as ` ` baron court ##elin ' ' in order to hide the truth from the comte . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 12:0 13:1 14:1 15:1 16:1 17:2 18:3 19:4 20:5 21:5 22:5 23:6 24:7 25:7 26:8 27:9 28:10 29:10 30:10 31:10 32:10 33:11 34:12 35:12 36:13 37:14 38:15 39:15 40:15 41:15 42:16 43:17 44:18 45:19 46:20 47:21 48:21 49:21 50:21 51:21 52:21 53:22 54:23 55:24 56:25 57:26 58:27 59:28 60:29 61:29 62:30 63:31 64:32 65:32 66:33 67:34 68:35 69:36 70:37 71:38 72:38 73:39 74:39 75:39 76:40 77:41 78:42 79:42 80:43 81:44 82:45 83:46 84:46 85:47 86:48 87:49 88:49 89:49 90:50 91:51 92:51 93:52 94:53 95:54 96:55 97:56 98:57 99:57 100:58 101:59 102:60 103:61 104:62 105:62 106:62 107:63 108:63 109:63 110:63 111:64 112:65 113:66 114:67 115:68 116:69 117:70 118:71 119:72 120:73\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 13999 2032 2004 1036 1036 5797 2457 18809 1005 1005 102 7994 7661 1011 22701 2015 5929 2005 2139 13075 1008 27838 2006 4923 1010 2021 1996 10967 5358 2618 1005 1055 23850 22701 2075 8236 2468 2046 3917 3085 1010 2061 7994 7930 2000 2139 7842 5737 16989 2278 1005 1055 3317 2000 8145 1996 2769 12232 2000 2032 1012 2006 1996 2126 1010 2002 2038 1037 13111 2007 4615 2063 3744 7585 1012 2002 3202 11268 26636 2010 2293 2005 2014 1010 2021 2016 5292 18533 6588 19164 2032 1012 2043 7994 8480 2012 1996 3317 1010 7664 13999 2032 2004 1036 1036 5797 2457 18809 1005 1005 1999 2344 2000 5342 1996 3606 2013 1996 19758 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000017\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 17\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] from his injury and briefly [SEP] in 1988 , race suffered an abdominal injury and during his absence his manager bobby ` ` the brain ' ' hee ##nan awarded the crown to ha ##ku in july , rec ##hri ##sten ##ing him king ha ##ku , even though randy savage had won the tournament by that point and ted di ##bia ##se would also win the tournament during this storyline . race eventually returned from his injury and briefly feud ##ed with king ha ##ku , but was unable to regain the crown at the 1989 royal rumble . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:14 24:14 25:15 26:15 27:15 28:16 29:16 30:17 31:18 32:19 33:20 34:21 35:21 36:22 37:23 38:23 39:24 40:24 41:24 42:24 43:25 44:26 45:27 46:27 47:27 48:28 49:29 50:30 51:31 52:32 53:33 54:34 55:35 56:36 57:37 58:38 59:39 60:40 61:41 62:41 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:58 83:59 84:60 85:61 86:61 87:61 88:62 89:63 90:64 91:65 92:66 93:67 94:68 95:69 96:70 97:71 98:72 99:73 100:73\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 2013 2010 4544 1998 4780 102 1999 2997 1010 2679 4265 2019 21419 4544 1998 2076 2010 6438 2010 3208 6173 1036 1036 1996 4167 1005 1005 18235 7229 3018 1996 4410 2000 5292 5283 1999 2251 1010 28667 26378 16173 2075 2032 2332 5292 5283 1010 2130 2295 9744 9576 2018 2180 1996 2977 2011 2008 2391 1998 6945 4487 11607 3366 2052 2036 2663 1996 2977 2076 2023 9994 1012 2679 2776 2513 2013 2010 4544 1998 4780 13552 2098 2007 2332 5292 5283 1010 2021 2001 4039 2000 12452 1996 4410 2012 1996 2960 2548 15658 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000018\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 18\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] eliminating him from the tournament . [SEP] the rest of the group find out what has happened to case and decide to band together and take on justin at the beat ##down to avenge their mentor . with each facing their own trials to reach the final match , it comes down to only one of them versus their own . mike defeats zack , while justin in ##jure ##s tim in the restroom - thus eliminating him from the tournament . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:22 31:23 32:23 33:24 34:25 35:26 36:27 37:27 38:28 39:29 40:30 41:31 42:32 43:33 44:34 45:35 46:36 47:37 48:38 49:38 50:39 51:40 52:41 53:42 54:43 55:44 56:45 57:46 58:47 59:48 60:49 61:49 62:50 63:51 64:52 65:52 66:53 67:54 68:55 69:55 70:55 71:56 72:57 73:58 74:59 75:60 76:61 77:62 78:63 79:64 80:65 81:66 82:66\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 15349 2032 2013 1996 2977 1012 102 1996 2717 1997 1996 2177 2424 2041 2054 2038 3047 2000 2553 1998 5630 2000 2316 2362 1998 2202 2006 6796 2012 1996 3786 7698 2000 24896 2037 10779 1012 2007 2169 5307 2037 2219 7012 2000 3362 1996 2345 2674 1010 2009 3310 2091 2000 2069 2028 1997 2068 6431 2037 2219 1012 3505 14222 13658 1010 2096 6796 1999 25243 2015 5199 1999 1996 28249 1011 2947 15349 2032 2013 1996 2977 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   unique_id: 1000000019\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   example_index: 19\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   tokens: [CLS] filling his side with a [SEP] on 30 july 1966 , ramsey ' s promise was fulfilled as england became the world champions by beating west germany in a thrilling final . a lot of ramsey ' s tactics and decisions proved their worth in this final . ramsey came under pressure to restore the fit - again jimmy greaves to the side : but he stuck to his guns and kept faith with greaves ' s replacement , geoff hurst , who vin ##dicated ramsey ' s judgement by scoring a hat - trick in a 4 - - 2 win ( after extra time ) at wembley . filling his side with a good balance of experience and youth proved vital when the gr ##uel ##ling final went to extra time . [SEP]\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:3 12:4 13:4 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:19 30:20 31:21 32:21 33:22 34:23 35:24 36:25 37:25 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:34 49:35 50:36 51:37 52:38 53:39 54:40 55:41 56:42 57:42 58:42 59:43 60:44 61:45 62:46 63:47 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:54 72:55 73:56 74:57 75:58 76:58 77:58 78:59 79:59 80:60 81:61 82:61 83:62 84:63 85:63 86:64 87:64 88:64 89:65 90:66 91:67 92:68 93:69 94:69 95:69 96:70 97:71 98:72 99:72 100:72 101:72 102:73 103:74 104:74 105:75 106:76 107:76 108:77 109:78 110:78 111:79 112:80 113:81 114:82 115:83 116:84 117:85 118:86 119:87 120:88 121:89 122:90 123:91 124:92 125:93 126:94 127:94 128:94 129:95 130:96 131:97 132:98 133:99 134:99\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_ids: 101 8110 2010 2217 2007 1037 102 2006 2382 2251 3547 1010 15092 1005 1055 4872 2001 16829 2004 2563 2150 1996 2088 3966 2011 6012 2225 2762 1999 1037 26162 2345 1012 1037 2843 1997 15092 1005 1055 9887 1998 6567 4928 2037 4276 1999 2023 2345 1012 15092 2234 2104 3778 2000 9239 1996 4906 1011 2153 5261 27808 2000 1996 2217 1024 2021 2002 5881 2000 2010 4409 1998 2921 4752 2007 27808 1005 1055 6110 1010 14915 26405 1010 2040 19354 26022 15092 1005 1055 16646 2011 4577 1037 6045 1011 7577 1999 1037 1018 1011 1011 1016 2663 1006 2044 4469 2051 1007 2012 16538 1012 8110 2010 2217 2007 1037 2204 5703 1997 3325 1998 3360 4928 8995 2043 1996 24665 16284 2989 2345 2253 2000 4469 2051 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:43:44 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Fold 1\n",
      "====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2019 16:43:50 - INFO - pytorch_pretrained_bert.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz not found in cache, downloading to /tmp/tmp928er4g4\n",
      "100%|██████████| 1248501532/1248501532 [00:24<00:00, 50530439.56B/s]\n",
      "05/02/2019 16:44:15 - INFO - pytorch_pretrained_bert.file_utils -   copying /tmp/tmp928er4g4 to cache at /tmp/.pytorch_pretrained_bert/distributed_-1/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "05/02/2019 16:44:20 - INFO - pytorch_pretrained_bert.file_utils -   creating metadata file for /tmp/.pytorch_pretrained_bert/distributed_-1/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "05/02/2019 16:44:20 - INFO - pytorch_pretrained_bert.file_utils -   removing temp file /tmp/tmp928er4g4\n",
      "05/02/2019 16:44:20 - INFO - pytorch_pretrained_bert.modeling -   loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased.tar.gz from cache at /tmp/.pytorch_pretrained_bert/distributed_-1/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05\n",
      "05/02/2019 16:44:20 - INFO - pytorch_pretrained_bert.modeling -   extracting archive file /tmp/.pytorch_pretrained_bert/distributed_-1/214d4777e8e3eb234563136cd3a49f6bc34131de836848454373fa43f10adc5e.abfbb80ee795a608acbf35c7bf2d2d58574df3887cdd94b355fc67e03fddba05 to temp dir /tmp/tmpl7qal3os\n",
      "05/02/2019 16:44:44 - INFO - pytorch_pretrained_bert.modeling -   Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "05/02/2019 16:44:57 - INFO - pytorch_pretrained_bert.modeling -   Weights of BertForQuestionAnswering not initialized from pretrained model: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "05/02/2019 16:44:57 - INFO - pytorch_pretrained_bert.modeling -   Weights from pretrained model not used in BertForQuestionAnswering: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 335143938, trainable parameters: 152206338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000000\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] uncles . his cousin is minnesota [SEP] upon their acceptance into the ko ##ntine ##ntal hockey league , de ##hner left finland to sign a contract in germany with eh ##c m * nc ##hen of the del on june 18 , 2014 . after capturing the german championship with the m * nc ##hen team in 2016 , he left the club and was picked up by fellow del side eh ##c wolf ##sburg in july 2016 . former nhl ##er gary su ##ter and olympic - medalist bob su ##ter are de ##hner ' s uncles . his cousin is minnesota wild ' s alternate captain ryan su ##ter . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:5 16:6 17:7 18:7 19:8 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:19 34:19 35:19 36:20 37:21 38:22 39:23 40:24 41:25 42:25 43:26 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:34 54:34 55:34 56:35 57:36 58:37 59:37 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:50 74:51 75:51 76:52 77:53 78:54 79:54 80:55 81:56 82:56 83:57 84:58 85:58 86:59 87:60 88:60 89:60 90:61 91:62 92:62 93:63 94:64 95:64 96:64 97:64 98:65 99:65 100:66 101:67 102:68 103:69 104:70 105:70 106:70 107:71 108:72 109:73 110:74 111:74 112:74\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 27328 1012 2010 5542 2003 5135 102 2588 2037 9920 2046 1996 12849 26730 15758 3873 2223 1010 2139 28989 2187 6435 2000 3696 1037 3206 1999 2762 2007 15501 2278 1049 1008 13316 10222 1997 1996 3972 2006 2238 2324 1010 2297 1012 2044 11847 1996 2446 2528 2007 1996 1049 1008 13316 10222 2136 1999 2355 1010 2002 2187 1996 2252 1998 2001 3856 2039 2011 3507 3972 2217 15501 2278 4702 9695 1999 2251 2355 1012 2280 7097 2121 5639 10514 3334 1998 4386 1011 12968 3960 10514 3334 2024 2139 28989 1005 1055 27328 1012 2010 5542 2003 5135 3748 1005 1055 6585 2952 4575 10514 3334 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 94\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 95\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: de ##hner\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000001\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 1\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] selected him for the first [SEP] between the years 1979 - 1981 , river won four local titles , and became one of the most expensive teams in the world , with a first team ( alonso - lu ##que ) playing in league games and an equally prestigious second team ( carr ##asco - ram * n d * az ) used mostly in copa libertadores matches . during the 1981 ` ` nacional ' ' tournament ( which river would eventually win ) , alonso often clashed with then coach alfredo di st * fan ##o ( who seldom selected him for the first team and instead put younger players such as carlos daniel tap ##ia and jose maria viet ##a in his position ) . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:3 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:19 32:20 33:21 34:22 35:23 36:24 37:24 38:24 39:25 40:25 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:36 54:36 55:36 56:37 57:37 58:37 59:38 60:38 61:38 62:38 63:39 64:40 65:41 66:42 67:43 68:44 69:44 70:45 71:46 72:47 73:48 74:48 75:48 76:48 77:48 78:49 79:50 80:50 81:51 82:52 83:53 84:54 85:54 86:54 87:55 88:56 89:57 90:58 91:59 92:60 93:61 94:62 95:63 96:63 97:63 98:63 99:64 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:71 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:80 117:81 118:81 119:82 120:83 121:84 122:85 123:85 124:86 125:87 126:88 127:88 128:88\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 3479 2032 2005 1996 2034 102 2090 1996 2086 3245 1011 3261 1010 2314 2180 2176 2334 4486 1010 1998 2150 2028 1997 1996 2087 6450 2780 1999 1996 2088 1010 2007 1037 2034 2136 1006 17649 1011 11320 4226 1007 2652 1999 2223 2399 1998 2019 8053 8919 2117 2136 1006 12385 28187 1011 8223 1008 1050 1040 1008 17207 1007 2109 3262 1999 10613 27968 3503 1012 2076 1996 3261 1036 1036 10718 1005 1005 2977 1006 2029 2314 2052 2776 2663 1007 1010 17649 2411 22600 2007 2059 2873 19423 4487 2358 1008 5470 2080 1006 2040 15839 3479 2032 2005 1996 2034 2136 1998 2612 2404 3920 2867 2107 2004 5828 3817 11112 2401 1998 4560 3814 19710 2050 1999 2010 2597 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 87\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 87\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: alonso\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000002\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 2\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] regime . he was ambushed with [SEP] though his emigration from the country has affected his leadership status , kam ##el is still a respected elder of the clan . after the fall of hu ##ssi ##en ' s regime , many considered dr . ali ala ##dha ##dh a candidate to lead the clan . a contributor to iraq ' s liberation , ali ala ##dha ##dh and a long time oppose to saddam ' s regime . he was ambushed with his pregnant wife on his way to the hospital in 2006 by iraqi insurgents . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:19 30:19 31:20 32:21 33:22 34:23 35:24 36:24 37:24 38:24 39:24 40:25 41:25 42:26 43:27 44:28 45:28 46:29 47:30 48:30 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:36 57:37 58:38 59:39 60:40 61:40 62:40 63:41 64:41 65:42 66:43 67:43 68:43 69:44 70:45 71:46 72:47 73:48 74:49 75:50 76:50 77:50 78:51 79:51 80:52 81:53 82:54 83:55 84:56 85:57 86:58 87:59 88:60 89:61 90:62 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:69\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 6939 1012 2002 2001 22168 2007 102 2295 2010 20387 2013 1996 2406 2038 5360 2010 4105 3570 1010 27829 2884 2003 2145 1037 9768 6422 1997 1996 6338 1012 2044 1996 2991 1997 15876 18719 2368 1005 1055 6939 1010 2116 2641 2852 1012 4862 21862 17516 16425 1037 4018 2000 2599 1996 6338 1012 1037 12130 2000 5712 1005 1055 7931 1010 4862 21862 17516 16425 1998 1037 2146 2051 15391 2000 24111 1005 1055 6939 1012 2002 2001 22168 2007 2010 6875 2564 2006 2010 2126 2000 1996 2902 1999 2294 2011 8956 20541 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 65\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 68\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: ali ala ##dha ##dh\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000003\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 3\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] during his trial pi ##sc ##iot ##ta could [SEP] at the trial , pi ##sc ##iot ##ta said : ` ` those who have made promises to us are called bernardo matt ##are ##lla , prince all ##ia ##ta , the monarch ##ist mp marches ##ano and also sign ##or sc ##el ##ba , minister for home affairs . . . it was marches ##ano , prince all ##ia ##ta and bernardo matt ##are ##lla who ordered the massacre of porte ##lla di gin ##estra . before the massacre they met gi ##ulia ##no . . . ' ' however the mps matt ##are ##lla , all ##ia ##ta and marches ##ano were declared innocent by the court of appeal of palermo , at a trial which dealt with their alleged role in the event . during his trial pi ##sc ##iot ##ta could not account for gi ##ulia ##no ' s documents in which he named the high - ranking government officials and ma ##fi ##osi involved with gi ##ulia ##no ' s band . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 10:0 11:1 12:2 13:2 14:3 15:3 16:3 17:3 18:4 19:4 20:5 21:5 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:15 34:15 35:15 36:16 37:17 38:17 39:17 40:17 41:18 42:19 43:19 44:20 45:21 46:21 47:22 48:23 49:24 50:24 51:25 52:25 53:25 54:25 55:26 56:27 57:28 58:29 59:30 60:30 61:30 62:31 63:32 64:33 65:33 66:33 67:34 68:35 69:35 70:35 71:36 72:37 73:38 74:38 75:38 76:39 77:40 78:41 79:42 80:43 81:44 82:44 83:45 84:46 85:46 86:46 87:47 88:48 89:49 90:50 91:51 92:52 93:52 94:52 95:52 96:52 97:52 98:52 99:52 100:53 101:54 102:55 103:56 104:56 105:56 106:56 107:57 108:57 109:57 110:58 111:59 112:59 113:60 114:61 115:62 116:63 117:64 118:65 119:66 120:67 121:68 122:69 123:69 124:70 125:71 126:72 127:73 128:74 129:75 130:76 131:77 132:78 133:79 134:80 135:81 136:81 137:82 138:83 139:84 140:85 141:85 142:85 143:85 144:86 145:87 146:88 147:89 148:90 149:90 150:90 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:97 161:97 162:98 163:99 164:100 165:101 166:101 167:101 168:102 169:103 170:104 171:104 172:104 173:104 174:104 175:105 176:105\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 2076 2010 3979 14255 11020 25185 2696 2071 102 2012 1996 3979 1010 14255 11020 25185 2696 2056 1024 1036 1036 2216 2040 2031 2081 10659 2000 2149 2024 2170 21175 4717 12069 4571 1010 3159 2035 2401 2696 1010 1996 11590 2923 6131 20691 6761 1998 2036 3696 2953 8040 2884 3676 1010 2704 2005 2188 3821 1012 1012 1012 2009 2001 20691 6761 1010 3159 2035 2401 2696 1998 21175 4717 12069 4571 2040 3641 1996 9288 1997 25927 4571 4487 18353 26199 1012 2077 1996 9288 2027 2777 21025 20922 3630 1012 1012 1012 1005 1005 2174 1996 12616 4717 12069 4571 1010 2035 2401 2696 1998 20691 6761 2020 4161 7036 2011 1996 2457 1997 5574 1997 18705 1010 2012 1037 3979 2029 9411 2007 2037 6884 2535 1999 1996 2724 1012 2076 2010 3979 14255 11020 25185 2696 2071 2025 4070 2005 21025 20922 3630 1005 1055 5491 1999 2029 2002 2315 1996 2152 1011 5464 2231 4584 1998 5003 8873 20049 2920 2007 21025 20922 3630 1005 1055 2316 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 140\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 143\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: pi ##sc ##iot ##ta\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000004\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 4\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] before his discharge , eddie is [SEP] it is about a pair of united states navy shore patrol ##lers ( sp ##s ) ( tom be ##ren ##ger and william mcnamara ) who must escort a beautiful prisoner ( erika el ##enia ##k ) , and the troubles they encounter . eddie dev ##ane ( william mcnamara ) is a young sailor who has carried out a number of inventory - related sc ##ams along with his partner - in - crime howard ( crisp ##in glover ) and made a lot of money during his service . a day before his discharge , eddie is assigned to escort a prisoner from the marine base at camp le ##je ##une along with the authoritarian , no - nonsense chief petty officer rock reilly ( tom be ##ren ##ger ) . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:11 22:11 23:11 24:12 25:12 26:13 27:13 28:13 29:14 30:15 31:16 32:16 33:17 34:18 35:19 36:20 37:21 38:22 39:23 40:23 41:24 42:24 43:24 44:24 45:24 46:25 47:26 48:27 49:28 50:29 51:29 52:30 53:31 54:31 55:32 56:32 57:33 58:33 59:34 60:35 61:36 62:37 63:38 64:39 65:40 66:41 67:42 68:43 69:44 70:45 71:45 72:45 73:46 74:46 75:47 76:48 77:49 78:50 79:50 80:50 81:50 82:50 83:51 84:52 85:52 86:52 87:53 88:53 89:54 90:55 91:56 92:57 93:58 94:59 95:60 96:61 97:62 98:62 99:63 100:64 101:65 102:66 103:67 104:67 105:68 106:69 107:70 108:71 109:72 110:73 111:74 112:75 113:76 114:77 115:78 116:79 117:80 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:85 126:86 127:86 128:86 129:87 130:88 131:89 132:90 133:91 134:92 135:92 136:93 137:93 138:93 139:93 140:93\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 2077 2010 11889 1010 5752 2003 102 2009 2003 2055 1037 3940 1997 2142 2163 3212 5370 6477 12910 1006 11867 2015 1007 1006 3419 2022 7389 4590 1998 2520 28340 1007 2040 2442 8620 1037 3376 7267 1006 24900 3449 19825 2243 1007 1010 1998 1996 13460 2027 8087 1012 5752 16475 7231 1006 2520 28340 1007 2003 1037 2402 11803 2040 2038 3344 2041 1037 2193 1997 12612 1011 3141 8040 13596 2247 2007 2010 4256 1011 1999 1011 4126 4922 1006 15594 2378 20012 1007 1998 2081 1037 2843 1997 2769 2076 2010 2326 1012 1037 2154 2077 2010 11889 1010 5752 2003 4137 2000 8620 1037 7267 2013 1996 3884 2918 2012 3409 3393 6460 9816 2247 2007 1996 27246 1010 2053 1011 14652 2708 11612 2961 2600 13875 1006 3419 2022 7389 4590 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 105\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 105\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: eddie\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000005\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 5\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] with her previously as el ##lia [SEP] the others were adam baldwin ( jayne cobb in fire ##fly ) who played colonel dave dixon , and more ##na ba ##cca ##rin ( ina ##ra serra in fire ##fly ) who played ad ##ria . executive producer martin ge ##ro created the character of jennifer keller while writing ` ` first strike ' ' . the producers decided to cast jewel st ##ai ##te for the role as keller after they enjoyed working with her previously as el ##lia in ` ` instinct ' ' . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:6 16:7 17:8 18:8 19:8 20:9 21:10 22:11 23:12 24:13 25:13 26:14 27:15 28:15 29:16 30:16 31:16 32:17 33:17 34:17 35:18 36:19 37:20 38:20 39:20 40:21 41:22 42:23 43:23 44:23 45:24 46:25 47:26 48:27 49:27 50:28 51:29 52:30 53:31 54:32 55:33 56:34 57:35 58:36 59:36 60:36 61:37 62:37 63:37 64:37 65:38 66:39 67:40 68:41 69:42 70:43 71:44 72:44 73:44 74:45 75:46 76:47 77:48 78:49 79:50 80:51 81:52 82:53 83:54 84:55 85:56 86:57 87:58 88:58 89:59 90:60 91:60 92:60 93:60 94:60 95:60\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 2007 2014 3130 2004 3449 6632 102 1996 2500 2020 4205 10970 1006 24408 17176 1999 2543 14151 1007 2040 2209 4327 4913 11357 1010 1998 2062 2532 8670 16665 6657 1006 27118 2527 22737 1999 2543 14151 1007 2040 2209 4748 4360 1012 3237 3135 3235 16216 3217 2580 1996 2839 1997 7673 16155 2096 3015 1036 1036 2034 4894 1005 1005 1012 1996 6443 2787 2000 3459 13713 2358 4886 2618 2005 1996 2535 2004 16155 2044 2027 5632 2551 2007 2014 3130 2004 3449 6632 1999 1036 1036 12753 1005 1005 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 70\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 73\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: jewel st ##ai ##te\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000006\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 6\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] curry . she played lady jane [SEP] allison fischer ( born october 19 , 1988 ) is an american singer and actress . originally from northern new jersey , allison had her first professional performance in the off - broadway musical king island christmas in 2000 . also in 2000 , allison performed on broadway at madison square garden as grace smyth ##e in a christmas carol , alongside frank lange ##lla and tim curry . she played lady jane in the off - broadway musical version of the prince and the pau ##per from 2002 - - 2003 , and briefly performed at playwright ##s horizon in january 2003 in jean ##ine te ##sor ##i ' s musical , ' ' violet ' ' . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:2 12:3 13:4 14:4 15:5 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:11 24:12 25:13 26:14 27:15 28:16 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:31 48:32 49:33 50:34 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:43 61:44 62:45 63:45 64:46 65:47 66:48 67:49 68:49 69:50 70:51 71:52 72:52 73:53 74:54 75:55 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:62 85:62 86:63 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:70 95:71 96:72 97:72 98:72 99:72 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:83 114:84 115:84 116:84 117:85 118:85 119:86 120:86 121:87 122:87 123:87 124:87 125:87 126:87\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 15478 1012 2016 2209 3203 4869 102 10786 13042 1006 2141 2255 2539 1010 2997 1007 2003 2019 2137 3220 1998 3883 1012 2761 2013 2642 2047 3933 1010 10786 2018 2014 2034 2658 2836 1999 1996 2125 1011 5934 3315 2332 2479 4234 1999 2456 1012 2036 1999 2456 1010 10786 2864 2006 5934 2012 7063 2675 3871 2004 4519 28103 2063 1999 1037 4234 8594 1010 4077 3581 21395 4571 1998 5199 15478 1012 2016 2209 3203 4869 1999 1996 2125 1011 5934 3315 2544 1997 1996 3159 1998 1996 29025 4842 2013 2526 1011 1011 2494 1010 1998 4780 2864 2012 11170 2015 9154 1999 2254 2494 1999 3744 3170 8915 21748 2072 1005 1055 3315 1010 1005 1005 8766 1005 1005 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 52\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 52\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: allison\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000007\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 7\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] killing her . [SEP] the monster arrives and bites jen ##i ' s tongue , but david manages to break free and releases the other three , though at the cost of his own life . the remaining trio head back to the cottage to set a trap to kill the monster , but the le ##pre ##cha ##un tricks sophie and ben into striking jen ##i with their axes , killing her . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 5:0 6:1 7:2 8:3 9:4 10:5 11:5 12:5 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:17 28:18 29:19 30:20 31:21 32:22 33:23 34:24 35:25 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:37 49:38 50:39 51:40 52:41 53:41 54:42 55:43 56:44 57:44 58:44 59:44 60:45 61:46 62:47 63:48 64:49 65:50 66:51 67:51 68:52 69:53 70:54 71:54 72:55 73:56 74:56\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 5:True 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 4288 2014 1012 102 1996 6071 8480 1998 15424 15419 2072 1005 1055 4416 1010 2021 2585 9020 2000 3338 2489 1998 7085 1996 2060 2093 1010 2295 2012 1996 3465 1997 2010 2219 2166 1012 1996 3588 7146 2132 2067 2000 1996 9151 2000 2275 1037 8132 2000 3102 1996 6071 1010 2021 1996 3393 28139 7507 4609 12225 8234 1998 3841 2046 8478 15419 2072 2007 2037 19589 1010 4288 2014 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 66\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 67\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: jen ##i\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000008\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 8\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] then he faced former world [SEP] on june 4 , 1973 at the felt forum , madison square garden , new york , mala ##ve lost to ray lamp ##kin by an eighth - round knockout . mala ##ve took a fight in boston , mass . against greg join ##er , winning by a knockout in the 3rd round . then he faced former world lightweight champion ken buchanan , losing by a tko in the 7th round september 1 , 1973 , which turned out to be his last professional boxing match . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:7 17:8 18:9 19:10 20:10 21:11 22:12 23:12 24:13 25:13 26:14 27:15 28:16 29:17 30:17 31:18 32:19 33:20 34:20 35:20 36:21 37:21 38:22 39:22 40:23 41:24 42:25 43:26 44:27 45:27 46:28 47:28 48:29 49:30 50:31 51:31 52:31 53:32 54:33 55:34 56:35 57:36 58:37 59:38 60:39 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:58 83:59 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:69\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 2059 2002 4320 2280 2088 102 2006 2238 1018 1010 3381 2012 1996 2371 7057 1010 7063 2675 3871 1010 2047 2259 1010 28935 3726 2439 2000 4097 10437 4939 2011 2019 5964 1011 2461 11369 1012 28935 3726 2165 1037 2954 1999 3731 1010 3742 1012 2114 6754 3693 2121 1010 3045 2011 1037 11369 1999 1996 3822 2461 1012 2059 2002 4320 2280 2088 12038 3410 6358 14349 1010 3974 2011 1037 26537 1999 1996 5504 2461 2244 1015 1010 3381 1010 2029 2357 2041 2000 2022 2010 2197 2658 8362 2674 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 38\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 39\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: mala ##ve\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000009\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 9\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] from her album sha ##kin ' things [SEP] go away ( lo ##rrie morgan song ) ` ` go away ' ' is a song written by step ##hony smith , cathy maj ##es ##ki and sunny russ , and recorded by american country music artist lo ##rrie morgan . it was released in july 1997 as the first single from her album sha ##kin ' things up . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:2 13:2 14:3 15:4 16:4 17:5 18:5 19:5 20:6 21:6 22:6 23:7 24:8 25:9 26:10 27:11 28:12 29:12 30:13 31:13 32:14 33:15 34:15 35:15 36:16 37:17 38:18 39:18 40:19 41:20 42:21 43:22 44:23 45:24 46:25 47:26 48:26 49:27 50:27 51:28 52:29 53:30 54:31 55:32 56:33 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:41 66:41 67:42 68:43 69:43\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 2013 2014 2201 21146 4939 1005 2477 102 2175 2185 1006 8840 22155 5253 2299 1007 1036 1036 2175 2185 1005 1005 2003 1037 2299 2517 2011 3357 27629 3044 1010 18305 16686 2229 3211 1998 11559 18072 1010 1998 2680 2011 2137 2406 2189 3063 8840 22155 5253 1012 2009 2001 2207 1999 2251 2722 2004 1996 2034 2309 2013 2014 2201 21146 4939 1005 2477 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 47\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 49\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   answer: lo ##rrie morgan\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   unique_id: 1000000010\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   example_index: 10\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   tokens: [CLS] in her most visible action , [SEP] taken in by s . h . i . e . l . d . she is under the direct supervision of its longtime executive director , nick fury , even after the latter ' s defect ##ion from the agency during the events of the ` ` secret war ' ' series . she possesses a ` ` level 10 ' ' security clearance , the only known agent aside from fury and the black widow ( natasha romano ##va ) to do so . in her most visible action , johnson has helped to defeat the powerful mutant rebel leader magnet ##o by inducing a vibration in his brain that made him lose consciousness . [SEP]\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:3 14:3 15:3 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:14 35:15 36:16 37:16 38:17 39:18 40:19 41:20 42:20 43:20 44:21 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:28 53:29 54:30 55:30 56:30 57:31 58:31 59:31 60:32 61:32 62:33 63:34 64:35 65:36 66:36 67:36 68:37 69:37 70:37 71:38 72:39 73:39 74:40 75:41 76:42 77:43 78:44 79:45 80:46 81:47 82:48 83:49 84:50 85:51 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:55 94:56 95:57 96:58 97:59 98:60 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:81 122:82 123:83 124:83\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_ids: 101 1999 2014 2087 5710 2895 1010 102 2579 1999 2011 1055 1012 1044 1012 1045 1012 1041 1012 1048 1012 1040 1012 2016 2003 2104 1996 3622 10429 1997 2049 11155 3237 2472 1010 4172 8111 1010 2130 2044 1996 3732 1005 1055 21262 3258 2013 1996 4034 2076 1996 2824 1997 1996 1036 1036 3595 2162 1005 1005 2186 1012 2016 14882 1037 1036 1036 2504 2184 1005 1005 3036 14860 1010 1996 2069 2124 4005 4998 2013 8111 1998 1996 2304 7794 1006 17399 22070 3567 1007 2000 2079 2061 1012 1999 2014 2087 5710 2895 1010 3779 2038 3271 2000 4154 1996 3928 15527 8443 3003 16853 2080 2011 29290 1037 17880 1999 2010 4167 2008 2081 2032 4558 8298 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   start_position: 100\n",
      "05/02/2019 16:44:59 - INFO - __main__ -   end_position: 100\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: johnson\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000011\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 11\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] department . his wife is su ##zan ##na [SEP] he was a lawyer in pu ##las ##ki county before serving as mayor of little rock from 1979 until he resigned in 1981 . he was appointed by bill clinton as chief justice of arkansas state supreme court in 1983 . when clinton became president , hub ##bell was appointed as associate attorney general , which is the third most powerful person in the justice department . his wife is su ##zan ##na ` ` suzy ' ' hub ##bell . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:5 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:35 49:36 50:36 51:37 52:38 53:39 54:40 55:40 56:41 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:54 72:55 73:56 74:57 75:58 76:58 77:59 78:60 79:61 80:62 81:62 82:62 83:63 84:63 85:63 86:63 87:63 88:64 89:64 90:64\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 2533 1012 2010 2564 2003 10514 13471 2532 102 2002 2001 1037 5160 1999 16405 8523 3211 2221 2077 3529 2004 3664 1997 2210 2600 2013 3245 2127 2002 5295 1999 3261 1012 2002 2001 2805 2011 3021 7207 2004 2708 3425 1997 6751 2110 4259 2457 1999 3172 1012 2043 7207 2150 2343 1010 9594 17327 2001 2805 2004 5482 4905 2236 1010 2029 2003 1996 2353 2087 3928 2711 1999 1996 3425 2533 1012 2010 2564 2003 10514 13471 2532 1036 1036 28722 1005 1005 9594 17327 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 56\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 57\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: hub ##bell\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000012\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 12\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] which he accepted . [SEP] he left the army in 1946 . as the recipient of a fellowship in composition , hanson after the war was able to resume his studies at the con ##ser ##vat ##ori ##um . following a year of study with alex bernard , the con ##ser ##vat ##ori ##um offered hanson a place on the staff which he accepted . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:5 13:6 14:7 15:8 16:9 17:10 18:11 19:12 20:13 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:22 31:23 32:24 33:25 34:26 35:26 36:26 37:26 38:26 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:34 49:35 50:36 51:36 52:36 53:36 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:43 62:44 63:45 64:46 65:46\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 2029 2002 3970 1012 102 2002 2187 1996 2390 1999 3918 1012 2004 1996 7799 1997 1037 7881 1999 5512 1010 17179 2044 1996 2162 2001 2583 2000 13746 2010 2913 2012 1996 9530 8043 22879 10050 2819 1012 2206 1037 2095 1997 2817 2007 4074 6795 1010 1996 9530 8043 22879 10050 2819 3253 17179 1037 2173 2006 1996 3095 2029 2002 3970 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 56\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 56\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: hanson\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000013\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 13\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] bill . she recently played the [SEP] nicola alexis is a british actress best known for playing the role of w ##pc ruby bu ##xton in the long running itv drama the bill . she recently played the lead role in the theatre adaptation of carl hi ##aa ##sen ' s lucky you , which premiered at the edinburgh festival fringe in 2008 . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:13 23:14 24:15 25:15 26:16 27:17 28:18 29:19 30:20 31:21 32:22 33:23 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:36 49:36 50:36 51:36 52:37 53:38 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:47\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 3021 1012 2016 3728 2209 1996 102 17388 13573 2003 1037 2329 3883 2190 2124 2005 2652 1996 2535 1997 1059 15042 10090 20934 14226 1999 1996 2146 2770 11858 3689 1996 3021 1012 2016 3728 2209 1996 2599 2535 1999 1996 3004 6789 1997 5529 7632 11057 5054 1005 1055 5341 2017 1010 2029 5885 2012 1996 5928 2782 13548 1999 2263 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 8\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 9\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: nicola alexis\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000014\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 14\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] that his father ' s garage had [SEP] indeed , buster was fully intended to exist in place of spike for the comic book series , until the release of the fortress maximus toy in 1987 , which included spike as a headmaster partner , hence nec ##ess ##itating the hurried introduction of spike into the comic book continuity . returning home from college to discover that his father ' s garage had been destroyed , spike investigated the auto ##bots ' deserted base at mount saint hillary , learning that buster had been captured by the earth - based dec ##ept ##icon ##s . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:22 34:23 35:24 36:25 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:43 59:44 60:44 61:45 62:46 63:47 64:48 65:49 66:50 67:51 68:52 69:53 70:53 71:53 72:54 73:55 74:56 75:57 76:57 77:58 78:59 79:60 80:61 81:61 82:61 83:62 84:63 85:64 86:65 87:66 88:67 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:76 100:76 101:77 102:77 103:77 104:77 105:77\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 2008 2010 2269 1005 1055 7381 2018 102 5262 1010 18396 2001 3929 3832 2000 4839 1999 2173 1997 9997 2005 1996 5021 2338 2186 1010 2127 1996 2713 1997 1996 7841 21692 9121 1999 3055 1010 2029 2443 9997 2004 1037 16296 4256 1010 6516 26785 7971 16518 1996 9520 4955 1997 9997 2046 1996 5021 2338 13717 1012 4192 2188 2013 2267 2000 7523 2008 2010 2269 1005 1055 7381 2018 2042 3908 1010 9997 10847 1996 8285 27014 1005 12768 2918 2012 4057 3002 18520 1010 4083 2008 18396 2018 2042 4110 2011 1996 3011 1011 2241 11703 23606 28524 2015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 77\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 77\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: spike\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000015\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 15\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] 1979 . she also starred in [SEP] in the late 1970s , she toured in musical comedies including sammy ca ##hn ' s words and music . after appearing with mickey rooney in the play goodnight ladies in chicago , the producers cast ann jillian to appear in the original company of sugar babies on broadway with mickey rooney and ann miller in 1979 . she also starred in i love my wife at the drury lane theatre in chicago . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:11 22:11 23:11 24:12 25:13 26:14 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:37 52:38 53:39 54:40 55:41 56:42 57:43 58:44 59:45 60:46 61:47 62:48 63:49 64:50 65:50 66:51 67:52 68:53 69:54 70:55 71:56 72:57 73:58 74:59 75:60 76:61 77:62 78:63 79:64 80:65 81:65\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 3245 1012 2016 2036 5652 1999 102 1999 1996 2397 3955 1010 2016 7255 1999 3315 22092 2164 14450 6187 7295 1005 1055 2616 1998 2189 1012 2044 6037 2007 11021 24246 1999 1996 2377 22708 6456 1999 3190 1010 1996 6443 3459 5754 27286 2000 3711 1999 1996 2434 2194 1997 5699 10834 2006 5934 2007 11021 24246 1998 5754 4679 1999 3245 1012 2016 2036 5652 1999 1045 2293 2026 2564 2012 1996 25663 4644 3004 1999 3190 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 44\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 45\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: ann jillian\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000016\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 16\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] selected her to appear in [SEP] jennifer slept here ended in 1984 , enabling her to take a role in the miniseries ellis island , co - starring richard burton , faye dun ##away , ben ve ##reen and liam nee ##son . dun ##away and ve ##reen were nominated for golden globe awards , and jillian and burton were nominated for emmy awards . bob hope selected her to appear in six of his television specials , including two entertaining u . s . troops stationed in beirut ( 1984 ) and saudi arabia ( 1991 ) . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:16 26:17 27:17 28:17 29:18 30:19 31:19 32:20 33:21 34:21 35:21 36:22 37:23 38:23 39:24 40:25 41:26 42:26 43:26 44:27 45:27 46:28 47:29 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:41 62:42 63:43 64:44 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:57 80:58 81:59 82:60 83:60 84:60 85:60 86:61 87:62 88:63 89:64 90:65 91:65 92:65 93:66 94:67 95:68 96:69 97:69 98:69 99:69\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 3479 2014 2000 3711 1999 102 7673 7771 2182 3092 1999 3118 1010 12067 2014 2000 2202 1037 2535 1999 1996 13612 8547 2479 1010 2522 1011 4626 2957 9658 1010 19243 24654 9497 1010 3841 2310 28029 1998 8230 7663 3385 1012 24654 9497 1998 2310 28029 2020 4222 2005 3585 7595 2982 1010 1998 27286 1998 9658 2020 4222 2005 10096 2982 1012 3960 3246 3479 2014 2000 3711 1999 2416 1997 2010 2547 19247 1010 2164 2048 14036 1057 1012 1055 1012 3629 8895 1999 15335 1006 3118 1007 1998 8174 9264 1006 2889 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 57\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 57\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: jillian\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000017\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 17\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] since her predecessor elisabeth vol ##km ##ann [SEP] on may 17 , 2004 , when the very successful die harald schmidt show left sat . 1 , eng ##el ##ke took over its times ##lot with an ##ke late night , which was cancelled due to low ratings a few months later on october 21 , 2004 . eng ##el ##ke is the german voice of marge simpson on the simpsons since her predecessor elisabeth vol ##km ##ann died in the summer of 2006 . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:2 13:3 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:13 26:13 27:13 28:14 29:14 30:14 31:15 32:16 33:17 34:18 35:18 36:19 37:20 38:20 39:21 40:22 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:36 57:37 58:37 59:38 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:59\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 2144 2014 8646 12877 5285 22287 11639 102 2006 2089 2459 1010 2432 1010 2043 1996 2200 3144 3280 20966 12940 2265 2187 2938 1012 1015 1010 25540 2884 3489 2165 2058 2049 2335 10994 2007 2019 3489 2397 2305 1010 2029 2001 8014 2349 2000 2659 8599 1037 2261 2706 2101 2006 2255 2538 1010 2432 1012 25540 2884 3489 2003 1996 2446 2376 1997 25532 9304 2006 1996 19047 2144 2014 8646 12877 5285 22287 11639 2351 1999 1996 2621 1997 2294 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 59\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 61\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: eng ##el ##ke\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000018\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 18\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] tuscany . he was born into [SEP] antonio di filippo di lorenzo nic ##col ##ini ( florence , 1701 - - 1769 ) was an italian abbot , jurist and scholar , who was considered one of the leading figures of eighteenth - century tuscany . he was born into a noble fl ##ore ##ntine family , the youngest child of filippo , third marquess of po ##ns ##ac ##co and cam ##ug ##lian ##o , and was a relative of the pope . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:5 16:6 17:6 18:6 19:7 20:7 21:7 22:7 23:7 24:8 25:9 26:10 27:11 28:11 29:12 30:13 31:14 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:23 42:24 43:24 44:24 45:25 46:25 47:26 48:27 49:28 50:29 51:30 52:31 53:32 54:32 55:32 56:33 57:33 58:34 59:35 60:36 61:37 62:38 63:38 64:39 65:40 66:41 67:42 68:42 69:42 70:42 71:43 72:44 73:44 74:44 75:44 76:44 77:45 78:46 79:47 80:48 81:49 82:50 83:51 84:51\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 23322 1012 2002 2001 2141 2046 102 4980 4487 28669 4487 12484 27969 25778 5498 1006 7701 1010 26059 1011 1011 20663 1007 2001 2019 3059 11428 1010 22757 1998 6288 1010 2040 2001 2641 2028 1997 1996 2877 4481 1997 12965 1011 2301 23322 1012 2002 2001 2141 2046 1037 7015 13109 5686 26730 2155 1010 1996 6587 2775 1997 28669 1010 2353 17391 1997 13433 3619 6305 3597 1998 11503 15916 15204 2080 1010 1998 2001 1037 5816 1997 1996 4831 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 8\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 15\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: antonio di filippo di lorenzo nic ##col ##ini\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   unique_id: 1000000019\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   example_index: 19\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   tokens: [CLS] of his novel by the [SEP] ra ##bel ##ais traveled frequently to rome with his friend cardinal jean du bella ##y , and lived for a short time in turin with du bella ##y ' s brother , guillaume , during which fran * o ##is i was his patron . ra ##bel ##ais probably spent some time in hiding , threatened by being labeled a here ##tic . only the protection of du bella ##y saved ra ##bel ##ais after the condemnation of his novel by the sorbonne . [SEP]\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_to_orig_map: 7:0 8:0 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:11 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:22 34:22 35:22 36:22 37:23 38:23 39:24 40:24 41:25 42:26 43:27 44:27 45:27 46:27 47:28 48:29 49:30 50:31 51:31 52:32 53:32 54:32 55:33 56:34 57:35 58:36 59:37 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:44 69:44 70:45 71:46 72:47 73:48 74:49 75:50 76:50 77:51 78:52 79:52 80:52 81:53 82:54 83:55 84:56 85:57 86:58 87:59 88:60 89:61 90:61\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_ids: 101 1997 2010 3117 2011 1996 102 10958 8671 15593 6158 4703 2000 4199 2007 2010 2767 7185 3744 4241 12101 2100 1010 1998 2973 2005 1037 2460 2051 1999 13667 2007 4241 12101 2100 1005 1055 2567 1010 20061 1010 2076 2029 23151 1008 1051 2483 1045 2001 2010 9161 1012 10958 8671 15593 2763 2985 2070 2051 1999 6318 1010 5561 2011 2108 12599 1037 2182 4588 1012 2069 1996 3860 1997 4241 12101 2100 5552 10958 8671 15593 2044 1996 26248 1997 2010 3117 2011 1996 28452 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   start_position: 78\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   end_position: 80\n",
      "05/02/2019 16:45:00 - INFO - __main__ -   answer: ra ##bel ##ais\n",
      "05/02/2019 16:45:04 - INFO - __main__ -   ***** Running training *****\n",
      "05/02/2019 16:45:04 - INFO - __main__ -     Num orig examples = 1737\n",
      "05/02/2019 16:45:04 - INFO - __main__ -     Num split examples = 1740\n",
      "05/02/2019 16:45:04 - INFO - __main__ -     Batch size = 12\n",
      "05/02/2019 16:45:04 - INFO - __main__ -     Num steps = 288\n",
      "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/145 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.8715105056762695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/145 [00:01<02:47,  1.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.861325263977051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|▏         | 2/145 [00:02<02:36,  1.09s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.867560386657715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 3/145 [00:03<02:28,  1.04s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.7972731590271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|▎         | 4/145 [00:03<02:22,  1.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.782127380371094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|▎         | 5/145 [00:04<02:17,  1.01it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.699764251708984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|▍         | 6/145 [00:05<02:14,  1.03it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.619152069091797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|▍         | 7/145 [00:06<02:12,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.438771724700928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▌         | 8/145 [00:07<02:10,  1.05it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.504520416259766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▌         | 9/145 [00:08<02:08,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.120607376098633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|▋         | 10/145 [00:09<02:06,  1.06it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 5.2071428298950195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 11/145 [00:10<02:05,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.84064245223999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 12/145 [00:11<02:04,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.695480823516846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|▉         | 13/145 [00:12<02:03,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.742727279663086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|▉         | 14/145 [00:13<02:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 4.118405342102051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|█         | 15/145 [00:14<02:01,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.8281655311584473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|█         | 16/145 [00:15<02:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.5564768314361572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▏        | 17/145 [00:16<01:59,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 3.2338292598724365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▏        | 18/145 [00:16<01:58,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.9646143913269043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|█▎        | 19/145 [00:17<01:57,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.685448169708252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█▍        | 20/145 [00:18<01:56,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.049759864807129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█▍        | 21/145 [00:19<01:55,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8363356590270996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|█▌        | 22/145 [00:20<01:54,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3898394107818604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|█▌        | 23/145 [00:21<01:53,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7085070610046387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|█▋        | 24/145 [00:22<01:52,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5384392738342285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|█▋        | 25/145 [00:23<01:51,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.660534381866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|█▊        | 26/145 [00:24<01:50,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6040244102478027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▊        | 27/145 [00:25<01:49,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4661915302276611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 28/145 [00:26<01:49,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2834579944610596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|██        | 29/145 [00:27<01:48,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6117208003997803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██        | 30/145 [00:28<01:47,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.092018961906433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██▏       | 31/145 [00:29<01:46,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0814510583877563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|██▏       | 32/145 [00:30<01:45,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.5071301460266113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|██▎       | 33/145 [00:30<01:44,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.9817649126052856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|██▎       | 34/145 [00:31<01:43,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3268392086029053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|██▍       | 35/145 [00:32<01:42,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.8156523704528809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▍       | 36/145 [00:33<01:41,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.606353998184204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██▌       | 37/145 [00:34<01:41,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.731170654296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██▌       | 38/145 [00:35<01:40,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6261159181594849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|██▋       | 39/145 [00:36<01:39,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0176911354064941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 40/145 [00:37<01:38,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5750186443328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 41/145 [00:38<01:37,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0936455726623535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|██▉       | 42/145 [00:39<01:36,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9083608388900757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|██▉       | 43/145 [00:40<01:35,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6688380241394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|███       | 44/145 [00:41<01:34,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8276156187057495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███       | 45/145 [00:42<01:33,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8917223811149597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|███▏      | 46/145 [00:43<01:32,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.215299367904663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|███▏      | 47/145 [00:44<01:31,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.058619737625122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|███▎      | 48/145 [00:44<01:30,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.57561194896698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███▍      | 49/145 [00:45<01:29,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8691554069519043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███▍      | 50/145 [00:46<01:28,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6202476024627686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|███▌      | 51/145 [00:47<01:27,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6682355403900146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  36%|███▌      | 52/145 [00:48<01:26,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.435158371925354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|███▋      | 53/145 [00:49<01:25,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7197849750518799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|███▋      | 54/145 [00:50<01:24,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5902529954910278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 55/145 [00:51<01:23,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8234772682189941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|███▊      | 56/145 [00:52<01:22,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4936937093734741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|███▉      | 57/145 [00:53<01:21,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8249622583389282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|████      | 58/145 [00:54<01:21,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7610199451446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|████      | 59/145 [00:55<01:20,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0614962577819824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|████▏     | 60/145 [00:56<01:19,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5441094636917114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  42%|████▏     | 61/145 [00:57<01:18,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.958791971206665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|████▎     | 62/145 [00:58<01:17,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7622014284133911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|████▎     | 63/145 [00:58<01:16,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0476667881011963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 64/145 [00:59<01:15,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.4776197671890259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|████▍     | 65/145 [01:00<01:14,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.162919282913208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|████▌     | 66/145 [01:01<01:13,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7121552228927612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|████▌     | 67/145 [01:02<01:12,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5346634984016418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|████▋     | 68/145 [01:03<01:11,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9809370636940002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|████▊     | 69/145 [01:04<01:10,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6564507484436035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|████▊     | 70/145 [01:05<01:09,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3657933473587036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  49%|████▉     | 71/145 [01:06<01:08,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7176196575164795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|████▉     | 72/145 [01:07<01:07,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.485907793045044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 73/145 [01:08<01:07,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7677430510520935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  51%|█████     | 74/145 [01:09<01:06,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2893388271331787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|█████▏    | 75/145 [01:10<01:05,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3526870012283325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|█████▏    | 76/145 [01:11<01:04,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0267276763916016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|█████▎    | 77/145 [01:11<01:03,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9894533157348633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|█████▍    | 78/145 [01:12<01:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6469285488128662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|█████▍    | 79/145 [01:13<01:01,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7662137746810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 80/145 [01:14<01:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2648810148239136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▌    | 81/145 [01:15<00:59,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7555862665176392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|█████▋    | 82/145 [01:16<00:58,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8688740134239197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|█████▋    | 83/145 [01:17<00:57,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0718988180160522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  58%|█████▊    | 84/145 [01:18<00:56,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1747075319290161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▊    | 85/145 [01:19<00:55,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1410690546035767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▉    | 86/145 [01:20<00:54,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.113013505935669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|██████    | 87/145 [01:21<00:54,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6648385524749756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|██████    | 88/145 [01:22<00:53,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1918420791625977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|██████▏   | 89/145 [01:23<00:52,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8347129821777344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▏   | 90/145 [01:24<00:51,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.095557689666748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|██████▎   | 91/145 [01:25<00:50,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6554478406906128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|██████▎   | 92/145 [01:25<00:49,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6415379047393799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  64%|██████▍   | 93/145 [01:26<00:48,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8916252851486206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|██████▍   | 94/145 [01:27<00:47,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.196712851524353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|██████▌   | 95/145 [01:28<00:46,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7141375541687012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|██████▌   | 96/145 [01:29<00:45,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9551658630371094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|██████▋   | 97/145 [01:30<00:44,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2666691541671753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|██████▊   | 98/145 [01:31<00:43,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.318522572517395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|██████▊   | 99/145 [01:32<00:42,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7762788534164429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 100/145 [01:33<00:41,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8452898859977722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|██████▉   | 101/145 [01:34<00:40,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.282812476158142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|███████   | 102/145 [01:35<00:40,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7476457953453064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|███████   | 103/145 [01:36<00:39,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30615663528442383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|███████▏  | 104/145 [01:37<00:38,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0005899667739868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|███████▏  | 105/145 [01:38<00:37,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0011663436889648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|███████▎  | 106/145 [01:38<00:36,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4781731367111206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|███████▍  | 107/145 [01:39<00:35,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8780045509338379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|███████▍  | 108/145 [01:40<00:34,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3093724846839905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 109/145 [01:41<00:33,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0940197706222534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  76%|███████▌  | 110/145 [01:42<00:32,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8517390489578247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|███████▋  | 111/145 [01:43<00:31,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7897692918777466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|███████▋  | 112/145 [01:44<00:30,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2397666573524475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|███████▊  | 113/145 [01:45<00:29,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1512377262115479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|███████▊  | 114/145 [01:46<00:28,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5161793828010559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|███████▉  | 115/145 [01:47<00:27,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9582760334014893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|████████  | 116/145 [01:48<00:27,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.741068422794342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████  | 117/145 [01:49<00:26,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5179610252380371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 118/145 [01:50<00:25,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.31677401065826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  82%|████████▏ | 119/145 [01:51<00:24,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17216631770133972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%|████████▎ | 120/145 [01:52<00:23,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8002053499221802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%|████████▎ | 121/145 [01:52<00:22,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26429882645606995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%|████████▍ | 122/145 [01:53<00:21,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30317795276641846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%|████████▍ | 123/145 [01:54<00:20,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.46991825103759766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%|████████▌ | 124/145 [01:55<00:19,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0538450479507446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%|████████▌ | 125/145 [01:56<00:18,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.428166151046753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%|████████▋ | 126/145 [01:57<00:17,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6600968837738037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 127/145 [01:58<00:16,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3574053943157196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 128/145 [01:59<00:15,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5460360050201416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  89%|████████▉ | 129/145 [02:00<00:14,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7721656560897827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%|████████▉ | 130/145 [02:01<00:13,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8885635137557983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%|█████████ | 131/145 [02:02<00:13,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24706625938415527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%|█████████ | 132/145 [02:03<00:12,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6132175326347351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|█████████▏| 133/145 [02:04<00:11,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5632258057594299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|█████████▏| 134/145 [02:05<00:10,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8541563153266907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  93%|█████████▎| 135/145 [02:05<00:09,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4413735270500183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 136/145 [02:06<00:08,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2636313438415527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 137/145 [02:07<00:07,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.41978734731674194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|█████████▌| 138/145 [02:08<00:06,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8708992004394531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|█████████▌| 139/145 [02:09<00:05,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.43644195795059204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|█████████▋| 140/145 [02:10<00:04,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7438925504684448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|█████████▋| 141/145 [02:11<00:03,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9576178193092346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|█████████▊| 142/145 [02:12<00:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.3295819759368896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|█████████▊| 143/145 [02:13<00:01,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9200907945632935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|█████████▉| 144/145 [02:14<00:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4758354723453522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch:  50%|█████     | 1/2 [02:15<02:15, 135.32s/it]\n",
      "Iteration:   0%|          | 0/145 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6066654324531555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|          | 1/145 [00:00<02:13,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3947090804576874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   1%|▏         | 2/145 [00:01<02:12,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3863118290901184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   2%|▏         | 3/145 [00:02<02:12,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5719528198242188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|▎         | 4/145 [00:03<02:11,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5925866365432739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   3%|▎         | 5/145 [00:04<02:10,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5357756018638611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   4%|▍         | 6/145 [00:05<02:09,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5981413722038269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   5%|▍         | 7/145 [00:06<02:08,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3563840389251709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▌         | 8/145 [00:07<02:07,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6687853336334229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   6%|▌         | 9/145 [00:08<02:06,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7078253030776978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   7%|▋         | 10/145 [00:09<02:05,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30951255559921265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 11/145 [00:10<02:04,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.334755539894104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   8%|▊         | 12/145 [00:11<02:03,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.33434319496154785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:   9%|▉         | 13/145 [00:12<02:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.15999305248260498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|▉         | 14/145 [00:13<02:01,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0783649682998657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  10%|█         | 15/145 [00:13<02:00,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.28186511993408203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  11%|█         | 16/145 [00:14<01:59,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.502832293510437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▏        | 17/145 [00:15<01:59,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5700883865356445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  12%|█▏        | 18/145 [00:16<01:58,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2141198217868805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  13%|█▎        | 19/145 [00:17<01:57,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9892795085906982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█▍        | 20/145 [00:18<01:56,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3076283037662506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  14%|█▍        | 21/145 [00:19<01:55,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5346529483795166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  15%|█▌        | 22/145 [00:20<01:54,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22654381394386292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  16%|█▌        | 23/145 [00:21<01:53,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.48160111904144287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|█▋        | 24/145 [00:22<01:52,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1488586664199829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  17%|█▋        | 25/145 [00:23<01:51,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.1322662830352783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  18%|█▊        | 26/145 [00:24<01:50,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22595982253551483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▊        | 27/145 [00:25<01:49,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.403510570526123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  19%|█▉        | 28/145 [00:26<01:48,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4374893307685852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  20%|██        | 29/145 [00:26<01:47,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8481990098953247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██        | 30/145 [00:27<01:46,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.11970452964305878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  21%|██▏       | 31/145 [00:28<01:46,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.06295263767242432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  22%|██▏       | 32/145 [00:29<01:45,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.280785471200943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|██▎       | 33/145 [00:30<01:44,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.47348782420158386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  23%|██▎       | 34/145 [00:31<01:43,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34155717492103577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  24%|██▍       | 35/145 [00:32<01:42,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.28034716844558716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  25%|██▍       | 36/145 [00:33<01:41,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.046090446412563324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██▌       | 37/145 [00:34<01:40,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.7077782154083252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  26%|██▌       | 38/145 [00:35<01:39,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.6841195821762085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  27%|██▋       | 39/145 [00:36<01:38,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6263343095779419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 40/145 [00:37<01:37,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5498529672622681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  28%|██▊       | 41/145 [00:38<01:36,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.506902277469635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  29%|██▉       | 42/145 [00:39<01:35,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.2281198501586914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|██▉       | 43/145 [00:40<01:35,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2903396487236023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  30%|███       | 44/145 [00:40<01:34,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5219898819923401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  31%|███       | 45/145 [00:41<01:33,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1201164573431015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|███▏      | 46/145 [00:42<01:32,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30340373516082764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  32%|███▏      | 47/145 [00:43<01:31,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.39661866426467896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  33%|███▎      | 48/145 [00:44<01:30,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4468085765838623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███▍      | 49/145 [00:45<01:29,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.09745724499225616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  34%|███▍      | 50/145 [00:46<01:28,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34905922412872314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  35%|███▌      | 51/145 [00:47<01:27,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2229446917772293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  36%|███▌      | 52/145 [00:48<01:26,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5179957747459412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|███▋      | 53/145 [00:49<01:25,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21654489636421204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  37%|███▋      | 54/145 [00:50<01:24,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.31901735067367554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  38%|███▊      | 55/145 [00:51<01:23,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7859119176864624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|███▊      | 56/145 [00:52<01:22,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.44093674421310425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  39%|███▉      | 57/145 [00:53<01:21,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.38402271270751953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  40%|████      | 58/145 [00:53<01:21,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0269677639007568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|████      | 59/145 [00:54<01:20,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.22938835620880127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  41%|████▏     | 60/145 [00:55<01:19,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7186936140060425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  42%|████▏     | 61/145 [00:56<01:18,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08349994570016861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|████▎     | 62/145 [00:57<01:17,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.35319608449935913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  43%|████▎     | 63/145 [00:58<01:16,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.32114750146865845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  44%|████▍     | 64/145 [00:59<01:15,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4043726325035095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  45%|████▍     | 65/145 [01:00<01:14,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6956925988197327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|████▌     | 66/145 [01:01<01:13,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2739059329032898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  46%|████▌     | 67/145 [01:02<01:12,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.36124134063720703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  47%|████▋     | 68/145 [01:03<01:11,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.745342493057251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|████▊     | 69/145 [01:04<01:10,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6730337142944336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  48%|████▊     | 70/145 [01:05<01:10,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.29403239488601685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  49%|████▉     | 71/145 [01:06<01:09,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5683594942092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|████▉     | 72/145 [01:07<01:08,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8682581186294556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  50%|█████     | 73/145 [01:07<01:07,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.21570560336112976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  51%|█████     | 74/145 [01:08<01:06,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.38342225551605225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|█████▏    | 75/145 [01:09<01:05,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9170408248901367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  52%|█████▏    | 76/145 [01:10<01:04,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4814896881580353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  53%|█████▎    | 77/145 [01:11<01:03,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3865450620651245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|█████▍    | 78/145 [01:12<01:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.40721774101257324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  54%|█████▍    | 79/145 [01:13<01:01,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5460205078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  55%|█████▌    | 80/145 [01:14<01:00,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5320748090744019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  56%|█████▌    | 81/145 [01:15<00:59,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8010726571083069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|█████▋    | 82/145 [01:16<00:58,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2969386577606201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  57%|█████▋    | 83/145 [01:17<00:57,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8604586124420166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  58%|█████▊    | 84/145 [01:18<00:56,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4566326141357422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▊    | 85/145 [01:19<00:55,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8156020045280457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  59%|█████▉    | 86/145 [01:20<00:54,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34038347005844116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  60%|██████    | 87/145 [01:20<00:53,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4752575159072876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|██████    | 88/145 [01:21<00:53,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8779505491256714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  61%|██████▏   | 89/145 [01:22<00:52,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.18966758251190186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  62%|██████▏   | 90/145 [01:23<00:51,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5257543325424194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|██████▎   | 91/145 [01:24<00:50,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1745949536561966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  63%|██████▎   | 92/145 [01:25<00:49,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6187422871589661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  64%|██████▍   | 93/145 [01:26<00:48,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8106874227523804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  65%|██████▍   | 94/145 [01:27<00:47,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.19461947679519653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|██████▌   | 95/145 [01:28<00:46,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7697899341583252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  66%|██████▌   | 96/145 [01:29<00:45,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.8751398921012878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  67%|██████▋   | 97/145 [01:30<00:44,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7959267497062683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|██████▊   | 98/145 [01:31<00:43,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.26371997594833374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  68%|██████▊   | 99/145 [01:32<00:42,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1119549572467804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  69%|██████▉   | 100/145 [01:33<00:41,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3177783191204071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|██████▉   | 101/145 [01:34<00:40,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7667547464370728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  70%|███████   | 102/145 [01:34<00:39,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6889169216156006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  71%|███████   | 103/145 [01:35<00:39,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5607614517211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|███████▏  | 104/145 [01:36<00:38,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.457019567489624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  72%|███████▏  | 105/145 [01:37<00:37,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2850682735443115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  73%|███████▎  | 106/145 [01:38<00:36,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.17659515142440796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|███████▍  | 107/145 [01:39<00:35,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.0347623825073242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  74%|███████▍  | 108/145 [01:40<00:34,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1393018662929535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  75%|███████▌  | 109/145 [01:41<00:33,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.6216451525688171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  76%|███████▌  | 110/145 [01:42<00:32,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3065412640571594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|███████▋  | 111/145 [01:43<00:31,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2363768219947815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  77%|███████▋  | 112/145 [01:44<00:30,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.29215508699417114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  78%|███████▊  | 113/145 [01:45<00:29,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.586383581161499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|███████▊  | 114/145 [01:46<00:28,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0470573715865612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  79%|███████▉  | 115/145 [01:47<00:27,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.3894878029823303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  80%|████████  | 116/145 [01:47<00:26,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.24164614081382751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████  | 117/145 [01:48<00:26,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7242708206176758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  81%|████████▏ | 118/145 [01:49<00:25,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.582251250743866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  82%|████████▏ | 119/145 [01:50<00:24,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.09114076942205429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%|████████▎ | 120/145 [01:51<00:23,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.16685520112514496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  83%|████████▎ | 121/145 [01:52<00:22,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23709294199943542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  84%|████████▍ | 122/145 [01:53<00:21,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.25692465901374817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  85%|████████▍ | 123/145 [01:54<00:20,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.34231454133987427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%|████████▌ | 124/145 [01:55<00:19,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.848867654800415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  86%|████████▌ | 125/145 [01:56<00:18,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.12582199275493622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  87%|████████▋ | 126/145 [01:57<00:17,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.40047988295555115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 127/145 [01:58<00:16,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5399009585380554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  88%|████████▊ | 128/145 [01:59<00:15,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7497513294219971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  89%|████████▉ | 129/145 [02:00<00:14,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0937008410692215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%|████████▉ | 130/145 [02:00<00:13,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.13903498649597168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  90%|█████████ | 131/145 [02:01<00:13,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.16368919610977173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  91%|█████████ | 132/145 [02:02<00:12,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.20028935372829437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|█████████▏| 133/145 [02:03<00:11,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.30388447642326355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  92%|█████████▏| 134/145 [02:04<00:10,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.2142198383808136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  93%|█████████▎| 135/145 [02:05<00:09,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5280216932296753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 136/145 [02:06<00:08,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.08750977367162704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  94%|█████████▍| 137/145 [02:07<00:07,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.37129098176956177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  95%|█████████▌| 138/145 [02:08<00:06,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 1.076167106628418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  96%|█████████▌| 139/145 [02:09<00:05,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1192859634757042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|█████████▋| 140/145 [02:10<00:04,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.1521834433078766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  97%|█████████▋| 141/145 [02:11<00:03,  1.08it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.9476394057273865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  98%|█████████▊| 142/145 [02:12<00:02,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4550390839576721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|█████████▊| 143/145 [02:13<00:01,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.23730838298797607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration:  99%|█████████▉| 144/145 [02:13<00:00,  1.07it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.49594545364379883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/02/2019 16:49:35 - WARNING - pytorch_pretrained_bert.optimization -   Training beyond specified 't_total'. Learning rate multiplier set to 0.0. Please set 't_total' of WarmupLinearSchedule correctly.\n",
      "\n",
      "Epoch: 100%|██████████| 2/2 [04:30<00:00, 135.20s/it]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000000\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] uncles . his cousin is minnesota [SEP] upon their acceptance into the ko ##ntine ##ntal hockey league , de ##hner left finland to sign a contract in germany with eh ##c m * nc ##hen of the del on june 18 , 2014 . after capturing the german championship with the m * nc ##hen team in 2016 , he left the club and was picked up by fellow del side eh ##c wolf ##sburg in july 2016 . former nhl ##er gary su ##ter and olympic - medalist bob su ##ter are de ##hner ' s uncles . his cousin is minnesota wild ' s alternate captain ryan su ##ter . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:5 16:6 17:7 18:7 19:8 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:18 32:19 33:19 34:19 35:19 36:20 37:21 38:22 39:23 40:24 41:25 42:25 43:26 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:34 54:34 55:34 56:35 57:36 58:37 59:37 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:50 74:51 75:51 76:52 77:53 78:54 79:54 80:55 81:56 82:56 83:57 84:58 85:58 86:59 87:60 88:60 89:60 90:61 91:62 92:62 93:63 94:64 95:64 96:64 97:64 98:65 99:65 100:66 101:67 102:68 103:69 104:70 105:70 106:70 107:71 108:72 109:73 110:74 111:74 112:74\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 27328 1012 2010 5542 2003 5135 102 2588 2037 9920 2046 1996 12849 26730 15758 3873 2223 1010 2139 28989 2187 6435 2000 3696 1037 3206 1999 2762 2007 15501 2278 1049 1008 13316 10222 1997 1996 3972 2006 2238 2324 1010 2297 1012 2044 11847 1996 2446 2528 2007 1996 1049 1008 13316 10222 2136 1999 2355 1010 2002 2187 1996 2252 1998 2001 3856 2039 2011 3507 3972 2217 15501 2278 4702 9695 1999 2251 2355 1012 2280 7097 2121 5639 10514 3334 1998 4386 1011 12968 3960 10514 3334 2024 2139 28989 1005 1055 27328 1012 2010 5542 2003 5135 3748 1005 1055 6585 2952 4575 10514 3334 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000001\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 1\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] selected him for the first [SEP] between the years 1979 - 1981 , river won four local titles , and became one of the most expensive teams in the world , with a first team ( alonso - lu ##que ) playing in league games and an equally prestigious second team ( carr ##asco - ram * n d * az ) used mostly in copa libertadores matches . during the 1981 ` ` nacional ' ' tournament ( which river would eventually win ) , alonso often clashed with then coach alfredo di st * fan ##o ( who seldom selected him for the first team and instead put younger players such as carlos daniel tap ##ia and jose maria viet ##a in his position ) . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:3 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:19 32:20 33:21 34:22 35:23 36:24 37:24 38:24 39:25 40:25 41:25 42:26 43:27 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:36 54:36 55:36 56:37 57:37 58:37 59:38 60:38 61:38 62:38 63:39 64:40 65:41 66:42 67:43 68:44 69:44 70:45 71:46 72:47 73:48 74:48 75:48 76:48 77:48 78:49 79:50 80:50 81:51 82:52 83:53 84:54 85:54 86:54 87:55 88:56 89:57 90:58 91:59 92:60 93:61 94:62 95:63 96:63 97:63 98:63 99:64 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:71 108:72 109:73 110:74 111:75 112:76 113:77 114:78 115:79 116:80 117:81 118:81 119:82 120:83 121:84 122:85 123:85 124:86 125:87 126:88 127:88 128:88\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 3479 2032 2005 1996 2034 102 2090 1996 2086 3245 1011 3261 1010 2314 2180 2176 2334 4486 1010 1998 2150 2028 1997 1996 2087 6450 2780 1999 1996 2088 1010 2007 1037 2034 2136 1006 17649 1011 11320 4226 1007 2652 1999 2223 2399 1998 2019 8053 8919 2117 2136 1006 12385 28187 1011 8223 1008 1050 1040 1008 17207 1007 2109 3262 1999 10613 27968 3503 1012 2076 1996 3261 1036 1036 10718 1005 1005 2977 1006 2029 2314 2052 2776 2663 1007 1010 17649 2411 22600 2007 2059 2873 19423 4487 2358 1008 5470 2080 1006 2040 15839 3479 2032 2005 1996 2034 2136 1998 2612 2404 3920 2867 2107 2004 5828 3817 11112 2401 1998 4560 3814 19710 2050 1999 2010 2597 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000002\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 2\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] regime . he was ambushed with [SEP] though his emigration from the country has affected his leadership status , kam ##el is still a respected elder of the clan . after the fall of hu ##ssi ##en ' s regime , many considered dr . ali ala ##dha ##dh a candidate to lead the clan . a contributor to iraq ' s liberation , ali ala ##dha ##dh and a long time oppose to saddam ' s regime . he was ambushed with his pregnant wife on his way to the hospital in 2006 by iraqi insurgents . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:11 22:12 23:13 24:14 25:15 26:16 27:17 28:18 29:19 30:19 31:20 32:21 33:22 34:23 35:24 36:24 37:24 38:24 39:24 40:25 41:25 42:26 43:27 44:28 45:28 46:29 47:30 48:30 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:36 57:37 58:38 59:39 60:40 61:40 62:40 63:41 64:41 65:42 66:43 67:43 68:43 69:44 70:45 71:46 72:47 73:48 74:49 75:50 76:50 77:50 78:51 79:51 80:52 81:53 82:54 83:55 84:56 85:57 86:58 87:59 88:60 89:61 90:62 91:63 92:64 93:65 94:66 95:67 96:68 97:69 98:69\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 6939 1012 2002 2001 22168 2007 102 2295 2010 20387 2013 1996 2406 2038 5360 2010 4105 3570 1010 27829 2884 2003 2145 1037 9768 6422 1997 1996 6338 1012 2044 1996 2991 1997 15876 18719 2368 1005 1055 6939 1010 2116 2641 2852 1012 4862 21862 17516 16425 1037 4018 2000 2599 1996 6338 1012 1037 12130 2000 5712 1005 1055 7931 1010 4862 21862 17516 16425 1998 1037 2146 2051 15391 2000 24111 1005 1055 6939 1012 2002 2001 22168 2007 2010 6875 2564 2006 2010 2126 2000 1996 2902 1999 2294 2011 8956 20541 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000003\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 3\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] during his trial pi ##sc ##iot ##ta could [SEP] at the trial , pi ##sc ##iot ##ta said : ` ` those who have made promises to us are called bernardo matt ##are ##lla , prince all ##ia ##ta , the monarch ##ist mp marches ##ano and also sign ##or sc ##el ##ba , minister for home affairs . . . it was marches ##ano , prince all ##ia ##ta and bernardo matt ##are ##lla who ordered the massacre of porte ##lla di gin ##estra . before the massacre they met gi ##ulia ##no . . . ' ' however the mps matt ##are ##lla , all ##ia ##ta and marches ##ano were declared innocent by the court of appeal of palermo , at a trial which dealt with their alleged role in the event . during his trial pi ##sc ##iot ##ta could not account for gi ##ulia ##no ' s documents in which he named the high - ranking government officials and ma ##fi ##osi involved with gi ##ulia ##no ' s band . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 10:0 11:1 12:2 13:2 14:3 15:3 16:3 17:3 18:4 19:4 20:5 21:5 22:5 23:6 24:7 25:8 26:9 27:10 28:11 29:12 30:13 31:14 32:15 33:15 34:15 35:15 36:16 37:17 38:17 39:17 40:17 41:18 42:19 43:19 44:20 45:21 46:21 47:22 48:23 49:24 50:24 51:25 52:25 53:25 54:25 55:26 56:27 57:28 58:29 59:30 60:30 61:30 62:31 63:32 64:33 65:33 66:33 67:34 68:35 69:35 70:35 71:36 72:37 73:38 74:38 75:38 76:39 77:40 78:41 79:42 80:43 81:44 82:44 83:45 84:46 85:46 86:46 87:47 88:48 89:49 90:50 91:51 92:52 93:52 94:52 95:52 96:52 97:52 98:52 99:52 100:53 101:54 102:55 103:56 104:56 105:56 106:56 107:57 108:57 109:57 110:58 111:59 112:59 113:60 114:61 115:62 116:63 117:64 118:65 119:66 120:67 121:68 122:69 123:69 124:70 125:71 126:72 127:73 128:74 129:75 130:76 131:77 132:78 133:79 134:80 135:81 136:81 137:82 138:83 139:84 140:85 141:85 142:85 143:85 144:86 145:87 146:88 147:89 148:90 149:90 150:90 151:90 152:90 153:91 154:92 155:93 156:94 157:95 158:96 159:97 160:97 161:97 162:98 163:99 164:100 165:101 166:101 167:101 168:102 169:103 170:104 171:104 172:104 173:104 174:104 175:105 176:105\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True 174:True 175:True 176:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2076 2010 3979 14255 11020 25185 2696 2071 102 2012 1996 3979 1010 14255 11020 25185 2696 2056 1024 1036 1036 2216 2040 2031 2081 10659 2000 2149 2024 2170 21175 4717 12069 4571 1010 3159 2035 2401 2696 1010 1996 11590 2923 6131 20691 6761 1998 2036 3696 2953 8040 2884 3676 1010 2704 2005 2188 3821 1012 1012 1012 2009 2001 20691 6761 1010 3159 2035 2401 2696 1998 21175 4717 12069 4571 2040 3641 1996 9288 1997 25927 4571 4487 18353 26199 1012 2077 1996 9288 2027 2777 21025 20922 3630 1012 1012 1012 1005 1005 2174 1996 12616 4717 12069 4571 1010 2035 2401 2696 1998 20691 6761 2020 4161 7036 2011 1996 2457 1997 5574 1997 18705 1010 2012 1037 3979 2029 9411 2007 2037 6884 2535 1999 1996 2724 1012 2076 2010 3979 14255 11020 25185 2696 2071 2025 4070 2005 21025 20922 3630 1005 1055 5491 1999 2029 2002 2315 1996 2152 1011 5464 2231 4584 1998 5003 8873 20049 2920 2007 21025 20922 3630 1005 1055 2316 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000004\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 4\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] before his discharge , eddie is [SEP] it is about a pair of united states navy shore patrol ##lers ( sp ##s ) ( tom be ##ren ##ger and william mcnamara ) who must escort a beautiful prisoner ( erika el ##enia ##k ) , and the troubles they encounter . eddie dev ##ane ( william mcnamara ) is a young sailor who has carried out a number of inventory - related sc ##ams along with his partner - in - crime howard ( crisp ##in glover ) and made a lot of money during his service . a day before his discharge , eddie is assigned to escort a prisoner from the marine base at camp le ##je ##une along with the authoritarian , no - nonsense chief petty officer rock reilly ( tom be ##ren ##ger ) . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:11 22:11 23:11 24:12 25:12 26:13 27:13 28:13 29:14 30:15 31:16 32:16 33:17 34:18 35:19 36:20 37:21 38:22 39:23 40:23 41:24 42:24 43:24 44:24 45:24 46:25 47:26 48:27 49:28 50:29 51:29 52:30 53:31 54:31 55:32 56:32 57:33 58:33 59:34 60:35 61:36 62:37 63:38 64:39 65:40 66:41 67:42 68:43 69:44 70:45 71:45 72:45 73:46 74:46 75:47 76:48 77:49 78:50 79:50 80:50 81:50 82:50 83:51 84:52 85:52 86:52 87:53 88:53 89:54 90:55 91:56 92:57 93:58 94:59 95:60 96:61 97:62 98:62 99:63 100:64 101:65 102:66 103:67 104:67 105:68 106:69 107:70 108:71 109:72 110:73 111:74 112:75 113:76 114:77 115:78 116:79 117:80 118:81 119:81 120:81 121:82 122:83 123:84 124:85 125:85 126:86 127:86 128:86 129:87 130:88 131:89 132:90 133:91 134:92 135:92 136:93 137:93 138:93 139:93 140:93\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2077 2010 11889 1010 5752 2003 102 2009 2003 2055 1037 3940 1997 2142 2163 3212 5370 6477 12910 1006 11867 2015 1007 1006 3419 2022 7389 4590 1998 2520 28340 1007 2040 2442 8620 1037 3376 7267 1006 24900 3449 19825 2243 1007 1010 1998 1996 13460 2027 8087 1012 5752 16475 7231 1006 2520 28340 1007 2003 1037 2402 11803 2040 2038 3344 2041 1037 2193 1997 12612 1011 3141 8040 13596 2247 2007 2010 4256 1011 1999 1011 4126 4922 1006 15594 2378 20012 1007 1998 2081 1037 2843 1997 2769 2076 2010 2326 1012 1037 2154 2077 2010 11889 1010 5752 2003 4137 2000 8620 1037 7267 2013 1996 3884 2918 2012 3409 3393 6460 9816 2247 2007 1996 27246 1010 2053 1011 14652 2708 11612 2961 2600 13875 1006 3419 2022 7389 4590 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000005\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 5\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] with her previously as el ##lia [SEP] the others were adam baldwin ( jayne cobb in fire ##fly ) who played colonel dave dixon , and more ##na ba ##cca ##rin ( ina ##ra serra in fire ##fly ) who played ad ##ria . executive producer martin ge ##ro created the character of jennifer keller while writing ` ` first strike ' ' . the producers decided to cast jewel st ##ai ##te for the role as keller after they enjoyed working with her previously as el ##lia in ` ` instinct ' ' . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:6 16:7 17:8 18:8 19:8 20:9 21:10 22:11 23:12 24:13 25:13 26:14 27:15 28:15 29:16 30:16 31:16 32:17 33:17 34:17 35:18 36:19 37:20 38:20 39:20 40:21 41:22 42:23 43:23 44:23 45:24 46:25 47:26 48:27 49:27 50:28 51:29 52:30 53:31 54:32 55:33 56:34 57:35 58:36 59:36 60:36 61:37 62:37 63:37 64:37 65:38 66:39 67:40 68:41 69:42 70:43 71:44 72:44 73:44 74:45 75:46 76:47 77:48 78:49 79:50 80:51 81:52 82:53 83:54 84:55 85:56 86:57 87:58 88:58 89:59 90:60 91:60 92:60 93:60 94:60 95:60\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2007 2014 3130 2004 3449 6632 102 1996 2500 2020 4205 10970 1006 24408 17176 1999 2543 14151 1007 2040 2209 4327 4913 11357 1010 1998 2062 2532 8670 16665 6657 1006 27118 2527 22737 1999 2543 14151 1007 2040 2209 4748 4360 1012 3237 3135 3235 16216 3217 2580 1996 2839 1997 7673 16155 2096 3015 1036 1036 2034 4894 1005 1005 1012 1996 6443 2787 2000 3459 13713 2358 4886 2618 2005 1996 2535 2004 16155 2044 2027 5632 2551 2007 2014 3130 2004 3449 6632 1999 1036 1036 12753 1005 1005 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000006\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 6\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] curry . she played lady jane [SEP] allison fischer ( born october 19 , 1988 ) is an american singer and actress . originally from northern new jersey , allison had her first professional performance in the off - broadway musical king island christmas in 2000 . also in 2000 , allison performed on broadway at madison square garden as grace smyth ##e in a christmas carol , alongside frank lange ##lla and tim curry . she played lady jane in the off - broadway musical version of the prince and the pau ##per from 2002 - - 2003 , and briefly performed at playwright ##s horizon in january 2003 in jean ##ine te ##sor ##i ' s musical , ' ' violet ' ' . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:2 12:3 13:4 14:4 15:5 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:11 24:12 25:13 26:14 27:15 28:16 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:31 48:32 49:33 50:34 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:43 61:44 62:45 63:45 64:46 65:47 66:48 67:49 68:49 69:50 70:51 71:52 72:52 73:53 74:54 75:55 76:55 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:62 85:62 86:63 87:64 88:65 89:66 90:67 91:68 92:69 93:70 94:70 95:71 96:72 97:72 98:72 99:72 100:72 101:73 102:74 103:75 104:76 105:77 106:77 107:78 108:79 109:80 110:81 111:82 112:83 113:83 114:84 115:84 116:84 117:85 118:85 119:86 120:86 121:87 122:87 123:87 124:87 125:87 126:87\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 15478 1012 2016 2209 3203 4869 102 10786 13042 1006 2141 2255 2539 1010 2997 1007 2003 2019 2137 3220 1998 3883 1012 2761 2013 2642 2047 3933 1010 10786 2018 2014 2034 2658 2836 1999 1996 2125 1011 5934 3315 2332 2479 4234 1999 2456 1012 2036 1999 2456 1010 10786 2864 2006 5934 2012 7063 2675 3871 2004 4519 28103 2063 1999 1037 4234 8594 1010 4077 3581 21395 4571 1998 5199 15478 1012 2016 2209 3203 4869 1999 1996 2125 1011 5934 3315 2544 1997 1996 3159 1998 1996 29025 4842 2013 2526 1011 1011 2494 1010 1998 4780 2864 2012 11170 2015 9154 1999 2254 2494 1999 3744 3170 8915 21748 2072 1005 1055 3315 1010 1005 1005 8766 1005 1005 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000007\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 7\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] killing her . [SEP] the monster arrives and bites jen ##i ' s tongue , but david manages to break free and releases the other three , though at the cost of his own life . the remaining trio head back to the cottage to set a trap to kill the monster , but the le ##pre ##cha ##un tricks sophie and ben into striking jen ##i with their axes , killing her . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 5:0 6:1 7:2 8:3 9:4 10:5 11:5 12:5 13:5 14:6 15:6 16:7 17:8 18:9 19:10 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:17 28:18 29:19 30:20 31:21 32:22 33:23 34:24 35:25 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:37 49:38 50:39 51:40 52:41 53:41 54:42 55:43 56:44 57:44 58:44 59:44 60:45 61:46 62:47 63:48 64:49 65:50 66:51 67:51 68:52 69:53 70:54 71:54 72:55 73:56 74:56\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 5:True 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 4288 2014 1012 102 1996 6071 8480 1998 15424 15419 2072 1005 1055 4416 1010 2021 2585 9020 2000 3338 2489 1998 7085 1996 2060 2093 1010 2295 2012 1996 3465 1997 2010 2219 2166 1012 1996 3588 7146 2132 2067 2000 1996 9151 2000 2275 1037 8132 2000 3102 1996 6071 1010 2021 1996 3393 28139 7507 4609 12225 8234 1998 3841 2046 8478 15419 2072 2007 2037 19589 1010 4288 2014 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000008\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 8\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] then he faced former world [SEP] on june 4 , 1973 at the felt forum , madison square garden , new york , mala ##ve lost to ray lamp ##kin by an eighth - round knockout . mala ##ve took a fight in boston , mass . against greg join ##er , winning by a knockout in the 3rd round . then he faced former world lightweight champion ken buchanan , losing by a tko in the 7th round september 1 , 1973 , which turned out to be his last professional boxing match . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:7 17:8 18:9 19:10 20:10 21:11 22:12 23:12 24:13 25:13 26:14 27:15 28:16 29:17 30:17 31:18 32:19 33:20 34:20 35:20 36:21 37:21 38:22 39:22 40:23 41:24 42:25 43:26 44:27 45:27 46:28 47:28 48:29 49:30 50:31 51:31 52:31 53:32 54:33 55:34 56:35 57:36 58:37 59:38 60:39 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:48 72:49 73:50 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:58 83:59 84:59 85:60 86:61 87:62 88:63 89:64 90:65 91:66 92:67 93:68 94:69 95:69\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2059 2002 4320 2280 2088 102 2006 2238 1018 1010 3381 2012 1996 2371 7057 1010 7063 2675 3871 1010 2047 2259 1010 28935 3726 2439 2000 4097 10437 4939 2011 2019 5964 1011 2461 11369 1012 28935 3726 2165 1037 2954 1999 3731 1010 3742 1012 2114 6754 3693 2121 1010 3045 2011 1037 11369 1999 1996 3822 2461 1012 2059 2002 4320 2280 2088 12038 3410 6358 14349 1010 3974 2011 1037 26537 1999 1996 5504 2461 2244 1015 1010 3381 1010 2029 2357 2041 2000 2022 2010 2197 2658 8362 2674 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000009\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 9\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] from her album sha ##kin ' things [SEP] go away ( lo ##rrie morgan song ) ` ` go away ' ' is a song written by step ##hony smith , cathy maj ##es ##ki and sunny russ , and recorded by american country music artist lo ##rrie morgan . it was released in july 1997 as the first single from her album sha ##kin ' things up . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:2 13:2 14:3 15:4 16:4 17:5 18:5 19:5 20:6 21:6 22:6 23:7 24:8 25:9 26:10 27:11 28:12 29:12 30:13 31:13 32:14 33:15 34:15 35:15 36:16 37:17 38:18 39:18 40:19 41:20 42:21 43:22 44:23 45:24 46:25 47:26 48:26 49:27 50:27 51:28 52:29 53:30 54:31 55:32 56:33 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:41 66:41 67:42 68:43 69:43\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2013 2014 2201 21146 4939 1005 2477 102 2175 2185 1006 8840 22155 5253 2299 1007 1036 1036 2175 2185 1005 1005 2003 1037 2299 2517 2011 3357 27629 3044 1010 18305 16686 2229 3211 1998 11559 18072 1010 1998 2680 2011 2137 2406 2189 3063 8840 22155 5253 1012 2009 2001 2207 1999 2251 2722 2004 1996 2034 2309 2013 2014 2201 21146 4939 1005 2477 2039 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000010\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 10\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] in her most visible action , [SEP] taken in by s . h . i . e . l . d . she is under the direct supervision of its longtime executive director , nick fury , even after the latter ' s defect ##ion from the agency during the events of the ` ` secret war ' ' series . she possesses a ` ` level 10 ' ' security clearance , the only known agent aside from fury and the black widow ( natasha romano ##va ) to do so . in her most visible action , johnson has helped to defeat the powerful mutant rebel leader magnet ##o by inducing a vibration in his brain that made him lose consciousness . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:3 14:3 15:3 16:3 17:3 18:3 19:3 20:3 21:3 22:3 23:4 24:5 25:6 26:7 27:8 28:9 29:10 30:11 31:12 32:13 33:14 34:14 35:15 36:16 37:16 38:17 39:18 40:19 41:20 42:20 43:20 44:21 45:21 46:22 47:23 48:24 49:25 50:26 51:27 52:28 53:29 54:30 55:30 56:30 57:31 58:31 59:31 60:32 61:32 62:33 63:34 64:35 65:36 66:36 67:36 68:37 69:37 70:37 71:38 72:39 73:39 74:40 75:41 76:42 77:43 78:44 79:45 80:46 81:47 82:48 83:49 84:50 85:51 86:51 87:52 88:52 89:52 90:53 91:54 92:55 93:55 94:56 95:57 96:58 97:59 98:60 99:60 100:61 101:62 102:63 103:64 104:65 105:66 106:67 107:68 108:69 109:70 110:71 111:71 112:72 113:73 114:74 115:75 116:76 117:77 118:78 119:79 120:80 121:81 122:82 123:83 124:83\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 1999 2014 2087 5710 2895 1010 102 2579 1999 2011 1055 1012 1044 1012 1045 1012 1041 1012 1048 1012 1040 1012 2016 2003 2104 1996 3622 10429 1997 2049 11155 3237 2472 1010 4172 8111 1010 2130 2044 1996 3732 1005 1055 21262 3258 2013 1996 4034 2076 1996 2824 1997 1996 1036 1036 3595 2162 1005 1005 2186 1012 2016 14882 1037 1036 1036 2504 2184 1005 1005 3036 14860 1010 1996 2069 2124 4005 4998 2013 8111 1998 1996 2304 7794 1006 17399 22070 3567 1007 2000 2079 2061 1012 1999 2014 2087 5710 2895 1010 3779 2038 3271 2000 4154 1996 3928 15527 8443 3003 16853 2080 2011 29290 1037 17880 1999 2010 4167 2008 2081 2032 4558 8298 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000011\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 11\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] because she is also in ##fat ##uated [SEP] neither knows the truth about their respective past ##s . when dona vale ##ria finds out that fernando jose is in a relationship , she gets mad at her son for dating someone beneath their social status . dolores and rosa ##lind ##a ' s sister , fed ##ra ( hal ##ili ) also does not accept their relationship because she is also in ##fat ##uated with fernando jose . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:3 13:4 14:5 15:6 16:7 17:7 18:7 19:8 20:9 21:10 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:32 47:33 48:34 49:35 50:35 51:35 52:35 53:35 54:36 55:36 56:37 57:37 58:38 59:38 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:49 74:49 75:50 76:51 77:52 78:52\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2138 2016 2003 2036 1999 27753 16453 102 4445 4282 1996 3606 2055 2037 7972 2627 2015 1012 2043 24260 10380 4360 4858 2041 2008 9158 4560 2003 1999 1037 3276 1010 2016 4152 5506 2012 2014 2365 2005 5306 2619 4218 2037 2591 3570 1012 21544 1998 9508 27164 2050 1005 1055 2905 1010 7349 2527 1006 11085 18622 1007 2036 2515 2025 5138 2037 3276 2138 2016 2003 2036 1999 27753 16453 2007 9158 4560 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000012\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 12\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] department . his wife is su ##zan ##na [SEP] he was a lawyer in pu ##las ##ki county before serving as mayor of little rock from 1979 until he resigned in 1981 . he was appointed by bill clinton as chief justice of arkansas state supreme court in 1983 . when clinton became president , hub ##bell was appointed as associate attorney general , which is the third most powerful person in the justice department . his wife is su ##zan ##na ` ` suzy ' ' hub ##bell . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 10:0 11:1 12:2 13:3 14:4 15:5 16:5 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:35 49:36 50:36 51:37 52:38 53:39 54:40 55:40 56:41 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:47 65:48 66:49 67:50 68:51 69:52 70:53 71:54 72:55 73:56 74:57 75:58 76:58 77:59 78:60 79:61 80:62 81:62 82:62 83:63 84:63 85:63 86:63 87:63 88:64 89:64 90:64\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2533 1012 2010 2564 2003 10514 13471 2532 102 2002 2001 1037 5160 1999 16405 8523 3211 2221 2077 3529 2004 3664 1997 2210 2600 2013 3245 2127 2002 5295 1999 3261 1012 2002 2001 2805 2011 3021 7207 2004 2708 3425 1997 6751 2110 4259 2457 1999 3172 1012 2043 7207 2150 2343 1010 9594 17327 2001 2805 2004 5482 4905 2236 1010 2029 2003 1996 2353 2087 3928 2711 1999 1996 3425 2533 1012 2010 2564 2003 10514 13471 2532 1036 1036 28722 1005 1005 9594 17327 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000013\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 13\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] which he accepted . [SEP] he left the army in 1946 . as the recipient of a fellowship in composition , hanson after the war was able to resume his studies at the con ##ser ##vat ##ori ##um . following a year of study with alex bernard , the con ##ser ##vat ##ori ##um offered hanson a place on the staff which he accepted . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:5 13:6 14:7 15:8 16:9 17:10 18:11 19:12 20:13 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:22 31:23 32:24 33:25 34:26 35:26 36:26 37:26 38:26 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:34 49:35 50:36 51:36 52:36 53:36 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:43 62:44 63:45 64:46 65:46\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2029 2002 3970 1012 102 2002 2187 1996 2390 1999 3918 1012 2004 1996 7799 1997 1037 7881 1999 5512 1010 17179 2044 1996 2162 2001 2583 2000 13746 2010 2913 2012 1996 9530 8043 22879 10050 2819 1012 2206 1037 2095 1997 2817 2007 4074 6795 1010 1996 9530 8043 22879 10050 2819 3253 17179 1037 2173 2006 1996 3095 2029 2002 3970 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000014\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 14\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] bill . she recently played the [SEP] nicola alexis is a british actress best known for playing the role of w ##pc ruby bu ##xton in the long running itv drama the bill . she recently played the lead role in the theatre adaptation of carl hi ##aa ##sen ' s lucky you , which premiered at the edinburgh festival fringe in 2008 . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:13 23:14 24:15 25:15 26:16 27:17 28:18 29:19 30:20 31:21 32:22 33:23 34:23 35:24 36:25 37:26 38:27 39:28 40:29 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:36 49:36 50:36 51:36 52:37 53:38 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:47\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 3021 1012 2016 3728 2209 1996 102 17388 13573 2003 1037 2329 3883 2190 2124 2005 2652 1996 2535 1997 1059 15042 10090 20934 14226 1999 1996 2146 2770 11858 3689 1996 3021 1012 2016 3728 2209 1996 2599 2535 1999 1996 3004 6789 1997 5529 7632 11057 5054 1005 1055 5341 2017 1010 2029 5885 2012 1996 5928 2782 13548 1999 2263 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000015\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 15\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] that his father ' s garage had [SEP] indeed , buster was fully intended to exist in place of spike for the comic book series , until the release of the fortress maximus toy in 1987 , which included spike as a headmaster partner , hence nec ##ess ##itating the hurried introduction of spike into the comic book continuity . returning home from college to discover that his father ' s garage had been destroyed , spike investigated the auto ##bots ' deserted base at mount saint hillary , learning that buster had been captured by the earth - based dec ##ept ##icon ##s . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:22 34:23 35:24 36:25 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:32 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:38 54:39 55:40 56:41 57:42 58:43 59:44 60:44 61:45 62:46 63:47 64:48 65:49 66:50 67:51 68:52 69:53 70:53 71:53 72:54 73:55 74:56 75:57 76:57 77:58 78:59 79:60 80:61 81:61 82:61 83:62 84:63 85:64 86:65 87:66 88:67 89:67 90:68 91:69 92:70 93:71 94:72 95:73 96:74 97:75 98:76 99:76 100:76 101:77 102:77 103:77 104:77 105:77\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2008 2010 2269 1005 1055 7381 2018 102 5262 1010 18396 2001 3929 3832 2000 4839 1999 2173 1997 9997 2005 1996 5021 2338 2186 1010 2127 1996 2713 1997 1996 7841 21692 9121 1999 3055 1010 2029 2443 9997 2004 1037 16296 4256 1010 6516 26785 7971 16518 1996 9520 4955 1997 9997 2046 1996 5021 2338 13717 1012 4192 2188 2013 2267 2000 7523 2008 2010 2269 1005 1055 7381 2018 2042 3908 1010 9997 10847 1996 8285 27014 1005 12768 2918 2012 4057 3002 18520 1010 4083 2008 18396 2018 2042 4110 2011 1996 3011 1011 2241 11703 23606 28524 2015 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000016\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 16\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] 1979 . she also starred in [SEP] in the late 1970s , she toured in musical comedies including sammy ca ##hn ' s words and music . after appearing with mickey rooney in the play goodnight ladies in chicago , the producers cast ann jillian to appear in the original company of sugar babies on broadway with mickey rooney and ann miller in 1979 . she also starred in i love my wife at the drury lane theatre in chicago . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:10 20:11 21:11 22:11 23:11 24:12 25:13 26:14 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:23 37:24 38:25 39:26 40:26 41:27 42:28 43:29 44:30 45:31 46:32 47:33 48:34 49:35 50:36 51:37 52:38 53:39 54:40 55:41 56:42 57:43 58:44 59:45 60:46 61:47 62:48 63:49 64:50 65:50 66:51 67:52 68:53 69:54 70:55 71:56 72:57 73:58 74:59 75:60 76:61 77:62 78:63 79:64 80:65 81:65\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 3245 1012 2016 2036 5652 1999 102 1999 1996 2397 3955 1010 2016 7255 1999 3315 22092 2164 14450 6187 7295 1005 1055 2616 1998 2189 1012 2044 6037 2007 11021 24246 1999 1996 2377 22708 6456 1999 3190 1010 1996 6443 3459 5754 27286 2000 3711 1999 1996 2434 2194 1997 5699 10834 2006 5934 2007 11021 24246 1998 5754 4679 1999 3245 1012 2016 2036 5652 1999 1045 2293 2026 2564 2012 1996 25663 4644 3004 1999 3190 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000017\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 17\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] selected her to appear in [SEP] jennifer slept here ended in 1984 , enabling her to take a role in the miniseries ellis island , co - starring richard burton , faye dun ##away , ben ve ##reen and liam nee ##son . dun ##away and ve ##reen were nominated for golden globe awards , and jillian and burton were nominated for emmy awards . bob hope selected her to appear in six of his television specials , including two entertaining u . s . troops stationed in beirut ( 1984 ) and saudi arabia ( 1991 ) . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:16 26:17 27:17 28:17 29:18 30:19 31:19 32:20 33:21 34:21 35:21 36:22 37:23 38:23 39:24 40:25 41:26 42:26 43:26 44:27 45:27 46:28 47:29 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:35 56:36 57:37 58:38 59:39 60:40 61:41 62:42 63:43 64:44 65:44 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:55 77:56 78:56 79:57 80:58 81:59 82:60 83:60 84:60 85:60 86:61 87:62 88:63 89:64 90:65 91:65 92:65 93:66 94:67 95:68 96:69 97:69 98:69 99:69\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 3479 2014 2000 3711 1999 102 7673 7771 2182 3092 1999 3118 1010 12067 2014 2000 2202 1037 2535 1999 1996 13612 8547 2479 1010 2522 1011 4626 2957 9658 1010 19243 24654 9497 1010 3841 2310 28029 1998 8230 7663 3385 1012 24654 9497 1998 2310 28029 2020 4222 2005 3585 7595 2982 1010 1998 27286 1998 9658 2020 4222 2005 10096 2982 1012 3960 3246 3479 2014 2000 3711 1999 2416 1997 2010 2547 19247 1010 2164 2048 14036 1057 1012 1055 1012 3629 8895 1999 15335 1006 3118 1007 1998 8174 9264 1006 2889 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000018\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 18\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] since her predecessor elisabeth vol ##km ##ann [SEP] on may 17 , 2004 , when the very successful die harald schmidt show left sat . 1 , eng ##el ##ke took over its times ##lot with an ##ke late night , which was cancelled due to low ratings a few months later on october 21 , 2004 . eng ##el ##ke is the german voice of marge simpson on the simpsons since her predecessor elisabeth vol ##km ##ann died in the summer of 2006 . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 9:0 10:1 11:2 12:2 13:3 14:3 15:4 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:13 26:13 27:13 28:14 29:14 30:14 31:15 32:16 33:17 34:18 35:18 36:19 37:20 38:20 39:21 40:22 41:22 42:23 43:24 44:25 45:26 46:27 47:28 48:29 49:30 50:31 51:32 52:33 53:34 54:35 55:36 56:36 57:37 58:37 59:38 60:38 61:38 62:39 63:40 64:41 65:42 66:43 67:44 68:45 69:46 70:47 71:48 72:49 73:50 74:51 75:52 76:53 77:53 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:59\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 2144 2014 8646 12877 5285 22287 11639 102 2006 2089 2459 1010 2432 1010 2043 1996 2200 3144 3280 20966 12940 2265 2187 2938 1012 1015 1010 25540 2884 3489 2165 2058 2049 2335 10994 2007 2019 3489 2397 2305 1010 2029 2001 8014 2349 2000 2659 8599 1037 2261 2706 2101 2006 2255 2538 1010 2432 1012 25540 2884 3489 2003 1996 2446 2376 1997 25532 9304 2006 1996 19047 2144 2014 8646 12877 5285 22287 11639 2351 1999 1996 2621 1997 2294 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   unique_id: 1000000019\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   example_index: 19\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   tokens: [CLS] tuscany . he was born into [SEP] antonio di filippo di lorenzo nic ##col ##ini ( florence , 1701 - - 1769 ) was an italian abbot , jurist and scholar , who was considered one of the leading figures of eighteenth - century tuscany . he was born into a noble fl ##ore ##ntine family , the youngest child of filippo , third marquess of po ##ns ##ac ##co and cam ##ug ##lian ##o , and was a relative of the pope . [SEP]\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:5 15:5 16:6 17:6 18:6 19:7 20:7 21:7 22:7 23:7 24:8 25:9 26:10 27:11 28:11 29:12 30:13 31:14 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:23 42:24 43:24 44:24 45:25 46:25 47:26 48:27 49:28 50:29 51:30 52:31 53:32 54:32 55:32 56:33 57:33 58:34 59:35 60:36 61:37 62:38 63:38 64:39 65:40 66:41 67:42 68:42 69:42 70:42 71:43 72:44 73:44 74:44 75:44 76:44 77:45 78:46 79:47 80:48 81:49 82:50 83:51 84:51\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_ids: 101 23322 1012 2002 2001 2141 2046 102 4980 4487 28669 4487 12484 27969 25778 5498 1006 7701 1010 26059 1011 1011 20663 1007 2001 2019 3059 11428 1010 22757 1998 6288 1010 2040 2001 2641 2028 1997 1996 2877 4481 1997 12965 1011 2301 23322 1012 2002 2001 2141 2046 1037 7015 13109 5686 26730 2155 1010 1996 6587 2775 1997 28669 1010 2353 17391 1997 13433 3619 6305 3597 1998 11503 15916 15204 2080 1010 1998 2001 1037 5816 1997 1996 4831 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:38 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000000\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] with his knowledge of scott , [SEP] however he was never able to get close to two of the best , dai vernon or sam ho ##row ##itz . so mcguire got close to a magician both men admired , max mali ##ni , and through clever use of his association with mali ##ni got to ho ##row ##itz . with his knowledge of scott , mcguire had leverage and a worth to the top card ##men . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:12 22:13 23:14 24:15 25:16 26:17 27:17 28:17 29:17 30:18 31:19 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:27 41:28 42:29 43:29 44:29 45:30 46:31 47:32 48:33 49:34 50:35 51:36 52:37 53:38 54:38 55:39 56:40 57:41 58:41 59:41 60:41 61:42 62:43 63:44 64:45 65:46 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:54 75:55 76:56 77:56 78:56\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2007 2010 3716 1997 3660 1010 102 2174 2002 2001 2196 2583 2000 2131 2485 2000 2048 1997 1996 2190 1010 18765 11447 2030 3520 7570 10524 8838 1012 2061 23872 2288 2485 2000 1037 16669 2119 2273 12749 1010 4098 16007 3490 1010 1998 2083 12266 2224 1997 2010 2523 2007 16007 3490 2288 2000 7570 10524 8838 1012 2007 2010 3716 1997 3660 1010 23872 2018 21155 1998 1037 4276 2000 1996 2327 4003 3549 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000001\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 1\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] not . she again played with [SEP] on january 13 , 2010 , she performed for ringo starr with ben harper and the relentless ##7 on the daily show to promote starr ' s new album , y not . she again played with them and joan osborne on january 14 , 2010 for a performance at the metropolitan museum of art , in the grace rain ##ey rogers auditorium , in new york city which was recorded for and appeared in 2010 on the pbs show , live from the artists den . ann marie collaborated with hans z ##im ##mer , as a featured soloist and contributing writer on the film score for the 2009 film sherlock holmes , directed by guy ritchie . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:2 12:3 13:3 14:4 15:5 16:6 17:7 18:8 19:9 20:10 21:11 22:12 23:13 24:14 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:21 34:21 35:22 36:23 37:23 38:24 39:25 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:34 50:35 51:36 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:46 64:47 65:48 66:49 67:50 68:50 69:51 70:52 71:52 72:53 73:54 74:55 75:56 76:57 77:58 78:59 79:60 80:61 81:62 82:63 83:64 84:65 85:66 86:67 87:68 88:68 89:69 90:70 91:71 92:72 93:73 94:73 95:74 96:75 97:76 98:77 99:78 100:79 101:79 102:79 103:79 104:80 105:81 106:82 107:83 108:84 109:85 110:86 111:87 112:88 113:89 114:90 115:91 116:92 117:93 118:94 119:95 120:96 121:96 122:97 123:98 124:99 125:100 126:100\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2025 1012 2016 2153 2209 2007 102 2006 2254 2410 1010 2230 1010 2016 2864 2005 25589 14330 2007 3841 8500 1998 1996 21660 2581 2006 1996 3679 2265 2000 5326 14330 1005 1055 2047 2201 1010 1061 2025 1012 2016 2153 2209 2007 2068 1998 7437 16732 2006 2254 2403 1010 2230 2005 1037 2836 2012 1996 4956 2688 1997 2396 1010 1999 1996 4519 4542 3240 7369 11448 1010 1999 2047 2259 2103 2029 2001 2680 2005 1998 2596 1999 2230 2006 1996 13683 2265 1010 2444 2013 1996 3324 7939 1012 5754 5032 8678 2007 7003 1062 5714 5017 1010 2004 1037 2956 16504 1998 8020 3213 2006 1996 2143 3556 2005 1996 2268 2143 20052 9106 1010 2856 2011 3124 20404 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000002\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 2\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] before his decision to attend [SEP] i thought the best way to do that was to transfer . ' ' after cr ##uth ##ers ' decision to leave us ##ma he called derek school ##ey , the new head coach of rm ##u men ##s hockey team . school ##ey , formerly assistant coach for air force , had recruited ryan before his decision to attend west point and was more than happy to take ryan on the team . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:9 17:10 18:10 19:10 20:10 21:11 22:12 23:12 24:12 25:12 26:13 27:14 28:15 29:16 30:16 31:17 32:18 33:19 34:20 35:20 36:20 37:21 38:22 39:23 40:24 41:25 42:26 43:26 44:27 45:27 46:28 47:29 48:29 49:30 50:30 51:30 52:31 53:32 54:33 55:34 56:35 57:36 58:36 59:37 60:38 61:39 62:40 63:41 64:42 65:43 66:44 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:52 75:53 76:54 77:55 78:56 79:57 80:57\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2077 2010 3247 2000 5463 102 1045 2245 1996 2190 2126 2000 2079 2008 2001 2000 4651 1012 1005 1005 2044 13675 14317 2545 1005 3247 2000 2681 2149 2863 2002 2170 7256 2082 3240 1010 1996 2047 2132 2873 1997 28549 2226 2273 2015 3873 2136 1012 2082 3240 1010 3839 3353 2873 2005 2250 2486 1010 2018 8733 4575 2077 2010 3247 2000 5463 2225 2391 1998 2001 2062 2084 3407 2000 2202 4575 2006 1996 2136 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000003\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 3\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] dancer she was not as [SEP] in 1995 came the turn of playing aurora , the central character in ` ` el be ##so de la mu ##jer ara * a ' ' , again under the direction of harold prince , who was a deciding factor when argentine producers called him to lead the implementation of the kiss . . . in buenos aires , and he inquired about who would be the protagonist , prince said : ` ` i love vale ##ria lynch . ' ' as valerie did not have to do casting , however cue ##ndo started with rehearsals for the musical , vale ##ria made it clear to rob ash ##ff ##ord fantastic choreographer , dancer she was not as chi ##ta rivera , to which ash ##ff ##ord utmost account . . . . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:7 16:8 17:9 18:10 19:11 20:12 21:12 22:12 23:13 24:13 25:14 26:15 27:16 28:16 29:17 30:17 31:17 32:17 33:17 34:17 35:18 36:19 37:20 38:21 39:22 40:23 41:24 42:24 43:25 44:26 45:27 46:28 47:29 48:30 49:31 50:32 51:33 52:34 53:35 54:36 55:37 56:38 57:39 58:40 59:41 60:42 61:42 62:42 63:43 64:44 65:45 66:45 67:46 68:47 69:48 70:49 71:50 72:51 73:52 74:53 75:54 76:54 77:55 78:56 79:56 80:57 81:57 82:57 83:58 84:59 85:59 86:60 87:60 88:60 89:60 90:61 91:62 92:63 93:64 94:65 95:66 96:67 97:68 98:68 99:69 100:70 101:70 102:71 103:72 104:73 105:74 106:75 107:76 108:76 109:77 110:77 111:78 112:79 113:80 114:81 115:82 116:83 117:83 118:83 119:84 120:85 121:85 122:86 123:87 124:88 125:89 126:90 127:91 128:91 129:92 130:92 131:93 132:94 133:95 134:95 135:95 136:96 137:97 138:98 139:98 140:98 141:98\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 8033 2016 2001 2025 2004 102 1999 2786 2234 1996 2735 1997 2652 13158 1010 1996 2430 2839 1999 1036 1036 3449 2022 6499 2139 2474 14163 20009 19027 1008 1037 1005 1005 1010 2153 2104 1996 3257 1997 7157 3159 1010 2040 2001 1037 10561 5387 2043 8511 6443 2170 2032 2000 2599 1996 7375 1997 1996 3610 1012 1012 1012 1999 9204 9149 1010 1998 2002 24849 2055 2040 2052 2022 1996 10191 1010 3159 2056 1024 1036 1036 1045 2293 10380 4360 11404 1012 1005 1005 2004 14264 2106 2025 2031 2000 2079 9179 1010 2174 16091 15482 2318 2007 24760 2005 1996 3315 1010 10380 4360 2081 2009 3154 2000 6487 6683 4246 8551 10392 17334 1010 8033 2016 2001 2025 2004 9610 2696 14043 1010 2000 2029 6683 4246 8551 27917 4070 1012 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000004\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 4\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] with his demanding schedule , jack [SEP] they had two sons , who were both professional football quarterback ##s : jeff kemp ( born in 1959 ) played in the nfl from 1981 to 1991 , and jimmy kemp ( born in 1971 ) played in the cfl from 1994 to 2002 . significantly for a man with his demanding schedule , jack never missed one of their games as children or in college . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:3 13:4 14:5 15:6 16:7 17:8 18:9 19:9 20:9 21:10 22:11 23:12 24:12 25:13 26:14 27:14 28:15 29:16 30:17 31:18 32:19 33:20 34:21 35:22 36:22 37:23 38:24 39:25 40:26 41:26 42:27 43:28 44:28 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:36 54:37 55:38 56:39 57:40 58:41 59:42 60:43 61:44 62:44 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:53 72:54 73:55 74:56 75:56\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2007 2010 9694 6134 1010 2990 102 2027 2018 2048 4124 1010 2040 2020 2119 2658 2374 9074 2015 1024 5076 20441 1006 2141 1999 3851 1007 2209 1999 1996 5088 2013 3261 2000 2889 1010 1998 5261 20441 1006 2141 1999 3411 1007 2209 1999 1996 18830 2013 2807 2000 2526 1012 6022 2005 1037 2158 2007 2010 9694 6134 1010 2990 2196 4771 2028 1997 2037 2399 2004 2336 2030 1999 2267 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000005\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 5\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] in his history of british [SEP] over the years , she provided him with specimens collected in cornwall as well as those from abroad that came into britain through fa ##lm ##outh . she is credited ( as ` ` miss warren ' ' ) as one of 19 plant specimen collectors to whom hooker is particularly ind ##eb ##ted in the preface to his 1841 manual of the british algae . in his history of british sea ##weed ##s , ph ##y ##col ##og ##ia brit ##ann ##ica , hooker lists an algae named after her by the botanist robert cas ##par ##y , sc ##hi ##zos ##ip ##hon warren ##iae ( now ri ##vu ##lar ##ia bias ##ole ##tti ##ana ) . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:12 21:13 22:14 23:15 24:16 25:17 26:18 27:19 28:20 29:21 30:22 31:22 32:22 33:22 34:23 35:24 36:25 37:26 38:26 39:27 40:27 41:27 42:28 43:28 44:28 45:28 46:29 47:30 48:31 49:32 50:33 51:34 52:35 53:36 54:37 55:38 56:39 57:40 58:41 59:41 60:41 61:42 62:43 63:44 64:45 65:46 66:47 67:48 68:49 69:50 70:51 71:52 72:52 73:53 74:54 75:55 76:56 77:57 78:58 79:58 80:58 81:58 82:59 83:59 84:59 85:59 86:59 87:60 88:60 89:60 90:60 91:61 92:62 93:63 94:64 95:65 96:66 97:67 98:68 99:69 100:70 101:71 102:72 103:72 104:72 105:72 106:73 107:73 108:73 109:73 110:73 111:74 112:74 113:75 114:75 115:76 116:76 117:76 118:76 119:77 120:77 121:77 122:77 123:77 124:77\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 1999 2010 2381 1997 2329 102 2058 1996 2086 1010 2016 3024 2032 2007 9908 5067 1999 10387 2004 2092 2004 2216 2013 6917 2008 2234 2046 3725 2083 6904 13728 17167 1012 2016 2003 5827 1006 2004 1036 1036 3335 6031 1005 1005 1007 2004 2028 1997 2539 3269 11375 14256 2000 3183 17074 2003 3391 27427 15878 3064 1999 1996 18443 2000 2010 9840 6410 1997 1996 2329 18670 1012 1999 2010 2381 1997 2329 2712 18041 2015 1010 6887 2100 25778 8649 2401 28101 11639 5555 1010 17074 7201 2019 18670 2315 2044 2014 2011 1996 17098 2728 25222 19362 2100 1010 8040 4048 28370 11514 8747 6031 19001 1006 2085 15544 19722 8017 2401 13827 9890 6916 5162 1007 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000006\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 6\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] that he and ni ##mo ##y were [SEP] sha ##tner referred to the original series as ` ` cartoon ##ish ' ' in mind mel ##d , but later , upon questioning by a reporter , said , ` ` i never thought it was a cartoon . . . i never thought it was beneath me . ' ' in a february 2002 interview on larry king live , sha ##tner said mind mel ##d was similar to my dinner with andre , and indicated that he and ni ##mo ##y were hoping to produce more films of a similar nature . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:1 12:2 13:3 14:4 15:5 16:6 17:7 18:7 19:7 20:7 21:7 22:7 23:8 24:9 25:10 26:10 27:10 28:11 29:12 30:12 31:13 32:14 33:15 34:16 35:17 36:17 37:18 38:18 39:19 40:19 41:19 42:20 43:21 44:22 45:23 46:24 47:25 48:26 49:26 50:26 51:27 52:28 53:29 54:30 55:31 56:32 57:33 58:33 59:33 60:33 61:34 62:35 63:36 64:37 65:38 66:39 67:40 68:41 69:42 70:42 71:43 72:43 73:44 74:45 75:46 76:46 77:47 78:48 79:49 80:50 81:51 82:52 83:53 84:53 85:54 86:55 87:56 88:57 89:58 90:59 91:59 92:59 93:60 94:61 95:62 96:63 97:64 98:65 99:66 100:67 101:68 102:69 103:69\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2008 2002 1998 9152 5302 2100 2020 102 21146 18885 3615 2000 1996 2434 2186 2004 1036 1036 9476 4509 1005 1005 1999 2568 11463 2094 1010 2021 2101 1010 2588 11242 2011 1037 6398 1010 2056 1010 1036 1036 1045 2196 2245 2009 2001 1037 9476 1012 1012 1012 1045 2196 2245 2009 2001 4218 2033 1012 1005 1005 1999 1037 2337 2526 4357 2006 6554 2332 2444 1010 21146 18885 2056 2568 11463 2094 2001 2714 2000 2026 4596 2007 7213 1010 1998 5393 2008 2002 1998 9152 5302 2100 2020 5327 2000 3965 2062 3152 1997 1037 2714 3267 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000007\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 7\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] among his accomplishments during this [SEP] loyalists in coa ##hui ##la quickly judged , convicted , and executed the prisoners captured in san antonio de be ##xa ##r . las casa ##s ' s head was shipped to san antonio and displayed on a pole in the military plaza . with sal ##ced ##o still in chihuahua , za ##mb ##rano administered the province . among his accomplishments during this time was to ina ##ug ##ura ##te the first primary school in san antonio . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:2 11:2 12:3 13:4 14:4 15:5 16:5 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:15 28:15 29:15 30:16 31:17 32:17 33:17 34:17 35:18 36:19 37:20 38:21 39:22 40:23 41:24 42:25 43:26 44:27 45:28 46:29 47:30 48:31 49:32 50:32 51:33 52:34 53:34 54:34 55:35 56:36 57:37 58:37 59:38 60:38 61:38 62:39 63:40 64:41 65:41 66:42 67:43 68:44 69:45 70:46 71:47 72:48 73:49 74:50 75:50 76:50 77:50 78:51 79:52 80:53 81:54 82:55 83:56 84:57 85:57\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2426 2010 17571 2076 2023 102 26590 1999 28155 20552 2721 2855 13224 1010 7979 1010 1998 6472 1996 5895 4110 1999 2624 4980 2139 2022 18684 2099 1012 5869 14124 2015 1005 1055 2132 2001 12057 2000 2624 4980 1998 6913 2006 1037 6536 1999 1996 2510 8232 1012 2007 16183 11788 2080 2145 1999 28480 1010 23564 14905 20770 8564 1996 2874 1012 2426 2010 17571 2076 2023 2051 2001 2000 27118 15916 4648 2618 1996 2034 3078 2082 1999 2624 4980 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000008\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 8\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] support his argument . [SEP] the first topic that madison addresses is the differentiation between a republic and a democracy . george clinton , the governor of new york and one of the foremost authors of the anti - federal ##ist papers at the time of the ratification of the constitution , cited monte ##s ##qui ##eu , a political philosopher who authored ` ` the spirit of the laws ' ' , to support his argument . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 6:0 7:1 8:2 9:3 10:4 11:5 12:6 13:7 14:8 15:9 16:10 17:11 18:12 19:13 20:14 21:14 22:15 23:16 24:16 25:17 26:18 27:19 28:20 29:21 30:22 31:23 32:24 33:25 34:26 35:27 36:28 37:29 38:30 39:30 40:30 41:30 42:31 43:32 44:33 45:34 46:35 47:36 48:37 49:38 50:39 51:40 52:40 53:41 54:42 55:42 56:42 57:42 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:48 66:48 67:49 68:50 69:51 70:52 71:52 72:52 73:52 74:53 75:54 76:55 77:56 78:56\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 6:True 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2490 2010 6685 1012 102 1996 2034 8476 2008 7063 11596 2003 1996 20582 2090 1037 3072 1998 1037 7072 1012 2577 7207 1010 1996 3099 1997 2047 2259 1998 2028 1997 1996 16097 6048 1997 1996 3424 1011 2976 2923 4981 2012 1996 2051 1997 1996 27369 1997 1996 4552 1010 6563 10125 2015 15549 13765 1010 1037 2576 9667 2040 8786 1036 1036 1996 4382 1997 1996 4277 1005 1005 1010 2000 2490 2010 6685 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000009\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 9\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] since his myth ##bus ##ters appearances , ve ##nder ##a [SEP] he first performed with the myth ##bus ##ters on good morning america , shattering a wine glass with the aid of an amplifier when his opponent could not shatter the glass . during the filming of myth ##bus ##ters , ve ##nder ##a ' s voice was measured at 117 db at 48 ` ` , translating into 120 db at one meter as recorded by dr . roger sc ##h ##wen ##ke of meyer sound laboratories . since his myth ##bus ##ters appearances , ve ##nder ##a has performed on other us shows such as ' ' i ' ve got a secret ` ` , ' ' time ##war ##p ` ` and the ' ' sonic ##1 tooth ##brush ` ` info ##mer ##cial . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 12:0 13:1 14:2 15:3 16:4 17:5 18:5 19:5 20:6 21:7 22:8 23:9 24:9 25:10 26:11 27:12 28:13 29:14 30:15 31:16 32:17 33:18 34:19 35:20 36:21 37:22 38:23 39:24 40:25 41:26 42:27 43:27 44:28 45:29 46:30 47:31 48:32 49:32 50:32 51:32 52:33 53:33 54:33 55:33 56:33 57:34 58:35 59:36 60:37 61:38 62:39 63:40 64:41 65:41 66:41 67:41 68:42 69:43 70:44 71:45 72:46 73:47 74:48 75:49 76:50 77:51 78:52 79:52 80:53 81:54 82:54 83:54 84:54 85:55 86:56 87:57 88:58 89:58 90:59 91:60 92:61 93:61 94:61 95:62 96:62 97:63 98:63 99:63 100:64 101:65 102:66 103:67 104:68 105:69 106:70 107:71 108:72 109:72 110:72 111:72 112:72 113:73 114:74 115:75 116:75 117:75 118:75 119:76 120:76 121:76 122:76 123:76 124:76 125:76 126:77 127:78 128:79 129:79 130:79 131:79 132:80 133:80 134:80 135:80 136:81 137:81 138:81 139:81\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2144 2010 10661 8286 7747 3922 1010 2310 11563 2050 102 2002 2034 2864 2007 1996 10661 8286 7747 2006 2204 2851 2637 1010 21797 1037 4511 3221 2007 1996 4681 1997 2019 22686 2043 2010 7116 2071 2025 27271 1996 3221 1012 2076 1996 7467 1997 10661 8286 7747 1010 2310 11563 2050 1005 1055 2376 2001 7594 2012 12567 16962 2012 4466 1036 1036 1010 22969 2046 6036 16962 2012 2028 8316 2004 2680 2011 2852 1012 5074 8040 2232 12449 3489 1997 11527 2614 12030 1012 2144 2010 10661 8286 7747 3922 1010 2310 11563 2050 2038 2864 2006 2060 2149 3065 2107 2004 1005 1005 1045 1005 2310 2288 1037 3595 1036 1036 1010 1005 1005 2051 9028 2361 1036 1036 1998 1996 1005 1005 12728 2487 11868 18623 1036 1036 18558 5017 13247 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000010\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 10\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] over his career he had [SEP] the team also captured two east german cups ( f ##d ##gb po ##kal ) in 1971 and 1977 , and made 42 european cup appearances . during his career the small , strict trainer also coached 40 national team players and helped uncover talents such as ul ##f ki ##rsten and matthias sam ##mer . fritz ##sch was succeeded as trainer at dynamo by gerhard pr ##au ##tz ##sch and moved on to work for the d ##f ##v ( deutsche ##r fuss ##ball verb ##and der dd ##r or german football association of east germany ) . over his career he had coached 1 , 900 games , coming away with 1 , 163 victories . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:6 14:7 15:8 16:8 17:8 18:8 19:9 20:9 21:9 22:10 23:11 24:12 25:13 26:13 27:14 28:15 29:16 30:17 31:18 32:19 33:19 34:20 35:21 36:22 37:23 38:24 39:24 40:25 41:26 42:27 43:28 44:29 45:30 46:31 47:32 48:33 49:34 50:35 51:36 52:37 53:38 54:39 55:39 56:40 57:40 58:41 59:42 60:43 61:43 62:43 63:44 64:44 65:45 66:46 67:47 68:48 69:49 70:50 71:51 72:52 73:53 74:53 75:53 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:61 86:61 87:62 88:62 89:62 90:63 91:63 92:64 93:64 94:65 95:66 96:66 97:67 98:68 99:69 100:70 101:71 102:72 103:73 104:73 105:73 106:74 107:75 108:76 109:77 110:78 111:79 112:80 113:80 114:80 115:81 116:81 117:82 118:83 119:84 120:85 121:85 122:85 123:86 124:86\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2058 2010 2476 2002 2018 102 1996 2136 2036 4110 2048 2264 2446 10268 1006 1042 2094 18259 13433 12902 1007 1999 3411 1998 3355 1010 1998 2081 4413 2647 2452 3922 1012 2076 2010 2476 1996 2235 1010 9384 10365 2036 8868 2871 2120 2136 2867 1998 3271 26944 11725 2107 2004 17359 2546 11382 19020 1998 17885 3520 5017 1012 12880 11624 2001 4594 2004 10365 2012 17205 2011 21037 10975 4887 5753 11624 1998 2333 2006 2000 2147 2005 1996 1040 2546 2615 1006 11605 2099 28554 7384 12034 5685 4315 20315 2099 2030 2446 2374 2523 1997 2264 2762 1007 1012 2058 2010 2476 2002 2018 8868 1015 1010 7706 2399 1010 2746 2185 2007 1015 1010 17867 9248 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000011\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 11\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] from her album think ##in ' about [SEP] xx ##x ' s and o ##oo ' s ( an american girl ) ` ` xx ##x ' s and o ##oo ' s ( an american girl ) ' ' is a song written by mat ##rac ##a berg and alice randall , and recorded by american country music singer tri ##sha year ##wood . it was released in june 1994 as the lead single from her album think ##in ' about you . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 9:0 10:0 11:0 12:0 13:1 14:2 15:2 16:2 17:2 18:3 19:3 20:4 21:5 22:5 23:6 24:6 25:6 26:6 27:6 28:6 29:7 30:8 31:8 32:8 33:8 34:9 35:9 36:10 37:11 38:11 39:11 40:11 41:12 42:13 43:14 44:15 45:16 46:17 47:17 48:17 49:18 50:19 51:20 52:21 53:21 54:22 55:23 56:24 57:25 58:26 59:27 60:28 61:29 62:29 63:30 64:30 65:30 66:31 67:32 68:33 69:34 70:35 71:36 72:37 73:38 74:39 75:40 76:41 77:42 78:43 79:44 80:44 81:44 82:45 83:46 84:46\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2013 2014 2201 2228 2378 1005 2055 102 22038 2595 1005 1055 1998 1051 9541 1005 1055 1006 2019 2137 2611 1007 1036 1036 22038 2595 1005 1055 1998 1051 9541 1005 1055 1006 2019 2137 2611 1007 1005 1005 2003 1037 2299 2517 2011 13523 22648 2050 15214 1998 5650 12813 1010 1998 2680 2011 2137 2406 2189 3220 13012 7377 2095 3702 1012 2009 2001 2207 1999 2238 2807 2004 1996 2599 2309 2013 2014 2201 2228 2378 1005 2055 2017 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000012\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 12\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] 1988 . she became intimately familiar [SEP] the ` ` 9th annual march to stop executions ' ' was october 25 , 2008 in houston . the ` ` 10th annual march to ab ##olis ##h the death penalty ' ' was attended by hundreds of people on october 24 , 2009 in austin . jean ##ette pop ##p was chairperson of texas mora ##torium network from 2001 - 04 . pop ##p ' s daughter nancy was murdered in austin in 1988 . she became intimately familiar with the many flaws of the texas criminal justice system after two innocent men were wrong ##fully convicted of her daughter ' s murder and spent 12 years in prison . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:1 11:1 12:2 13:3 14:4 15:5 16:6 17:6 18:6 19:7 20:8 21:9 22:9 23:10 24:11 25:12 26:12 27:13 28:14 29:14 30:14 31:15 32:16 33:17 34:18 35:18 36:18 37:19 38:20 39:21 40:21 41:21 42:22 43:23 44:24 45:25 46:26 47:27 48:28 49:29 50:30 51:30 52:31 53:32 54:33 55:33 56:34 57:34 58:35 59:35 60:36 61:37 62:38 63:39 64:40 65:40 66:41 67:42 68:43 69:43 70:43 71:43 72:44 73:44 74:44 75:44 76:45 77:46 78:47 79:48 80:49 81:50 82:51 83:52 84:52 85:53 86:54 87:55 88:56 89:57 90:58 91:59 92:60 93:61 94:62 95:63 96:64 97:65 98:66 99:67 100:68 101:69 102:70 103:71 104:72 105:72 106:73 107:74 108:75 109:76 110:76 111:76 112:77 113:78 114:79 115:80 116:81 117:82 118:83 119:83\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2997 1012 2016 2150 29024 5220 102 1996 1036 1036 6280 3296 2233 2000 2644 22679 1005 1005 2001 2255 2423 1010 2263 1999 5395 1012 1996 1036 1036 6049 3296 2233 2000 11113 20872 2232 1996 2331 6531 1005 1005 2001 3230 2011 5606 1997 2111 2006 2255 2484 1010 2268 1999 5899 1012 3744 7585 3769 2361 2001 19072 1997 3146 26821 24390 2897 2013 2541 1011 5840 1012 3769 2361 1005 1055 2684 7912 2001 7129 1999 5899 1999 2997 1012 2016 2150 29024 5220 2007 1996 2116 21407 1997 1996 3146 4735 3425 2291 2044 2048 7036 2273 2020 3308 7699 7979 1997 2014 2684 1005 1055 4028 1998 2985 2260 2086 1999 3827 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000013\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 13\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] prevents him from identifying who [SEP] in the second volume , xiii is captured by general carr ##ington , who confirms that xiii is steve rowland . carr ##ington further explains that rowland was a member of a special ops unit called spa ##ds ( special assault and destroying sections ) . carr ##ington had been commander of spa ##ds when rowland was supposedly killed in a helicopter crash two years earlier . because xiii ' s amnesia prevents him from identifying who sponsored the president ' s assassination , amos lets him go . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:9 19:9 20:10 21:11 22:12 23:13 24:14 25:15 26:16 27:16 28:17 29:17 30:18 31:19 32:20 33:21 34:22 35:23 36:24 37:25 38:26 39:27 40:28 41:29 42:30 43:31 44:31 45:32 46:32 47:33 48:34 49:35 50:36 51:36 52:36 53:37 54:37 55:38 56:39 57:40 58:41 59:42 60:42 61:43 62:44 63:45 64:46 65:47 66:48 67:49 68:50 69:51 70:52 71:53 72:54 73:54 74:55 75:56 76:56 77:56 78:57 79:58 80:59 81:60 82:61 83:62 84:63 85:64 86:65 87:65 88:65 89:66 90:66 91:67 92:68 93:69 94:70 95:70\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 16263 2032 2013 12151 2040 102 1999 1996 2117 3872 1010 15031 2003 4110 2011 2236 12385 7853 1010 2040 23283 2008 15031 2003 3889 20539 1012 12385 7853 2582 7607 2008 20539 2001 1037 2266 1997 1037 2569 23092 3131 2170 12403 5104 1006 2569 6101 1998 9846 5433 1007 1012 12385 7853 2018 2042 3474 1997 12403 5104 2043 20539 2001 10743 2730 1999 1037 7739 5823 2048 2086 3041 1012 2138 15031 1005 1055 29222 16263 2032 2013 12151 2040 6485 1996 2343 1005 1055 10102 1010 13744 11082 2032 2175 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000014\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 14\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] having his grandfather ' s boat imp ##ounded , [SEP] ron taylor is an amateur conservation ##ist who loves the sea and establishes a whale watching company after spotting a whale in the bay . he used to work at the local fish and chips shop ( hook , line & think ##er ) for colin ( played by dave fan ##e ) . after having his grandfather ' s boat imp ##ounded , ron and colin try and steal it back but are caught by officer mike . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 11:0 12:1 13:2 14:3 15:4 16:5 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:18 31:19 32:20 33:21 34:22 35:22 36:23 37:24 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:34 49:34 50:35 51:36 52:37 53:37 54:37 55:38 56:39 57:40 58:40 59:41 60:42 61:43 62:43 63:43 64:43 65:44 66:45 67:46 68:47 69:47 70:47 71:48 72:49 73:49 74:49 75:50 76:51 77:52 78:53 79:54 80:55 81:56 82:57 83:58 84:59 85:60 86:61 87:62 88:63 89:63\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2383 2010 5615 1005 1055 4049 17727 26240 1010 102 6902 4202 2003 2019 5515 5680 2923 2040 7459 1996 2712 1998 21009 1037 13156 3666 2194 2044 27963 1037 13156 1999 1996 3016 1012 2002 2109 2000 2147 2012 1996 2334 3869 1998 11772 4497 1006 8103 1010 2240 1004 2228 2121 1007 2005 6972 1006 2209 2011 4913 5470 2063 1007 1012 2044 2383 2010 5615 1005 1055 4049 17727 26240 1010 6902 1998 6972 3046 1998 8954 2009 2067 2021 2024 3236 2011 2961 3505 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000015\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 15\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] at his family home resulting [SEP] he , like the majority of those in the irish republican brotherhood , supported the anglo - irish treaty and was involved in debates against de vale ##ra during the controversy , most especially discussing the status of sinn f * in as a political entity . he was re - elected as a pro - treaty sinn f * in td in the 1922 general election , siding with the free state government during the irish civil war . according to frank henderson , as told to ernie o ' malley , liam lynch and other members of the * am ##on de vale ##ra ' s anti - treaty faction began planning the assassination of mc ##gar ##ry among other td ##s supporting the public safety bill . on 10 december 1922 , shortly before the first meeting of the free state parliament , a fire was deliberately set by the irregular ##s at his family home resulting in the death of his son . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:10 20:11 21:12 22:13 23:13 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:22 34:22 35:23 36:24 37:25 38:25 39:26 40:27 41:28 42:29 43:30 44:31 45:32 46:33 47:33 48:33 49:34 50:35 51:36 52:37 53:37 54:38 55:39 56:40 57:40 58:40 59:41 60:42 61:43 62:43 63:43 64:44 65:45 66:45 67:45 68:46 69:47 70:48 71:49 72:50 73:51 74:51 75:52 76:53 77:54 78:55 79:56 80:57 81:58 82:59 83:60 84:61 85:62 86:62 87:63 88:64 89:65 90:66 91:66 92:67 93:68 94:69 95:70 96:71 97:71 98:71 99:71 100:72 101:73 102:74 103:75 104:76 105:77 106:78 107:79 108:79 109:79 110:80 111:81 112:81 113:81 114:81 115:82 116:82 117:82 118:83 119:84 120:85 121:86 122:87 123:88 124:89 125:89 126:89 127:90 128:91 129:92 130:92 131:93 132:94 133:95 134:96 135:97 136:97 137:98 138:99 139:100 140:101 141:101 142:102 143:103 144:104 145:105 146:106 147:107 148:108 149:109 150:110 151:111 152:111 153:112 154:113 155:114 156:115 157:116 158:117 159:118 160:119 161:119 162:120 163:121 164:122 165:123 166:124 167:125 168:126 169:127 170:128 171:129 172:130 173:130\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True 114:True 115:True 116:True 117:True 118:True 119:True 120:True 121:True 122:True 123:True 124:True 125:True 126:True 127:True 128:True 129:True 130:True 131:True 132:True 133:True 134:True 135:True 136:True 137:True 138:True 139:True 140:True 141:True 142:True 143:True 144:True 145:True 146:True 147:True 148:True 149:True 150:True 151:True 152:True 153:True 154:True 155:True 156:True 157:True 158:True 159:True 160:True 161:True 162:True 163:True 164:True 165:True 166:True 167:True 168:True 169:True 170:True 171:True 172:True 173:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2012 2010 2155 2188 4525 102 2002 1010 2066 1996 3484 1997 2216 1999 1996 3493 3951 12865 1010 3569 1996 7819 1011 3493 5036 1998 2001 2920 1999 14379 2114 2139 10380 2527 2076 1996 6704 1010 2087 2926 10537 1996 3570 1997 26403 1042 1008 1999 2004 1037 2576 9178 1012 2002 2001 2128 1011 2700 2004 1037 4013 1011 5036 26403 1042 1008 1999 14595 1999 1996 4798 2236 2602 1010 17326 2007 1996 2489 2110 2231 2076 1996 3493 2942 2162 1012 2429 2000 3581 9481 1010 2004 2409 2000 14637 1051 1005 25271 1010 8230 11404 1998 2060 2372 1997 1996 1008 2572 2239 2139 10380 2527 1005 1055 3424 1011 5036 10233 2211 4041 1996 10102 1997 11338 6843 2854 2426 2060 14595 2015 4637 1996 2270 3808 3021 1012 2006 2184 2285 4798 1010 3859 2077 1996 2034 3116 1997 1996 2489 2110 3323 1010 1037 2543 2001 9969 2275 2011 1996 12052 2015 2012 2010 2155 2188 4525 1999 1996 2331 1997 2010 2365 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000016\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 16\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] on her program , but as [SEP] he loses his medal during the struggle , which laura recover ##s . later , leroy witnesses laura being kidnapped by ark ##adia ##n ' s br ##uti ##sh hen ##chman rock ( mike starr ) . a clue left behind reveals that the kidnap ##pers work for eddie ark ##adia ##n productions . laura refuses to promote angela vi ##rac ##co ' s video on her program , but as ark ##adia ##n ' s men prepare to coe ##rce her by force , leroy suddenly bursts into the room and rescues laura once again . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:6 16:7 17:8 18:9 19:9 20:9 21:10 22:10 23:11 24:12 25:13 26:14 27:15 28:16 29:17 30:17 31:17 32:17 33:17 34:18 35:18 36:18 37:19 38:19 39:20 40:21 41:21 42:22 43:22 44:22 45:23 46:24 47:25 48:26 49:27 50:28 51:29 52:30 53:30 54:31 55:32 56:33 57:34 58:34 59:34 60:35 61:35 62:36 63:37 64:38 65:39 66:40 67:41 68:41 69:41 70:41 71:41 72:42 73:43 74:44 75:45 76:45 77:46 78:47 79:48 80:48 81:48 82:48 83:48 84:49 85:50 86:51 87:52 88:52 89:53 90:54 91:55 92:55 93:56 94:57 95:58 96:59 97:60 98:61 99:62 100:63 101:64 102:65 103:66 104:66\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 2006 2014 2565 1010 2021 2004 102 2002 12386 2010 3101 2076 1996 5998 1010 2029 6874 8980 2015 1012 2101 1010 19103 9390 6874 2108 11364 2011 15745 25205 2078 1005 1055 7987 21823 4095 21863 19944 2600 1006 3505 14330 1007 1012 1037 9789 2187 2369 7657 2008 1996 22590 7347 2147 2005 5752 15745 25205 2078 5453 1012 6874 10220 2000 5326 10413 6819 22648 3597 1005 1055 2678 2006 2014 2565 1010 2021 2004 15745 25205 2078 1005 1055 2273 7374 2000 24873 19170 2014 2011 2486 1010 19103 3402 19239 2046 1996 2282 1998 26001 6874 2320 2153 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000017\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 17\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] and his first major photographic [SEP] soon after arriving in new york , see ##ff ' s photographs of the people he encountered on the streets of manhattan were discovered by the famed graphic designer , bob cat ##o . cat ##o introduced see ##ff to the world of album cover design and his first major photographic assignment for the band brought him immediate recognition . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:1 9:2 10:3 11:4 12:5 13:5 14:6 15:6 16:6 17:6 18:7 19:8 20:9 21:10 22:11 23:12 24:13 25:14 26:15 27:16 28:17 29:18 30:19 31:20 32:21 33:22 34:23 35:24 36:24 37:25 38:26 39:26 40:26 41:27 42:27 43:28 44:29 45:29 46:30 47:31 48:32 49:33 50:34 51:35 52:36 53:37 54:38 55:39 56:40 57:41 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:49 66:49\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 1998 2010 2034 2350 12416 102 2574 2044 7194 1999 2047 2259 1010 2156 4246 1005 1055 7008 1997 1996 2111 2002 8567 2006 1996 4534 1997 7128 2020 3603 2011 1996 15607 8425 5859 1010 3960 4937 2080 1012 4937 2080 3107 2156 4246 2000 1996 2088 1997 2201 3104 2640 1998 2010 2034 2350 12416 8775 2005 1996 2316 2716 2032 6234 5038 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000018\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 18\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] cox . she auditioned and won [SEP] her first tv role was in a german advertisement for cleaning powder . shortly afterwards she won the role of gee ##na gregory in coronation street which she played from 2000 - 2002 . after learning she was to be written out of her role as bar ##maid gee ##na , she brought out a fitness video entitled get fit quick with jennifer james with suzanne cox . she auditioned and won the role of joyce in the second quest , directed by david jason , for yorkshire television in 2003 . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 8:0 9:1 10:2 11:3 12:4 13:5 14:6 15:7 16:8 17:9 18:10 19:11 20:11 21:12 22:13 23:14 24:15 25:16 26:17 27:18 28:19 29:19 30:20 31:21 32:22 33:23 34:24 35:25 36:26 37:27 38:28 39:28 40:28 41:28 42:29 43:30 44:31 45:32 46:33 47:34 48:35 49:36 50:37 51:38 52:39 53:40 54:41 55:41 56:42 57:42 58:42 59:43 60:44 61:45 62:46 63:47 64:48 65:49 66:50 67:51 68:52 69:53 70:54 71:55 72:56 73:57 74:58 75:58 76:59 77:60 78:61 79:62 80:63 81:64 82:65 83:66 84:67 85:68 86:69 87:70 88:70 89:71 90:72 91:73 92:74 93:74 94:75 95:76 96:77 97:78 98:79 99:79\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 9574 1012 2016 23008 1998 2180 102 2014 2034 2694 2535 2001 1999 1037 2446 15147 2005 9344 9898 1012 3859 5728 2016 2180 1996 2535 1997 20277 2532 7296 1999 12773 2395 2029 2016 2209 2013 2456 1011 2526 1012 2044 4083 2016 2001 2000 2022 2517 2041 1997 2014 2535 2004 3347 28478 20277 2532 1010 2016 2716 2041 1037 10516 2678 4709 2131 4906 4248 2007 7673 2508 2007 15146 9574 1012 2016 23008 1998 2180 1996 2535 1997 11830 1999 1996 2117 8795 1010 2856 2011 2585 4463 1010 2005 7018 2547 1999 2494 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   *** Example ***\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   unique_id: 1000000019\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   example_index: 19\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   doc_span_index: 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   tokens: [CLS] of her husband sparked one [SEP] inn ##a gu ##dav ##ad ##ze is a georgian business ##woman and philanthropist and the widow of bad ##ri pat ##ark ##ats ##ish ##vili . in 2017 the sunday times estimated her wealth at * 650 ##m making her the 196 ##th wealthiest person in the uk . she has two daughters , lia ##na z ##hm ##oto ##va and i ##ya pat ##ark ##ats ##ish ##vili . the death of her husband sparked one of the biggest estate battles ever that forced inn ##a and her family to fight for their interests in the courts against several of bad ##ri ' s former business associates . [SEP]\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_to_orig_map: 7:0 8:0 9:1 10:1 11:1 12:1 13:2 14:3 15:4 16:5 17:5 18:6 19:7 20:8 21:9 22:10 23:11 24:12 25:12 26:13 27:13 28:13 29:13 30:13 31:13 32:14 33:15 34:16 35:17 36:18 37:19 38:20 39:21 40:22 41:23 42:23 43:23 44:24 45:25 46:26 47:27 48:27 49:28 50:29 51:30 52:31 53:32 54:32 55:33 56:34 57:35 58:36 59:36 60:37 61:37 62:38 63:38 64:38 65:38 66:39 67:40 68:40 69:41 70:41 71:41 72:41 73:41 74:41 75:42 76:43 77:44 78:45 79:46 80:47 81:48 82:49 83:50 84:51 85:52 86:53 87:54 88:55 89:56 90:57 91:57 92:58 93:59 94:60 95:61 96:62 97:63 98:64 99:65 100:66 101:67 102:68 103:69 104:70 105:71 106:72 107:72 108:72 109:72 110:73 111:74 112:75 113:75\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   token_is_max_context: 7:True 8:True 9:True 10:True 11:True 12:True 13:True 14:True 15:True 16:True 17:True 18:True 19:True 20:True 21:True 22:True 23:True 24:True 25:True 26:True 27:True 28:True 29:True 30:True 31:True 32:True 33:True 34:True 35:True 36:True 37:True 38:True 39:True 40:True 41:True 42:True 43:True 44:True 45:True 46:True 47:True 48:True 49:True 50:True 51:True 52:True 53:True 54:True 55:True 56:True 57:True 58:True 59:True 60:True 61:True 62:True 63:True 64:True 65:True 66:True 67:True 68:True 69:True 70:True 71:True 72:True 73:True 74:True 75:True 76:True 77:True 78:True 79:True 80:True 81:True 82:True 83:True 84:True 85:True 86:True 87:True 88:True 89:True 90:True 91:True 92:True 93:True 94:True 95:True 96:True 97:True 98:True 99:True 100:True 101:True 102:True 103:True 104:True 105:True 106:True 107:True 108:True 109:True 110:True 111:True 112:True 113:True\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_ids: 101 1997 2014 3129 13977 2028 102 7601 2050 19739 29045 4215 4371 2003 1037 9166 2449 10169 1998 15246 1998 1996 7794 1997 2919 3089 6986 17007 11149 4509 21661 1012 1999 2418 1996 4465 2335 4358 2014 7177 2012 1008 13757 2213 2437 2014 1996 20035 2705 27809 2711 1999 1996 2866 1012 2016 2038 2048 5727 1010 22393 2532 1062 14227 11439 3567 1998 1045 3148 6986 17007 11149 4509 21661 1012 1996 2331 1997 2014 3129 13977 2028 1997 1996 5221 3776 7465 2412 2008 3140 7601 2050 1998 2014 2155 2000 2954 2005 2037 5426 1999 1996 5434 2114 2195 1997 2919 3089 1005 1055 2280 2449 9228 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:45 - INFO - __main__ -   segment_ids: 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "05/02/2019 16:49:46 - INFO - __main__ -   ***** Running predictions *****\n",
      "05/02/2019 16:49:46 - INFO - __main__ -     Num split examples = 1965\n",
      "05/02/2019 16:49:46 - INFO - __main__ -     Batch size = 8\n",
      "05/02/2019 16:49:46 - INFO - __main__ -   Start evaluating\n",
      "Evaluating:   0%|          | 0/246 [00:00<?, ?it/s]05/02/2019 16:49:46 - INFO - __main__ -   Processing example: 0\n",
      "Evaluating:  51%|█████     | 125/246 [00:35<00:34,  3.56it/s]05/02/2019 16:50:22 - INFO - __main__ -   Processing example: 1000\n",
      "Evaluating: 100%|██████████| 246/246 [01:09<00:00,  3.95it/s]\n",
      "05/02/2019 16:51:13 - INFO - __main__ -   ***** Running predictions *****\n",
      "05/02/2019 16:51:13 - INFO - __main__ -     Num split examples = 492\n",
      "05/02/2019 16:51:13 - INFO - __main__ -     Batch size = 8\n",
      "05/02/2019 16:51:13 - INFO - __main__ -   Start evaluating\n",
      "Evaluating:   0%|          | 0/62 [00:00<?, ?it/s]05/02/2019 16:51:13 - INFO - __main__ -   Processing example: 0\n",
      "Evaluating: 100%|██████████| 62/62 [00:17<00:00,  4.10it/s]\n",
      "05/02/2019 16:51:34 - INFO - __main__ -   ***** Running predictions *****\n",
      "05/02/2019 16:51:34 - INFO - __main__ -     Num split examples = 2001\n",
      "05/02/2019 16:51:34 - INFO - __main__ -     Batch size = 8\n",
      "05/02/2019 16:51:34 - INFO - __main__ -   Start evaluating\n",
      "Evaluating:   0%|          | 0/251 [00:00<?, ?it/s]05/02/2019 16:51:34 - INFO - __main__ -   Processing example: 0\n",
      "Evaluating:  50%|████▉     | 125/251 [00:35<00:35,  3.56it/s]05/02/2019 16:52:09 - INFO - __main__ -   Processing example: 1000\n",
      "Evaluating: 100%|█████████▉| 250/251 [01:10<00:00,  3.55it/s]05/02/2019 16:52:45 - INFO - __main__ -   Processing example: 2000\n",
      "Evaluating: 100%|██████████| 251/251 [01:10<00:00,  3.57it/s]\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "05/02/2019 16:53:01 - INFO - __main__ -   Confirm val loss: 0.4535\n"
     ]
    }
   ],
   "source": [
    "squad_val_preds, squad_test_preds, squad_val_losses = squad_runner.run_k_fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_test_probas = np.mean(squad_test_preds, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# squad_runner_cased = SquadRunner(dev_df, val_df, test_df_prod, train_batch_size=12, num_train_epochs=2, do_lower_case=False)\n",
    "# squad_val_preds_cased, squad_test_preds_cased, squad_val_losses_cased = squad_runner_cased.run_k_fold()\n",
    "# squad_test_probas_cased = np.mean(squad_test_preds_cased, axis=0)\n",
    "# squad_test_probas = (squad_test_probas + squad_test_probas_cased) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame([test_df_prod.ID, squad_test_probas[:,0], squad_test_probas[:,1], squad_test_probas[:,2]], index=['ID', 'A', 'B', 'NEITHER']).transpose()\n",
    "submission_df.to_csv('stage1_squad_only.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
